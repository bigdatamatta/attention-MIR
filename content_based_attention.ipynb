{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pinouche\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from numpy import exp, sqrt, dot\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.io import loadmat\n",
    "from random import shuffle\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import moment\n",
    "from scipy.stats import skew\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data into bootstrapped sequences tf.Dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    dataset = \"MODIS\"\n",
    "    mat_dict = loadmat(r'../MIR/'+ dataset + '.mat')\n",
    "    full_data = pd.DataFrame(mat_dict[dataset])\n",
    "\n",
    "    # Rename columns to something more interpretable\n",
    "    columns = ([\"id\"] + [\"reflectance_\" + str(i) for i in range(7)]\n",
    "               + [\"solar_\" + str(i) for i in range(5)] + ['label'])\n",
    "    full_data.columns = columns\n",
    "    \n",
    "    if dataset == \"MISR2\":\n",
    "        full_data = full_data[full_data['id'].isin(list(full_data['id'].value_counts().index[full_data['id'].value_counts() == 100]))]\n",
    "\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def moments_df(n_moments):\n",
    "    \n",
    "    # load the data\n",
    "    full_data = load_data()\n",
    "\n",
    "    non_constant_cols = ['id', 'reflectance_0', 'reflectance_1', 'reflectance_2',\n",
    "           'reflectance_3', 'reflectance_4', 'reflectance_5', 'reflectance_6']\n",
    "\n",
    "    constant_columns = ['solar_0', 'solar_1', 'solar_2', 'solar_3', 'solar_4']\n",
    "    list_operation = ['np.mean', 'np.var', 'skew', 'kurtosis']\n",
    "\n",
    "    full_data_subset = full_data[non_constant_cols]\n",
    "    \n",
    "    dic_df = {}\n",
    "\n",
    "    for moments in range(1, n_moments+1):\n",
    "        if moments < 5:\n",
    "            dic_df[moments] = eval(\"np.stack(full_data_subset.groupby('id').apply(lambda group: \" + \n",
    "                                   list_operation[moments-1] + \"(group)).values)[:,1:]\")\n",
    "        else:\n",
    "            dic_df[moments] = np.stack(full_data_subset.groupby('id').apply(lambda group: moment(group, moment=moments)))[:,1:]\n",
    "\n",
    "    array_data = dic_df[1]\n",
    "    \n",
    "    if n_moments > 1:\n",
    "        for key in range(2, n_moments+1):\n",
    "            array_data = np.hstack([array_data, dic_df[key]])   \n",
    "\n",
    "    df = pd.DataFrame(array_data)\n",
    "    df = pd.concat([df, full_data.groupby('id').mean()[constant_columns].reset_index()], axis=1)\n",
    "    df['id'] = full_data['id'].unique()\n",
    "    df['label'] = full_data.groupby('id').mean()['label'].values\n",
    "    df = df.set_index('id')\n",
    "    \n",
    "    col_label = ['label']\n",
    "    labels = df[col_label]\n",
    "    df = df[[col for col in df.columns if col not in col_label]]\n",
    "    \n",
    "    return df, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_sequences(train, test):\n",
    "    list_sequence_train, list_sequence_test = [], []\n",
    "    list_train_y, list_test_y = [], []\n",
    "    features = [col for col in train.columns if col not in ['id', 'label']]\n",
    "    \n",
    "    for bag_id in list(train['id'].unique()):\n",
    "        list_sequence_train.append(np.array(train[train['id']==bag_id][features]))\n",
    "        list_train_y.append(np.array(train[train['id']==bag_id]['label'])[0])\n",
    "        \n",
    "    for bag_id in list(test['id'].unique()):\n",
    "        list_sequence_test.append(np.array(test[test['id']==bag_id][features]))\n",
    "        list_test_y.append(np.array(test[test['id']==bag_id]['label'])[0])\n",
    "    \n",
    "    return list_sequence_train, list_sequence_test, list_train_y, list_test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference_attention(random_seed, processor_steps, splits=5, use_moments=False, n_moments=1, concat_late=False):\n",
    "\n",
    "    full_data = load_data()\n",
    "    num_features = 12\n",
    "    count = 1\n",
    "    \n",
    "    if use_moments:\n",
    "        num_features = 12 + n_moments*7\n",
    "        df, _ = moments_df(n_moments)\n",
    "        col_solar = ['solar_0', 'solar_1', 'solar_2', 'solar_3', 'solar_4']\n",
    "        df = df.iloc[np.repeat(np.arange(len(df)), 100)]\n",
    "        df = df[[col for col in df.columns if col not in col_solar]]\n",
    "        df = df.reset_index(drop=True)\n",
    "        full_data = pd.concat([full_data, df], axis=1)\n",
    "    \n",
    "    kf = KFold(n_splits=splits, shuffle=True, random_state=random_seed)\n",
    "    cols_exclude = [\"id\", \"label\"]\n",
    "    features = [col for col in list(full_data.columns) if col not in cols_exclude]\n",
    "    lowest_val_list, loss_test_list = [], []\n",
    "    \n",
    "    for train_index, test_index in kf.split(list(full_data['id'].unique())):\n",
    "        #print('Compute for FOLD NUMBER ' + str(count))\n",
    "        train = full_data[full_data['id'].apply(lambda value: value in train_index)]\n",
    "        test = full_data[full_data['id'].apply(lambda value: value in test_index)]\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(train[features])\n",
    "        train[features], test[features] = scaler.transform(train[features]), scaler.transform(test[features])\n",
    "    \n",
    "        list_sequence_train, list_sequence_test, train_y, test_y = make_sequences(train, test)\n",
    "        lowest_val_loss, loss_test = attention(list_sequence_train, list_sequence_test, train_y, test_y, \n",
    "                                               num_features, processor_steps, concat_late)\n",
    "        \n",
    "        lowest_val_list.append(lowest_val_loss)\n",
    "        loss_test_list.append(loss_test)\n",
    "        \n",
    "        tf.reset_default_graph()\n",
    "        count += 1\n",
    "    \n",
    "    return lowest_val_loss, loss_test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_rmse(pred_array, truth_array):\n",
    "    loss = np.sqrt(mean_squared_error(np.reshape(np.array(pred_array), (np.array(pred_array).shape[0],1)), \n",
    "                                               np.reshape(np.array(truth_array), (np.array(truth_array).shape[0],1))))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check the neighbours of the minimum to be sure it is not due to stochasticity\n",
    "def get_min_index(array, n_max=3):\n",
    "    indices = array.argsort()[:n_max] \n",
    "    \n",
    "    avg_neighbourgs = []\n",
    "    for val in indices:\n",
    "        if val == len(array)-1:\n",
    "            avg_neighbourgs.append((array[val]+array[val-1]+array[val-2])/3)\n",
    "        else:\n",
    "            avg_neighbourgs.append((array[val]+array[val-1]+array[val+1])/3)\n",
    "    \n",
    "    index = indices[np.argmin(avg_neighbourgs)]\n",
    "    \n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# network hyperparameters\n",
    "\n",
    "batch_size = 1\n",
    "sequence_lenght = 100\n",
    "dropout_p = 0.5\n",
    "\n",
    "# reading block Neural Network size\n",
    "size_h1 = 256\n",
    "\n",
    "n_epochs = 500\n",
    "num_test_runs = 1\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def attention(list_sequence_train, list_sequence_val, train_y, val_y, num_features, processor_steps, concat_late=False):\n",
    "    \n",
    "    with tf.variable_scope('data'):\n",
    "        \n",
    "        prob = tf.placeholder_with_default(1.0, shape=())\n",
    "        X_or = tf.placeholder(shape = [sequence_lenght, num_features], dtype = tf.float32, name = \"input\")\n",
    "        if concat_late:\n",
    "            X_or = tf.placeholder(shape = [sequence_lenght, 12], dtype = tf.float32, name = \"input\")\n",
    "            X_fixed = tf.placeholder(shape = [1, num_features-12], dtype = tf.float32, name = \"fixed_input\")\n",
    "            fixed_num_features = num_features-12\n",
    "            num_features = 12\n",
    "        y = tf.placeholder(shape = [1,1], dtype = tf.float32, name = \"label_annotation\")\n",
    "        \n",
    "    with tf.variable_scope('reading_block'):\n",
    "    \n",
    "        W_reading1 = tf.Variable(tf.random_normal(shape = (num_features, int(size_h1/2)), stddev = 0.1), name = \"weights_hidden1\", trainable = True)\n",
    "        hidden_relu1 = tf.matmul(X_or, W_reading1)\n",
    "        BN1 = tf.nn.relu(hidden_relu1, name = \"ReLu_hidden_layer1\")\n",
    "        BN1 = tf.nn.dropout(BN1, prob, noise_shape=[1,int(size_h1/2)])\n",
    "        \n",
    "    with tf.variable_scope('initialize_lstm'):\n",
    "        \n",
    "        static_input = tf.zeros(shape=[1,1,1])\n",
    "        unstack_input = tf.unstack(static_input, 1, 1)\n",
    "        lstm_cell = tf.nn.rnn_cell.LSTMCell(int(size_h1/2), reuse=tf.AUTO_REUSE, state_is_tuple=False)\n",
    "        initial_state = lstm_cell.zero_state(1, dtype=tf.float32)\n",
    "        \n",
    "    for index in range(processor_steps):\n",
    "        with tf.variable_scope('lstm_cell_decoder', reuse = tf.AUTO_REUSE):\n",
    "            \n",
    "            output_decoder, state_decoder = tf.nn.static_rnn(lstm_cell, inputs=unstack_input,\n",
    "                                                             initial_state=initial_state, dtype=tf.float32)\n",
    "\n",
    "            W_decoder = tf.get_variable(initializer=tf.random_normal(shape = (size_h1, int(size_h1/2)), stddev = 0.1), name = \"decoder_weights\", trainable = True)\n",
    "\n",
    "            relu_decoder = tf.nn.relu(tf.matmul(state_decoder, W_decoder))\n",
    "            relu_decoder = tf.nn.dropout(relu_decoder, prob, noise_shape=[1,int(size_h1/2)])\n",
    "\n",
    "            inner_product = tf.matmul(BN1, tf.reshape(relu_decoder, shape=(int(size_h1/2), 1)))\n",
    "            reshaped_inner_product = tf.reshape(inner_product, shape=(1, sequence_lenght))\n",
    "#             W_attention = tf.get_variable(initializer=tf.random_normal(shape = (sequence_lenght, sequence_lenght), \n",
    "#                                                                        stddev = 0.1), name = \"w_attention\", trainable = True)\n",
    "#             reshaped_inner_product = tf.nn.sigmoid(tf.matmul(reshaped_inner_product, W_attention))\n",
    "            \n",
    "            attention_score =  tf.nn.softmax(reshaped_inner_product)\n",
    "            context_vector = tf.multiply(BN1, tf.reshape(attention_score, (sequence_lenght, 1)))\n",
    "            r_vector = tf.reshape(tf.reduce_sum(context_vector, axis=0), (1,int(size_h1/2)))\n",
    "            q_star = tf.concat([relu_decoder, r_vector], axis=1)\n",
    "\n",
    "            initial_state = q_star\n",
    "            \n",
    "    with tf.variable_scope('logits'):\n",
    "        if concat_late:\n",
    "            q_star_concat = tf.concat([q_star, X_fixed], axis=1)\n",
    "            q_star_concat = tf.nn.dropout(q_star_concat, prob)\n",
    "            W_concat = tf.Variable(tf.random_normal(shape = (size_h1+fixed_num_features, 1), stddev = 0.1), name = \"weights_concat\", trainable = True)\n",
    "            logits = tf.nn.relu(tf.matmul(q_star_concat, W_concat))\n",
    "        else:   \n",
    "            W_logits = tf.Variable(tf.random_normal(shape = (size_h1, 1), stddev = 0.1), name = \"weights_logits\", trainable = True)\n",
    "            logits = tf.nn.relu(tf.matmul(q_star, W_logits))\n",
    "        \n",
    "    with tf.variable_scope('loss'):\n",
    "        \n",
    "        loss =  tf.losses.mean_squared_error(predictions = logits, labels = y)\n",
    "        \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "    train_op = optimizer.minimize(loss)\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "    \n",
    "    val_loss_list, test_loss_list = [], []\n",
    "\n",
    "    for i in range(1, n_epochs+1):\n",
    "    \n",
    "        train_pred, train_truth = [], []\n",
    "        val_test_pred, val_test_truth = [], []\n",
    "        indices = list(range(len(list_sequence_train)))\n",
    "        shuffle(indices)\n",
    "\n",
    "        for index in indices:\n",
    "            # batch is size 1 here: stochastic gradient descent\n",
    "            if concat_late:\n",
    "                X_batch_or = np.reshape(list_sequence_train[index][:,:12], (100, num_features))\n",
    "                X_batch_fixed = np.reshape(list_sequence_train[index][0,12:], (1, fixed_num_features))\n",
    "                Y_batch = np.reshape(train_y[index], (1,1))\n",
    "                _, pred = sess.run([train_op, logits], feed_dict = {X_or: X_batch_or, X_fixed: X_batch_fixed,\n",
    "                                                                    y: Y_batch, prob: dropout_p})\n",
    "            else:\n",
    "                X_batch = np.reshape(list_sequence_train[index], (100, num_features))\n",
    "                Y_batch = np.reshape(train_y[index], (1,1))\n",
    "                _, pred = sess.run([train_op, logits], feed_dict = {X_or: X_batch, y: Y_batch, prob: dropout_p})\n",
    "\n",
    "            #_, pred = sess.run([train_op, logits], feed_dict = {X_or: X_batch, y: Y_batch, prob: dropout_p})\n",
    "            train_pred.append(pred)\n",
    "            train_truth.append(Y_batch)\n",
    "\n",
    "        for index in range(len(list_sequence_val)):\n",
    "            # batch is size 1 here: stochastic gradient descent\n",
    "            if concat_late:\n",
    "                X_batch_or = np.reshape(list_sequence_val[index][:,:12], (100, num_features))\n",
    "                X_batch_fixed = np.reshape(list_sequence_val[index][0,12:], (1, fixed_num_features))\n",
    "                Y_batch = np.reshape(val_y[index], (1,1))\n",
    "            else:\n",
    "                X_batch = np.reshape(list_sequence_val[index], (100, num_features))\n",
    "                Y_batch = np.reshape(val_y[index], (1,1))\n",
    "                \n",
    "            #X_batch = np.reshape(list_sequence_val[index], (100, num_features))\n",
    "            #Y_batch = np.reshape(val_y[index], (1,1))\n",
    "\n",
    "            pred_avg = 0\n",
    "            for _ in range(num_test_runs):\n",
    "                if concat_late:\n",
    "                    pred = sess.run([logits], feed_dict = {X_or: X_batch_or, X_fixed: X_batch_fixed,\n",
    "                                                           y: Y_batch, prob: 1})\n",
    "                else:\n",
    "                    pred = sess.run([logits], feed_dict = {X_or: X_batch, y: Y_batch, prob: 1})\n",
    "                pred_avg += pred[0]\n",
    "\n",
    "            val_test_pred.append(pred_avg/num_test_runs)\n",
    "            val_test_truth.append(Y_batch)\n",
    "            \n",
    "        if i == 1:\n",
    "            # shuffle because the bags in the list are ranked (increasing order)\n",
    "            range_arr = np.arange(len(val_test_truth))\n",
    "            half_lenght = int(len(val_test_truth)/2)\n",
    "            np.random.shuffle(range_arr)\n",
    "            indices_val, indices_test = range_arr[:half_lenght], range_arr[half_lenght:]\n",
    "        \n",
    "        val_test_truth, val_test_pred = np.array(val_test_truth), np.array(val_test_pred)\n",
    "        val_pred, val_truth = val_test_pred[indices_val], val_test_truth[indices_val]\n",
    "        test_pred, test_truth = val_test_pred[indices_test], val_test_truth[indices_test]\n",
    "\n",
    "        training_loss = compute_rmse(train_pred, train_truth)\n",
    "        val_loss = compute_rmse(val_pred, val_truth)\n",
    "        test_loss = compute_rmse(test_pred, test_truth)\n",
    "    \n",
    "        val_loss_list.append(val_loss)\n",
    "        test_loss_list.append(test_loss)\n",
    "        \n",
    "        if (i == 1) or (i % 10 == 0):\n",
    "            print(\"EPOCH \" + str(i))\n",
    "            print(\"VAL LOSS: \" + str(val_loss), \"TEST LOSS: \" + str(test_loss))\n",
    "\n",
    "#     lowest_val_loss = min(val_loss_list)\n",
    "#     loss_test = test_loss_list[val_loss_list.index(lowest_val_loss)]\n",
    "    \n",
    "    min_index = get_min_index(np.array(val_loss_list), 5)\n",
    "    lowest_val_loss = val_loss_list[min_index]\n",
    "    loss_test = test_loss_list[min_index]\n",
    "\n",
    "    return lowest_val_loss, loss_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPUTING FOR 4 MOMENTS\n",
      "COMPUTING FOR ITERATION NUMBER 1\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001781352B4A8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.261069623920048 TEST LOSS: 0.22620425013598444\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.261069623920048 TEST LOSS: 0.22620425013598444\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.1943280669612466 TEST LOSS: 0.15854484502834607\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.19307801046578782 TEST LOSS: 0.16754517312242084\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.16104269994665676 TEST LOSS: 0.1337658358997396\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.14272663454155413 TEST LOSS: 0.13179367277422957\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.13321796379721038 TEST LOSS: 0.11316379765807107\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.1258235650094206 TEST LOSS: 0.10131010417030875\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.1135367877066628 TEST LOSS: 0.09682748120238054\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.11770927043855188 TEST LOSS: 0.0901075226150185\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.11026683449487434 TEST LOSS: 0.08705439517837722\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.11047206541297404 TEST LOSS: 0.08056044109396221\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.09656640271253916 TEST LOSS: 0.07729504478613318\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.09771020773534081 TEST LOSS: 0.08200790568019144\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.0882975611831068 TEST LOSS: 0.07581330614233354\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.08894578937445802 TEST LOSS: 0.07588671125178063\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.09132565519611625 TEST LOSS: 0.07921548397181169\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.07772409288331514 TEST LOSS: 0.07589188650298591\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.07693737441577055 TEST LOSS: 0.071955673477835\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.08044208521760951 TEST LOSS: 0.06789018227915693\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.08205922911282816 TEST LOSS: 0.07602397997291226\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.08174345608702302 TEST LOSS: 0.07171627899252674\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.07440383867017403 TEST LOSS: 0.0669795487709535\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.07348255531035862 TEST LOSS: 0.07230290082140096\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.07644751837957332 TEST LOSS: 0.07056428374121361\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.07442280716837106 TEST LOSS: 0.06861625709564581\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.07802935856811768 TEST LOSS: 0.06455205796769048\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.07368760064484839 TEST LOSS: 0.06705938535813785\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.07128538081840609 TEST LOSS: 0.06029384878277151\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.06842547873286946 TEST LOSS: 0.06527613660957383\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.06530108681743306 TEST LOSS: 0.06609889908639395\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.06822907617750092 TEST LOSS: 0.060262183882068714\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.07553156798566762 TEST LOSS: 0.059104783069875017\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.0741956762303686 TEST LOSS: 0.06446466657449254\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.07084935620091518 TEST LOSS: 0.05641847350100635\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.07173428424444418 TEST LOSS: 0.05868469678284844\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.07049061133513132 TEST LOSS: 0.05908948118136979\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.07107889589611664 TEST LOSS: 0.0650073017762346\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.07019409665439014 TEST LOSS: 0.06325715520287171\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.07344978534295069 TEST LOSS: 0.060942597966629646\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.07757278146027856 TEST LOSS: 0.06564416471854999\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.07391480036131784 TEST LOSS: 0.058869034885940315\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.07365860230259891 TEST LOSS: 0.06511803393347618\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.07565611665329976 TEST LOSS: 0.05936235362747609\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.07506115261504058 TEST LOSS: 0.06127634201825725\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.07401792274869717 TEST LOSS: 0.0677400988556452\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.07537815489103088 TEST LOSS: 0.06266855541794089\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.07637437605256361 TEST LOSS: 0.06168060801345584\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.07333945051626732 TEST LOSS: 0.061010123057527045\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.07492654937196468 TEST LOSS: 0.06307629324526721\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.07360424138272657 TEST LOSS: 0.062262811237658\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000017810DCA550>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.3297721237247682 TEST LOSS: 0.16429621627129914\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.28604173753587725 TEST LOSS: 0.1572211989923008\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.28681510068195104 TEST LOSS: 0.16073671576539802\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.24147949075511035 TEST LOSS: 0.1399838070883262\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.1804336469949621 TEST LOSS: 0.127630876443252\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.17063901399065676 TEST LOSS: 0.11749367737839067\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.15829262414828335 TEST LOSS: 0.10834722806934773\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.14233929319215352 TEST LOSS: 0.10077253618466543\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.12560292459319491 TEST LOSS: 0.09959129375277123\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.12823511742135352 TEST LOSS: 0.08572901704124988\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.13356709948919937 TEST LOSS: 0.08777016130231317\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.1138987616219383 TEST LOSS: 0.08742697140949864\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.1108060044591595 TEST LOSS: 0.07821962128284946\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.1072544097188776 TEST LOSS: 0.07830632393857076\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.10719645536202552 TEST LOSS: 0.07426409852967786\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.11992333958171918 TEST LOSS: 0.07696575337934827\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.10485471255184158 TEST LOSS: 0.06278906215508781\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.11289356212838429 TEST LOSS: 0.06969624291545928\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.10837317810672151 TEST LOSS: 0.06403522140752209\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.11269410612240836 TEST LOSS: 0.06494138781922267\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.10446145468230364 TEST LOSS: 0.06085075459184761\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.10554969731721627 TEST LOSS: 0.06382482609609781\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.11000014039066387 TEST LOSS: 0.06276069239216635\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.10622712533214837 TEST LOSS: 0.06278238106440635\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.10265418717963894 TEST LOSS: 0.054997043260318644\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.09535298284060298 TEST LOSS: 0.058549328576790585\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.10458597089993367 TEST LOSS: 0.054914587882056935\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.10820735183634966 TEST LOSS: 0.05785075609297407\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.11671316211232131 TEST LOSS: 0.059615150258787664\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.11220172298477644 TEST LOSS: 0.055248704338199055\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.10411030728798291 TEST LOSS: 0.060126948599424475\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.10972849348100627 TEST LOSS: 0.05720934474779789\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.09373580935053898 TEST LOSS: 0.05536765359237049\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.10487571989543609 TEST LOSS: 0.05210569466020755\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.11019121713265399 TEST LOSS: 0.05610220160889359\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.11445680470430648 TEST LOSS: 0.057533042405892326\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.10247689851958998 TEST LOSS: 0.052259370110240476\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.11454961562228669 TEST LOSS: 0.054188057418564\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.10832121513655919 TEST LOSS: 0.053513648089199554\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.09326552653367406 TEST LOSS: 0.05586457489756139\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.09660775494719971 TEST LOSS: 0.05500347612546209\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.11221469903596895 TEST LOSS: 0.05457070452459371\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.10984054396886686 TEST LOSS: 0.05437099662158569\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.11137521435641434 TEST LOSS: 0.05354160771360029\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.10442406536661558 TEST LOSS: 0.054573820007156326\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.10639912483754145 TEST LOSS: 0.05210033724320523\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.0962656119043298 TEST LOSS: 0.05360543884423047\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.10047649413962935 TEST LOSS: 0.05209132747867659\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.07881395041381913 TEST LOSS: 0.0550420779893235\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.09456204802271719 TEST LOSS: 0.05289810243545996\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.10021154566582677 TEST LOSS: 0.055394925898405965\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001781332E630>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.19843562452771688 TEST LOSS: 0.28305904365256745\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.19843562452771688 TEST LOSS: 0.28305904365256745\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.19843562452771688 TEST LOSS: 0.28305904365256745\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.19843562452771688 TEST LOSS: 0.28305904365256745\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.19843562452771688 TEST LOSS: 0.28305904365256745\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.19843562452771688 TEST LOSS: 0.28305904365256745\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.19843562452771688 TEST LOSS: 0.28305904365256745\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.19843562452771688 TEST LOSS: 0.26954436302163703\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.17154726270818504 TEST LOSS: 0.18994351922943467\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.14797801536328034 TEST LOSS: 0.16685049653426903\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.12988811923246765 TEST LOSS: 0.17252052363809084\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.1177585219550712 TEST LOSS: 0.14487528464807473\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.10344680317656674 TEST LOSS: 0.12182275506124168\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.10703688724763064 TEST LOSS: 0.12492222093354773\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.09642975147980792 TEST LOSS: 0.11214385276831547\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.08771348155101978 TEST LOSS: 0.10710778435356062\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.09409723283806788 TEST LOSS: 0.11688551062068284\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.08112205243843036 TEST LOSS: 0.09522384219737302\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.0796821542599354 TEST LOSS: 0.1000530906223752\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.08915516899352147 TEST LOSS: 0.10756508238384346\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.07959519951986033 TEST LOSS: 0.09554334538048392\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.07834398581038197 TEST LOSS: 0.09214916654922269\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.06977496976660777 TEST LOSS: 0.08412009204330431\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.06566238867411348 TEST LOSS: 0.07337842298304334\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.06788567191379051 TEST LOSS: 0.08482177759345294\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.06559865920171101 TEST LOSS: 0.08483387575885966\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.06877678096251352 TEST LOSS: 0.08988136142381233\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.06438346840201584 TEST LOSS: 0.084840052687677\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.0656559445129178 TEST LOSS: 0.089200880244676\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.061619249889278915 TEST LOSS: 0.08081863715454492\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.06002192440432001 TEST LOSS: 0.08230912184004856\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.05620200927293881 TEST LOSS: 0.07539291568051448\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.06068071224440481 TEST LOSS: 0.08376092976466545\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.059340385555123075 TEST LOSS: 0.08167918094483936\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.055168509222569266 TEST LOSS: 0.075071966741319\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.05306872692329276 TEST LOSS: 0.07578539302325073\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.056839706328586856 TEST LOSS: 0.0815068443049316\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.05898973481863596 TEST LOSS: 0.08327778156371635\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.05465284895583411 TEST LOSS: 0.08446747412957203\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.052187289984084735 TEST LOSS: 0.07768176307240372\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.05440089030769133 TEST LOSS: 0.08142745719354084\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.05102236335914936 TEST LOSS: 0.07393861460329447\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.05170548759862966 TEST LOSS: 0.07769675123579672\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.05382485534189478 TEST LOSS: 0.07882429494973214\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.05430078738438151 TEST LOSS: 0.08675738459140285\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.05256103027598638 TEST LOSS: 0.08616402234837522\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.053665128585782186 TEST LOSS: 0.08376117909192905\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.05776546351228494 TEST LOSS: 0.08658152146979484\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.05168005789939914 TEST LOSS: 0.07634099172226481\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.050331315000561413 TEST LOSS: 0.06804791935590107\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.05411242961203957 TEST LOSS: 0.08196871625494824\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000017810DCAEB8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.25218769204247576 TEST LOSS: 0.31489159875474454\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.23490488520123376 TEST LOSS: 0.20317084075420128\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.21638381908892818 TEST LOSS: 0.18271616686097908\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.18768163230999865 TEST LOSS: 0.18272045771011722\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.1715242759280534 TEST LOSS: 0.1538453831139586\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.16783026665513864 TEST LOSS: 0.1598914628489121\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.16886819807780884 TEST LOSS: 0.1416991359446439\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.15597432948891657 TEST LOSS: 0.1333209923529317\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.15511982374982147 TEST LOSS: 0.13303601035679552\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.14613934977441312 TEST LOSS: 0.1269986288680061\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.14552556724214483 TEST LOSS: 0.11929064534643749\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.13614991185228054 TEST LOSS: 0.11992777875059808\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.14062817587596557 TEST LOSS: 0.11978395899843751\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.1362250953842347 TEST LOSS: 0.12261308612643636\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.12935637735974417 TEST LOSS: 0.1218972206644237\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.13167543431033346 TEST LOSS: 0.11479476941712197\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.127111988243332 TEST LOSS: 0.12997852859304188\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.11969659278889339 TEST LOSS: 0.1187708625691031\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.11762351794994491 TEST LOSS: 0.1085137831408406\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.11393140265394057 TEST LOSS: 0.1039672084746826\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.11598660151647233 TEST LOSS: 0.09780970765599693\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.10711538429084413 TEST LOSS: 0.11184312852944384\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.1105492530494288 TEST LOSS: 0.10605491348388146\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.10884119587821182 TEST LOSS: 0.11783479278026551\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.10786370371367716 TEST LOSS: 0.10468758538501678\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.10122602543775053 TEST LOSS: 0.10034298939433375\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.10679159191848354 TEST LOSS: 0.09956231280817529\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.10162062644340075 TEST LOSS: 0.10412748241131205\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.10457796775981933 TEST LOSS: 0.10100254743509\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.09791674811994754 TEST LOSS: 0.10258661500673781\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.10479007839549342 TEST LOSS: 0.09196825406965395\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.09591343124716481 TEST LOSS: 0.10111739814845419\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.09103869917552385 TEST LOSS: 0.10941379413997478\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.09744740054605679 TEST LOSS: 0.09537434936235484\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.09787090084970658 TEST LOSS: 0.09566255589029896\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.09384513134367839 TEST LOSS: 0.09979398988109738\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.09511863877956268 TEST LOSS: 0.09956975636199404\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.09747529566285167 TEST LOSS: 0.0926489940399402\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.1024621161104343 TEST LOSS: 0.08229922275168544\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.09180622345471996 TEST LOSS: 0.10057764043500461\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.09576688838660481 TEST LOSS: 0.09749728739517893\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.0939211108753981 TEST LOSS: 0.097612708474341\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.09589105243212148 TEST LOSS: 0.08576684800141786\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.08943735141173441 TEST LOSS: 0.10166714562003534\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.09126892737989545 TEST LOSS: 0.0968405949916624\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.09695497201032474 TEST LOSS: 0.08406793760805936\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.09329936288714759 TEST LOSS: 0.09892288529855932\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.09751061412022978 TEST LOSS: 0.08643603034440843\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.09663209259692412 TEST LOSS: 0.0975451694834308\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.09485362224018373 TEST LOSS: 0.10271829270704404\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.0977809437881577 TEST LOSS: 0.09146983148109385\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001781332EF98>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.2776507939032904 TEST LOSS: 0.259069011554836\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.2173866259182569 TEST LOSS: 0.18463633538343222\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.2188310572696511 TEST LOSS: 0.18572271744710764\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.18897887911612873 TEST LOSS: 0.16819391899233965\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.1610863326832278 TEST LOSS: 0.12919050868211612\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.156248556130931 TEST LOSS: 0.11606042198767469\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.14304171688882752 TEST LOSS: 0.10482412718806441\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.13132788861054118 TEST LOSS: 0.10546602330698417\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.13460307109930314 TEST LOSS: 0.10387718820846427\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.12233569633406177 TEST LOSS: 0.09566473666554581\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.11983721796754018 TEST LOSS: 0.09097383034526717\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.1271245855261384 TEST LOSS: 0.10629187018774225\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.12143523435129575 TEST LOSS: 0.09176026765530337\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.11717776609498531 TEST LOSS: 0.09049811561129019\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.11572114203925708 TEST LOSS: 0.089933283031556\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.10959052275204922 TEST LOSS: 0.07919453276359154\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.1119120966611328 TEST LOSS: 0.08501357036348599\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.10589133367642373 TEST LOSS: 0.08040616733734675\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.10343702426649175 TEST LOSS: 0.0803390960013697\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.1102553382337323 TEST LOSS: 0.08024030412927438\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.10763852077958348 TEST LOSS: 0.07726046508647821\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.10665041098791815 TEST LOSS: 0.08375541668983824\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.09939607779398744 TEST LOSS: 0.07785005588993878\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.0959552738276553 TEST LOSS: 0.07262734994285852\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.09285191094525765 TEST LOSS: 0.07487710912375585\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.10340311696041747 TEST LOSS: 0.08048773425919925\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.09737114532287114 TEST LOSS: 0.07589624379562293\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.10281756356306923 TEST LOSS: 0.08464114080214838\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.09988549608761138 TEST LOSS: 0.0779939208432673\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.09834350885154007 TEST LOSS: 0.08125158065924508\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.0886060395160051 TEST LOSS: 0.0729023105873294\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.09736439560748829 TEST LOSS: 0.08246704496163901\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.09644499786570401 TEST LOSS: 0.0829911804755316\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.08795146750229196 TEST LOSS: 0.06793693647481652\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.0895732384552926 TEST LOSS: 0.07596152073436424\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.08990627361616332 TEST LOSS: 0.07605235259324247\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.08713547239189984 TEST LOSS: 0.07807857650618127\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.09019233133942771 TEST LOSS: 0.08095422290844573\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.08668593628935516 TEST LOSS: 0.07436732970175632\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.08893476234326499 TEST LOSS: 0.07465556222215747\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.09352707464718987 TEST LOSS: 0.08088231487020744\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.08495778623606819 TEST LOSS: 0.07226595524831624\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.08923203673110677 TEST LOSS: 0.07662082709770875\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.08529562349827603 TEST LOSS: 0.0777114023822379\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.09230918904419584 TEST LOSS: 0.08157388678116811\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.08998844003601122 TEST LOSS: 0.08315341805313797\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.08710154114301782 TEST LOSS: 0.08117247077421288\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.0874221184136259 TEST LOSS: 0.07740250782122182\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.08558328312670102 TEST LOSS: 0.07585719072880055\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.09065156998372727 TEST LOSS: 0.07767894835069956\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.09056907478784715 TEST LOSS: 0.08368133709480505\n",
      "0.08228635510861651 0.07405057232791461\n",
      "COMPUTING FOR ITERATION NUMBER 2\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000017810DC4160>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.34771521342599643 TEST LOSS: 0.24902257601283662\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.3508336656905409 TEST LOSS: 0.2530984567223699\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.2890461661062756 TEST LOSS: 0.23903319282450602\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.2173790084557351 TEST LOSS: 0.1695189275944319\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.2129853554000664 TEST LOSS: 0.14478701276389855\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.20558126850561873 TEST LOSS: 0.13751528353263834\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.18653917504259293 TEST LOSS: 0.12341584227429693\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.1795914654230619 TEST LOSS: 0.1188806374084145\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.16103459885427898 TEST LOSS: 0.10510221895512331\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.14084941262447334 TEST LOSS: 0.09228823567008199\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.14990138206076642 TEST LOSS: 0.0918323553274689\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.14133033776585294 TEST LOSS: 0.0918989470330771\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.15302471625001907 TEST LOSS: 0.09524679118264388\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.14746551482708858 TEST LOSS: 0.0909444671722669\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.1275613133817544 TEST LOSS: 0.08465035440738668\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.1415464191957203 TEST LOSS: 0.08341853633809071\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.12996754602430025 TEST LOSS: 0.0846940953744129\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.13336755807111286 TEST LOSS: 0.08368997164415709\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.1314395342171922 TEST LOSS: 0.08548718675698451\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.13774019951190844 TEST LOSS: 0.08599215475795952\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.12835618839169818 TEST LOSS: 0.07739804060142243\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.12195323494093825 TEST LOSS: 0.08331431998237264\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.1372341599922207 TEST LOSS: 0.07940682648168085\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.13415317169326096 TEST LOSS: 0.08134244454860054\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.12038112152866058 TEST LOSS: 0.0766202002289005\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.12340688741187339 TEST LOSS: 0.07675719228943112\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.1272109123021605 TEST LOSS: 0.07998437583285324\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.12204948206675988 TEST LOSS: 0.07783442401935745\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.12850701261380804 TEST LOSS: 0.07565921991604829\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.1147096452264179 TEST LOSS: 0.07508006919422198\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.1301279801848799 TEST LOSS: 0.08081179763707018\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.12024085475955719 TEST LOSS: 0.08049059348032941\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.13095319646394984 TEST LOSS: 0.08197171205895278\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.12040999106449195 TEST LOSS: 0.07811875684316172\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.13197775524085362 TEST LOSS: 0.07943334609735156\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.11624777175591254 TEST LOSS: 0.07489636975681224\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.12363710387630227 TEST LOSS: 0.07845702592859105\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.11379680517680749 TEST LOSS: 0.07779309660563735\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.12641960431763855 TEST LOSS: 0.07946675534446418\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.11903520922910421 TEST LOSS: 0.08109559491409844\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.1088374321819387 TEST LOSS: 0.07522553683836475\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.11565675537360982 TEST LOSS: 0.07661563420067143\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.11321105461404496 TEST LOSS: 0.0773891537817937\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.12224518319458585 TEST LOSS: 0.07996126708155289\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.12381924699860809 TEST LOSS: 0.07944598504039084\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.14373106202939864 TEST LOSS: 0.08625360008528699\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.12131697302862046 TEST LOSS: 0.07903906751056015\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.12885271053576056 TEST LOSS: 0.07910770138695238\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.11442868635823222 TEST LOSS: 0.07834384205460043\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.1296721532411589 TEST LOSS: 0.08129075288750823\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.1241007970636031 TEST LOSS: 0.07884746419524025\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001781189F710>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.22970029286896596 TEST LOSS: 0.20959566988348868\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.1930188414471174 TEST LOSS: 0.21445375289132432\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.17771509119342307 TEST LOSS: 0.19576206257137904\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.1738312423331249 TEST LOSS: 0.1688796298106324\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.15760520481081652 TEST LOSS: 0.14531866229074522\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.15736174613071555 TEST LOSS: 0.14123997061566823\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.13545396078034713 TEST LOSS: 0.14394850654986405\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.12240920885823044 TEST LOSS: 0.11404725349002065\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.1261447971103688 TEST LOSS: 0.11696981556021274\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.12883480609136033 TEST LOSS: 0.11003704381567347\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.11635261226550225 TEST LOSS: 0.10425846997752332\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.10121287106424959 TEST LOSS: 0.08363835882512727\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.11856393869753963 TEST LOSS: 0.10585966380238655\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.10421877404461657 TEST LOSS: 0.07877384913124268\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.1001745090682302 TEST LOSS: 0.08701948321848149\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.10836772086593474 TEST LOSS: 0.079903590393558\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.10462421191656239 TEST LOSS: 0.086411321973514\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.1024633096586979 TEST LOSS: 0.08214557319744312\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.09477107065733266 TEST LOSS: 0.08885515057010145\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.08758032925321164 TEST LOSS: 0.07837339103592715\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.08567869459544615 TEST LOSS: 0.07877158454849685\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.08191188958171337 TEST LOSS: 0.0740110319887961\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.08493508298945632 TEST LOSS: 0.07036569352115868\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.08060023911924522 TEST LOSS: 0.07315851238421882\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.08766409071308019 TEST LOSS: 0.07639131450289578\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.07877255758027099 TEST LOSS: 0.07882060608833186\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.08457591013380675 TEST LOSS: 0.07299920988171606\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.0831502583176268 TEST LOSS: 0.07328550424957939\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.08394309408367785 TEST LOSS: 0.07177932308684055\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.08715510314670623 TEST LOSS: 0.07507019922327106\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.08666326710649151 TEST LOSS: 0.07287352972441055\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.08204206647263589 TEST LOSS: 0.07301626579401349\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.07856763711082355 TEST LOSS: 0.07160415982874425\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.08147865398550562 TEST LOSS: 0.06993836063630254\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.07793421228762022 TEST LOSS: 0.06783720703762798\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.07907975196579115 TEST LOSS: 0.06890086981606897\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.07818751859346455 TEST LOSS: 0.06581040530640839\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.07649851572499775 TEST LOSS: 0.06758804317720583\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.08245318435564726 TEST LOSS: 0.06690921930487019\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.07665664062209095 TEST LOSS: 0.06722072771405789\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.07910234848970796 TEST LOSS: 0.06866035590884449\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.07805493898382553 TEST LOSS: 0.06866093378227843\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.07674479617010968 TEST LOSS: 0.07122481640596999\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.07944677541929993 TEST LOSS: 0.0670276010148102\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.07776376787976388 TEST LOSS: 0.06644172906793037\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.07989391073520392 TEST LOSS: 0.06874757898401736\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.08055568438721268 TEST LOSS: 0.0740553094949098\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.07742730143010115 TEST LOSS: 0.07775255047218067\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.08035619504861964 TEST LOSS: 0.07302792710502005\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.07902956194031496 TEST LOSS: 0.07108806493528559\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.07750212436359794 TEST LOSS: 0.07057246531038795\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000017810E63E10>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.17260803996347354 TEST LOSS: 0.2335429061750502\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.1691436238052219 TEST LOSS: 0.22113430292844197\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.1648597289472698 TEST LOSS: 0.21951649972145074\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.16282057326799912 TEST LOSS: 0.20471209040267221\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.14892995589533145 TEST LOSS: 0.16323983787169954\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.12277613807968923 TEST LOSS: 0.13865284867249625\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.10898796098280819 TEST LOSS: 0.1336599175201588\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.11028366041986302 TEST LOSS: 0.13421479096688793\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.10582385037237262 TEST LOSS: 0.1242336060936779\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.11304953950188669 TEST LOSS: 0.13178290913520846\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.10197124711358678 TEST LOSS: 0.11819333798419562\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.10314434505276823 TEST LOSS: 0.1194511392283344\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.09767554999247383 TEST LOSS: 0.10773359902914938\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.09147178679558642 TEST LOSS: 0.1060994782510369\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.0904364965217707 TEST LOSS: 0.09856453867600988\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.09301083616408912 TEST LOSS: 0.08700838608134062\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.09331339103848131 TEST LOSS: 0.1038208534735781\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.09764373669351771 TEST LOSS: 0.09219128827896765\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.09366711218586637 TEST LOSS: 0.09435655379176236\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.08924881779463154 TEST LOSS: 0.09468041961942969\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.0876312178745195 TEST LOSS: 0.07843708150905641\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.0837347838862106 TEST LOSS: 0.08056842094686976\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.08516304019842431 TEST LOSS: 0.07552525228003718\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.08413986058684547 TEST LOSS: 0.08265275664355735\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.0805462407280641 TEST LOSS: 0.08215399239075534\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.07898869655398622 TEST LOSS: 0.07353917092277522\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.0801686891400381 TEST LOSS: 0.07102222542033874\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.08017558812788378 TEST LOSS: 0.07091924704628658\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.07906577575498237 TEST LOSS: 0.0711080863228224\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.08267788708036856 TEST LOSS: 0.07096572433682012\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.07329770337879254 TEST LOSS: 0.06617269182664745\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.07422317225138572 TEST LOSS: 0.06541873751912514\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.0749468470778957 TEST LOSS: 0.06702234118747133\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.07489089939219917 TEST LOSS: 0.06981286956614165\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.07694158925670226 TEST LOSS: 0.06649359608002284\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.07327344656410296 TEST LOSS: 0.06522202214334923\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.0738606585116118 TEST LOSS: 0.06747711804675259\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.07274839036097265 TEST LOSS: 0.0679748710778658\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.07276853647053372 TEST LOSS: 0.06888072364839304\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.07273651663149036 TEST LOSS: 0.06480402328793174\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.07072103994632642 TEST LOSS: 0.06309440518264645\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.06928267844797922 TEST LOSS: 0.06553087076273498\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.07153860813106692 TEST LOSS: 0.06503524182016408\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.0732533751321665 TEST LOSS: 0.06770742754823261\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.07229385351416814 TEST LOSS: 0.06907575898481977\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.07123234856664468 TEST LOSS: 0.0665948484511808\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.07012151029213101 TEST LOSS: 0.06844821736330654\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.07214955813649933 TEST LOSS: 0.0728381688252697\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.07155608734766182 TEST LOSS: 0.06670815036258544\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.07003910650504559 TEST LOSS: 0.0651599220824356\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.07037401829953607 TEST LOSS: 0.06615817267333489\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000017810E3C4E0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.19678246444464662 TEST LOSS: 0.2884863382850839\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.18339330732499257 TEST LOSS: 0.2626465739006678\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.1710583499024063 TEST LOSS: 0.23691103310648148\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.147667654116768 TEST LOSS: 0.19484555178264804\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.13509228870725157 TEST LOSS: 0.18250228276811334\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.1258029455167216 TEST LOSS: 0.15357856156086894\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.11818925374800393 TEST LOSS: 0.14859211932122685\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.10794003740454058 TEST LOSS: 0.14126685302520334\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.10172417337510327 TEST LOSS: 0.13252587999320525\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.09644719465196883 TEST LOSS: 0.12233418634245223\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.09043737844159869 TEST LOSS: 0.11806323151624995\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.09699673759204518 TEST LOSS: 0.12329229408392806\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.09780614938502283 TEST LOSS: 0.12321694362227624\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.08854964819928475 TEST LOSS: 0.10547644861483489\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.08630787253264098 TEST LOSS: 0.10946960013022572\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.07757691146541898 TEST LOSS: 0.09627173303823239\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.07439920729869479 TEST LOSS: 0.09525734937967448\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.07768478505650553 TEST LOSS: 0.10049183124288535\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.07692290763181935 TEST LOSS: 0.09678987610758026\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.07433184934643679 TEST LOSS: 0.09827909469936826\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.06360219264162587 TEST LOSS: 0.08231923865339386\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.06457663635520004 TEST LOSS: 0.08611678232917327\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.06363692419500026 TEST LOSS: 0.08737937376745827\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.06802888858605882 TEST LOSS: 0.08659286948378535\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.060665245068966554 TEST LOSS: 0.06951495563660434\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.058498303568163414 TEST LOSS: 0.07812595010886342\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.05409024775503493 TEST LOSS: 0.07401761803564658\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.05089049496083337 TEST LOSS: 0.07377543112139139\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.061610903528456926 TEST LOSS: 0.08105999061366584\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.06348688715319588 TEST LOSS: 0.08348343400266918\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.055659430736284696 TEST LOSS: 0.07439639942557452\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.05555317551091887 TEST LOSS: 0.07644496716913429\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.048961790902244035 TEST LOSS: 0.07480187393139204\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.05719987752786739 TEST LOSS: 0.08339855932559287\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.05554223350931035 TEST LOSS: 0.07179355672254978\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.06088657663561017 TEST LOSS: 0.08897598160834096\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.05567612291369031 TEST LOSS: 0.0777781236827312\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.057751185702704336 TEST LOSS: 0.08428255425179745\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.057231257504427833 TEST LOSS: 0.07942604624181755\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.06280169807679004 TEST LOSS: 0.0840504310166384\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.055092725434513455 TEST LOSS: 0.07834004500517767\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.05622476326521066 TEST LOSS: 0.08661737390565223\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.061839765349132964 TEST LOSS: 0.09468989224698218\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.061885698597690365 TEST LOSS: 0.08889027162764637\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.0578766691665483 TEST LOSS: 0.08381415985441974\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.06383280802897374 TEST LOSS: 0.08359915988549672\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.05668951909386281 TEST LOSS: 0.07996044180060373\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.05448893471133943 TEST LOSS: 0.07555337887777436\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.05666931239630921 TEST LOSS: 0.07622701087830862\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.05701226063455517 TEST LOSS: 0.07141811169734495\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.062092604205869185 TEST LOSS: 0.08973955639518687\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000017810D81DD8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.24455658995080973 TEST LOSS: 0.3581852030972173\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.24706585127467132 TEST LOSS: 0.3539058489112373\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.24706585127467132 TEST LOSS: 0.3539058489112373\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.2321504204494843 TEST LOSS: 0.3495234831800816\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.15144750105244972 TEST LOSS: 0.20213755765030345\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.1519910529191175 TEST LOSS: 0.145618266829515\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.15038070238099158 TEST LOSS: 0.1857832031585814\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.1363277610966391 TEST LOSS: 0.174023400955722\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.12456934443000106 TEST LOSS: 0.1714588308144595\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.12108702941367494 TEST LOSS: 0.14967314989040464\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.12176714086255944 TEST LOSS: 0.15032101562898337\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.11217515253795275 TEST LOSS: 0.1338526909620975\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.12113614473506275 TEST LOSS: 0.11649282360902827\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.1151228052905972 TEST LOSS: 0.1339798893157667\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.10906288597990992 TEST LOSS: 0.1337847186569838\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.10795441859736375 TEST LOSS: 0.13309193713182643\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.11371319956446671 TEST LOSS: 0.0988339737975343\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.10491350040412324 TEST LOSS: 0.11830421925265996\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.11120908275100352 TEST LOSS: 0.11477304024103466\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.10587361268242926 TEST LOSS: 0.11057434401851132\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.09757695218647838 TEST LOSS: 0.10603445103123227\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.08767074434613388 TEST LOSS: 0.12214187253238472\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.09874222364667168 TEST LOSS: 0.1180498033822772\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.09410337176595544 TEST LOSS: 0.11653306390292302\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.09290791020529043 TEST LOSS: 0.10030731526192893\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.0869540710960556 TEST LOSS: 0.10205840782172744\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.08983127587329752 TEST LOSS: 0.10417077570535344\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.09229174185538078 TEST LOSS: 0.1189297776161005\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.08787421608356565 TEST LOSS: 0.10930745127765568\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.08883890177264031 TEST LOSS: 0.10675103914953149\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.0921118255450089 TEST LOSS: 0.09498310981733961\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.0952908178448419 TEST LOSS: 0.09360169682396179\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.08407970564855582 TEST LOSS: 0.0992412108653443\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.0919032661660239 TEST LOSS: 0.0968228541908544\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.08017864150092242 TEST LOSS: 0.09939964210022263\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.0874475498791074 TEST LOSS: 0.09664542042364786\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.08845146534765744 TEST LOSS: 0.10660681242847414\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.08022436383073593 TEST LOSS: 0.09965649954591135\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.08258502769801296 TEST LOSS: 0.10185077628116772\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.08069203881896203 TEST LOSS: 0.09448033843329591\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.08732548015446143 TEST LOSS: 0.10205883357960956\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.07985899455885676 TEST LOSS: 0.10967611538880917\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.07895114555253151 TEST LOSS: 0.10284274217580741\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.08115148485609747 TEST LOSS: 0.1085306589952096\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.08032738261080424 TEST LOSS: 0.10364380162813298\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.08021911631377951 TEST LOSS: 0.10381151894336445\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.07903323840281792 TEST LOSS: 0.11831824927856753\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.07879659870867954 TEST LOSS: 0.11277059639167278\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.0791826272439311 TEST LOSS: 0.11591158482939376\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.07464744924542842 TEST LOSS: 0.10628321556630373\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.07825600365285314 TEST LOSS: 0.0947301623915055\n",
      "0.07389631046894196 0.07678516168457586\n",
      "COMPUTING FOR ITERATION NUMBER 3\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x00000178118C71D0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.2087625817986076 TEST LOSS: 0.23124266573823127\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.2090992033798145 TEST LOSS: 0.23131844487954753\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.20087297399057277 TEST LOSS: 0.2208391194541623\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.17954709444999878 TEST LOSS: 0.19807742471844036\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.18047260650415564 TEST LOSS: 0.19317247825326445\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.1572099196532777 TEST LOSS: 0.16920118803893508\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.15150433407054922 TEST LOSS: 0.16786096874074558\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.13888697734767547 TEST LOSS: 0.14613465149270352\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.11129400368378296 TEST LOSS: 0.11933031125798052\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.10421020161459074 TEST LOSS: 0.11471838266061794\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.10737960650939615 TEST LOSS: 0.12281724467555107\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.10018310732898646 TEST LOSS: 0.11648457939165309\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.10050544528960118 TEST LOSS: 0.1135247019931087\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.09733558378492507 TEST LOSS: 0.11529251362063375\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.10041046285511182 TEST LOSS: 0.11228396027240532\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.09436654956754052 TEST LOSS: 0.11618602275652286\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.09138398547618651 TEST LOSS: 0.10640122982898141\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.0936578292045208 TEST LOSS: 0.1089187987233794\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.09285620984377298 TEST LOSS: 0.10307927081129933\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.09369494228889363 TEST LOSS: 0.10282156180774012\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.0910142900630023 TEST LOSS: 0.09409449197103292\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.09166735757228124 TEST LOSS: 0.09710363067081619\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.09299175606646963 TEST LOSS: 0.1006211093116304\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.08624424780202036 TEST LOSS: 0.09124880518132612\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.08670709991336713 TEST LOSS: 0.0956414109636795\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.08614590641939486 TEST LOSS: 0.09541168370856656\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.08545869719550388 TEST LOSS: 0.08876543908741787\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.0859119715875071 TEST LOSS: 0.08906670650664762\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.08186461312292992 TEST LOSS: 0.08475980683099249\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.08268527549658716 TEST LOSS: 0.08862651544436113\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.07804655472532322 TEST LOSS: 0.08075093726642531\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.07972850596554494 TEST LOSS: 0.08644550875189647\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.08607310468199413 TEST LOSS: 0.09205722529328265\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.07932173716475709 TEST LOSS: 0.08807363043331445\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.07909772826243452 TEST LOSS: 0.0829678742718963\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.07669141939906655 TEST LOSS: 0.08553281603232485\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.08158208718474821 TEST LOSS: 0.09131710412673667\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.08274668309807122 TEST LOSS: 0.09195055160786833\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.07763128519632984 TEST LOSS: 0.08417657887245085\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.07360118601649598 TEST LOSS: 0.0831664476859756\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.07339340083150481 TEST LOSS: 0.08093385266470236\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.07664025541506812 TEST LOSS: 0.08447896652495769\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.08056493629357869 TEST LOSS: 0.08679652157937881\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.0869164772060177 TEST LOSS: 0.09551281158204133\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.07681695816288421 TEST LOSS: 0.08102638012860718\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.08028260766176945 TEST LOSS: 0.09131071500315006\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.07971823669419285 TEST LOSS: 0.08286538555239292\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.0759724244512864 TEST LOSS: 0.08170173410514014\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.0773634432233076 TEST LOSS: 0.078346392512602\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.07980567946601279 TEST LOSS: 0.0858591565557893\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.07940549158450357 TEST LOSS: 0.08754300403843994\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001781189F588>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.2770864674725949 TEST LOSS: 0.2869260211883605\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.26282011886508544 TEST LOSS: 0.27714020486336705\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.26282011886508544 TEST LOSS: 0.27714020486336705\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.26282011886508544 TEST LOSS: 0.27714020486336705\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.2501719785266877 TEST LOSS: 0.2672391277002922\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.21874517393590875 TEST LOSS: 0.21863737386956317\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.1799868179120177 TEST LOSS: 0.20683979693108648\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.1534981738567105 TEST LOSS: 0.16746592820696238\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.15094550815828567 TEST LOSS: 0.18085850093404884\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.15819020582935067 TEST LOSS: 0.16199088978679174\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.14853919124385737 TEST LOSS: 0.14942944698025162\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.11860459204375187 TEST LOSS: 0.13417414512546488\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.1178640516179219 TEST LOSS: 0.14350873315092866\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.10889953519554144 TEST LOSS: 0.11879017864455049\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.09711401277310636 TEST LOSS: 0.12222630001296353\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.09726921905155844 TEST LOSS: 0.12242058858780393\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.09611255861838294 TEST LOSS: 0.11884670730145834\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.0960602170777049 TEST LOSS: 0.1125671040195305\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.09923598405671029 TEST LOSS: 0.10836323689299045\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.08786042548495966 TEST LOSS: 0.0995414413606873\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.08911666740010153 TEST LOSS: 0.10566146600699813\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.09092758882751674 TEST LOSS: 0.1000101623399103\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.09232393096121239 TEST LOSS: 0.11233201573201823\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.09081412089832729 TEST LOSS: 0.10081495225139209\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.08928812441301247 TEST LOSS: 0.10028698478549626\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.08929533225459282 TEST LOSS: 0.10551343199942889\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.08308904591995803 TEST LOSS: 0.09684672301689912\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.07954419247716281 TEST LOSS: 0.09406797296185315\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.07565851631209677 TEST LOSS: 0.09071116564504056\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.08497851220604473 TEST LOSS: 0.09766149957723261\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.08044050874529098 TEST LOSS: 0.09063066956505013\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.07890998173483879 TEST LOSS: 0.09008166211501971\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.0787505555734355 TEST LOSS: 0.0935938436733743\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.07995020250186893 TEST LOSS: 0.09040440535937265\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.06764428523315649 TEST LOSS: 0.08367878775562344\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.0758864327902464 TEST LOSS: 0.08546693618300645\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.06935466945645839 TEST LOSS: 0.09025096211125602\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.06483428470740793 TEST LOSS: 0.0799597938536893\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.07084306864680726 TEST LOSS: 0.08151182853294624\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.07554068602692247 TEST LOSS: 0.08920228077819461\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.0638465530028129 TEST LOSS: 0.08444808694080416\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.07439230197181805 TEST LOSS: 0.09167074331741355\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.06310340690220158 TEST LOSS: 0.08586935653008909\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.06665639231780963 TEST LOSS: 0.08036550510639093\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.0648061784063658 TEST LOSS: 0.08158112747518118\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.07023267908422638 TEST LOSS: 0.08809262604410269\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.06619751907585848 TEST LOSS: 0.08137393770204808\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.06028073752471057 TEST LOSS: 0.07887326267685842\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.06310667442507002 TEST LOSS: 0.08244654272320008\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.06436976935405614 TEST LOSS: 0.08135289337645954\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.06699497036780112 TEST LOSS: 0.08502260982963024\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x00000178117DF0F0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.1656053670249546 TEST LOSS: 0.2765850319533865\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.16186988434698407 TEST LOSS: 0.2396180879392269\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.1435469442324417 TEST LOSS: 0.2083810273474642\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.14055608224754015 TEST LOSS: 0.1976112683392586\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.13905841529081514 TEST LOSS: 0.17470591038442862\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.13458562277546418 TEST LOSS: 0.17171559160666636\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.1301871490625652 TEST LOSS: 0.14503039558065464\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.12888798835024587 TEST LOSS: 0.13665864997270122\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.1183442768244846 TEST LOSS: 0.13241831704289497\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.11694453283411231 TEST LOSS: 0.12676543454543202\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.10750064355581093 TEST LOSS: 0.12080620271071961\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.10452652302486065 TEST LOSS: 0.12272529867696222\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.10007636977944405 TEST LOSS: 0.1205267318964823\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.10370935298699195 TEST LOSS: 0.1251501672198138\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.09444925708527609 TEST LOSS: 0.12025692282667202\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.08304478728486697 TEST LOSS: 0.11142317480607694\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.09237227734465218 TEST LOSS: 0.11814845702400079\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.09054358919985503 TEST LOSS: 0.11347235187524225\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.08432026107838275 TEST LOSS: 0.11708473483472022\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.07489437992507898 TEST LOSS: 0.10875641900517391\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.07646691943663687 TEST LOSS: 0.1049041941401565\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.08201606004401552 TEST LOSS: 0.10492031812640201\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.07800975358941714 TEST LOSS: 0.10109262833516815\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.06148291388428344 TEST LOSS: 0.1000106053443784\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.06859453759302193 TEST LOSS: 0.09803023946051229\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.07464795434654266 TEST LOSS: 0.09913245032714597\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.06389032407533123 TEST LOSS: 0.0945402578485545\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.06438685355948026 TEST LOSS: 0.09508127123334721\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.06376009017125657 TEST LOSS: 0.0896333317934536\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.06033427258502248 TEST LOSS: 0.091632955561185\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.05731942879582026 TEST LOSS: 0.09314032238113813\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.05911973260523575 TEST LOSS: 0.09227838971303985\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.05595875960095068 TEST LOSS: 0.08767033383124125\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.05760670872637214 TEST LOSS: 0.09140946920360435\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.05833371959937649 TEST LOSS: 0.09004602394511407\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.05556967564528556 TEST LOSS: 0.08751725326506062\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.05556842308775365 TEST LOSS: 0.09179284031004281\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.05715842320504545 TEST LOSS: 0.08729555201079597\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.054678235551465115 TEST LOSS: 0.09045080421610802\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.05587496908001587 TEST LOSS: 0.08229157773352287\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.055245081940524306 TEST LOSS: 0.08613379868103731\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.05293535779497579 TEST LOSS: 0.09418911019785496\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.05218117576058797 TEST LOSS: 0.08625297430895719\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.05481924914151711 TEST LOSS: 0.08934879043314474\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.05354723261994024 TEST LOSS: 0.08833338216629605\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.05679026270186537 TEST LOSS: 0.09400462323862577\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.055022969544911954 TEST LOSS: 0.08592293806394169\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.055705683007558855 TEST LOSS: 0.0980834660643936\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.05402937479721016 TEST LOSS: 0.0892760149656776\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.0545743483572367 TEST LOSS: 0.08967029922929531\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.053538008803289745 TEST LOSS: 0.09457737654375763\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000017810E63CF8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.3198228256291299 TEST LOSS: 0.2941848763083966\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.2517888093014987 TEST LOSS: 0.215386253106806\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.22241218003215807 TEST LOSS: 0.17555782008532914\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.2029060816838275 TEST LOSS: 0.1694339491703144\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.18741017938848245 TEST LOSS: 0.15813031616324963\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.14492880422124602 TEST LOSS: 0.1612122211854223\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.12258935172423346 TEST LOSS: 0.14484398819558686\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.13385661819545303 TEST LOSS: 0.14686762923784835\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.1213874116805818 TEST LOSS: 0.14333750968279732\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.12449529727136624 TEST LOSS: 0.13720693692990701\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.11154168241326393 TEST LOSS: 0.13617798587673186\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.10788562377927224 TEST LOSS: 0.12990415976653152\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.09640438505044524 TEST LOSS: 0.11328375884148661\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.10147498157081067 TEST LOSS: 0.12265833356402331\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.10409601588724822 TEST LOSS: 0.12278437802710701\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.09431836412223024 TEST LOSS: 0.10887064034230516\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.0880088274694493 TEST LOSS: 0.10689341327945025\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.0949374978769393 TEST LOSS: 0.10646035887632456\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.09303069131521452 TEST LOSS: 0.10434916585829206\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.08940151407390759 TEST LOSS: 0.10047968343502321\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.08584107189962042 TEST LOSS: 0.106386668266226\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.08625923143663766 TEST LOSS: 0.0963815886811879\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.07842013502416492 TEST LOSS: 0.09057008770097429\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.07924598434253126 TEST LOSS: 0.09365808418672751\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.09328743180278004 TEST LOSS: 0.10837412554232673\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.1017846826538915 TEST LOSS: 0.11049355936972027\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.09295570459303441 TEST LOSS: 0.10749866591711288\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.08234382795611372 TEST LOSS: 0.09347352348402571\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.08667463923619262 TEST LOSS: 0.09519225107943056\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.08011475471373723 TEST LOSS: 0.09212854467481556\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.07958770956444025 TEST LOSS: 0.08716787550931857\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.07986336394218202 TEST LOSS: 0.09121262715610287\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.0948847387767702 TEST LOSS: 0.1013637278131711\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.07608278305089672 TEST LOSS: 0.08686984058173852\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.09451358218014423 TEST LOSS: 0.102316842665832\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.09009007150378405 TEST LOSS: 0.09959663268940537\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.09405027637820927 TEST LOSS: 0.09442119513817156\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.08345132923769566 TEST LOSS: 0.08953256814350172\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.09240668823337134 TEST LOSS: 0.096330757807886\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.09033885776690236 TEST LOSS: 0.09718579944425919\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.09878936870876372 TEST LOSS: 0.0994314966716253\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.09310235520793184 TEST LOSS: 0.09228411940078338\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.08544826789646215 TEST LOSS: 0.0975394778306139\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.08183007212751367 TEST LOSS: 0.08595723271408506\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.09149909543709851 TEST LOSS: 0.10066367301582896\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.07935364299056503 TEST LOSS: 0.08660015364008743\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.08638368676014305 TEST LOSS: 0.08692800746894913\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.09198298190669947 TEST LOSS: 0.09211354737156274\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.09213792205225668 TEST LOSS: 0.09211204620377021\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.08990564870472814 TEST LOSS: 0.09320085861617819\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.10703995175223946 TEST LOSS: 0.10926306570043144\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x00000178117DF240>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.29331868365094943 TEST LOSS: 0.2228461585461679\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.27317891716783105 TEST LOSS: 0.22224663007493753\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.27317891716783105 TEST LOSS: 0.22224663007493753\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.27317891716783105 TEST LOSS: 0.22224663007493753\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.27317891716783105 TEST LOSS: 0.22224663007493753\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.20154437943751172 TEST LOSS: 0.18787247381479968\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.19282312520555356 TEST LOSS: 0.1862643371447629\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.1797323738085307 TEST LOSS: 0.16729262216434523\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.15830592315932437 TEST LOSS: 0.14757676943523096\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.14214514256216954 TEST LOSS: 0.13746473755075064\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.1499626643370549 TEST LOSS: 0.13419427987574553\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.1352800561657107 TEST LOSS: 0.13391329814977268\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.12396759862965977 TEST LOSS: 0.11737973837420405\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.11643123781304208 TEST LOSS: 0.11015587838660422\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.11726056790226724 TEST LOSS: 0.12128539455696544\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.1158840204130763 TEST LOSS: 0.11977427876776096\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.10414422565986725 TEST LOSS: 0.1109205700711747\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.10434968739277237 TEST LOSS: 0.10342720480388033\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.10215243740707243 TEST LOSS: 0.09875518639150155\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.10396601235577643 TEST LOSS: 0.09975784212633655\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.10205748443877752 TEST LOSS: 0.09853323559627535\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.099429781269113 TEST LOSS: 0.08833468965232082\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.09631942554607181 TEST LOSS: 0.09179946182203204\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.09823393476936716 TEST LOSS: 0.09285877093696072\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.09357437488995782 TEST LOSS: 0.08111550751354425\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.09474682282569549 TEST LOSS: 0.07561177292353471\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.08584380756945124 TEST LOSS: 0.06802720141075728\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.09524561016929073 TEST LOSS: 0.08566948446983662\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.08880121736527868 TEST LOSS: 0.07117327106375476\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.09412146559006689 TEST LOSS: 0.08019462181893017\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.09337113657684919 TEST LOSS: 0.0801556041554626\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.09437682486690756 TEST LOSS: 0.08161321923264743\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.07938756708697521 TEST LOSS: 0.07184888019159211\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.08222884648362294 TEST LOSS: 0.07597876413054475\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.08028209427364529 TEST LOSS: 0.07669795528780146\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.07767567871769072 TEST LOSS: 0.07771278595531986\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.07837608864024681 TEST LOSS: 0.08158772955576664\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.07409390486003277 TEST LOSS: 0.07188758655956258\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.07770041750658001 TEST LOSS: 0.07597598351100636\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.0776382679471635 TEST LOSS: 0.07485372750139486\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.07374066851133906 TEST LOSS: 0.0701510931055496\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.06922258938068573 TEST LOSS: 0.07334631995143458\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.06658872611130492 TEST LOSS: 0.06939149155868318\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.07554539089616681 TEST LOSS: 0.07365935031023645\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.08076108049314015 TEST LOSS: 0.07865956401794079\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.07949145419274097 TEST LOSS: 0.0823508806290545\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.0701677617335395 TEST LOSS: 0.07538039603918203\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.07232111502820093 TEST LOSS: 0.07777783489681502\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.06899095397738834 TEST LOSS: 0.07645091982214024\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.07055387466905547 TEST LOSS: 0.07372933283080141\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.07357598390656889 TEST LOSS: 0.07644645003841295\n",
      "0.06658872611130492 0.08048811467882791\n",
      "COMPUTING FOR ITERATION NUMBER 4\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000017810EFB0F0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.23618121098323958 TEST LOSS: 0.3121294872579429\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.22622315963167736 TEST LOSS: 0.3087126000635253\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.22622315963167736 TEST LOSS: 0.3087126000635253\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.22381302946862386 TEST LOSS: 0.19063707811833233\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.21254510337021568 TEST LOSS: 0.17469231859109066\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.20216524295704721 TEST LOSS: 0.15963293696937916\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.19465086011617072 TEST LOSS: 0.16136472411787056\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.1703910849809549 TEST LOSS: 0.15004386843960654\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.14904665678975126 TEST LOSS: 0.1327265128729696\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.14170004919785334 TEST LOSS: 0.1353388721870356\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.13279525559735517 TEST LOSS: 0.12135714603515545\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.13032982092471468 TEST LOSS: 0.12650299520129998\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.12422073295743297 TEST LOSS: 0.10330413316883828\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.12725514006748326 TEST LOSS: 0.12154613055421684\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.1245131478326884 TEST LOSS: 0.11082771898901213\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.12165377020575129 TEST LOSS: 0.11287566920731586\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.12914459090918148 TEST LOSS: 0.109199567469959\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.1244672464710074 TEST LOSS: 0.10820115495687235\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.11701063902975574 TEST LOSS: 0.10799205983601218\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.1144757842908152 TEST LOSS: 0.10450693376664144\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.12139898628994045 TEST LOSS: 0.09832582425007975\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.11324096387177719 TEST LOSS: 0.1044982185166361\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.11464398948969537 TEST LOSS: 0.09993026355155732\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.10917199708053528 TEST LOSS: 0.1014435439125511\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.10933537989732342 TEST LOSS: 0.08694313825234118\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.10532781682839529 TEST LOSS: 0.10287986374536603\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.10680504936117002 TEST LOSS: 0.09304542824221072\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.10859053430449538 TEST LOSS: 0.09322667477274366\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.10993894973246887 TEST LOSS: 0.10034895749836253\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.09733168655694038 TEST LOSS: 0.08647786011966066\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.09621448988883471 TEST LOSS: 0.08399489251506428\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.1030367050200428 TEST LOSS: 0.09111056682611476\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.10191534478966009 TEST LOSS: 0.09014121907911674\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.09761102037246709 TEST LOSS: 0.08821026669353321\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.09346672014183846 TEST LOSS: 0.07978282474204755\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.0933120090596625 TEST LOSS: 0.07928782666377256\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.0938124553151865 TEST LOSS: 0.078723122286753\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.09008322489129482 TEST LOSS: 0.08144344725656043\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.09056703804269166 TEST LOSS: 0.08014916382146779\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.08710757569341854 TEST LOSS: 0.09065553649352515\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.09075066029133869 TEST LOSS: 0.0822059630515378\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.09276985090490167 TEST LOSS: 0.0785289534543647\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.09625099303124224 TEST LOSS: 0.0932849165693019\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.08839373918664925 TEST LOSS: 0.07425456839024562\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.08963337769457443 TEST LOSS: 0.08567122385888146\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.08650022492445229 TEST LOSS: 0.08215730295726817\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.0875414940594213 TEST LOSS: 0.08013727784264503\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.08770437446199363 TEST LOSS: 0.08503510499452142\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.08903881464131111 TEST LOSS: 0.07840382637317525\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.08684689884551693 TEST LOSS: 0.07539464850946441\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.09196738574441322 TEST LOSS: 0.08414015408642614\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000017810EE01D0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.234625200626284 TEST LOSS: 0.2741455108610071\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.21197212700516796 TEST LOSS: 0.2513552935038466\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.19804966016738415 TEST LOSS: 0.23663862186344506\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.1673964503028943 TEST LOSS: 0.20321477698409807\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.1501196050983988 TEST LOSS: 0.18820483205426136\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.1486287783908334 TEST LOSS: 0.18614259579663336\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.1308036785288777 TEST LOSS: 0.16826753395216942\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.13242182380471454 TEST LOSS: 0.16235060056922146\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.12310715751396831 TEST LOSS: 0.15887202736529588\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.1162479511682389 TEST LOSS: 0.14750240555968142\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.11091198778983802 TEST LOSS: 0.1413311186980712\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.10627142996179345 TEST LOSS: 0.13715309509486212\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.09677962012538391 TEST LOSS: 0.13425250137407704\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.10332337548447636 TEST LOSS: 0.1367195691765075\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.09845105130053614 TEST LOSS: 0.13195930850205756\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.08545979951216037 TEST LOSS: 0.1258602477056798\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.0880603747298808 TEST LOSS: 0.12431620326093913\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.09289955538615995 TEST LOSS: 0.1259796565788443\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.08438780359241804 TEST LOSS: 0.1269770914099518\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.08855362089504294 TEST LOSS: 0.12933026267329206\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.08254024987645783 TEST LOSS: 0.12299182815591901\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.07336345587916243 TEST LOSS: 0.11618417027114857\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.08307900379858743 TEST LOSS: 0.11975740566287069\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.0846970383210828 TEST LOSS: 0.12167259913966301\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.07200870641528138 TEST LOSS: 0.11554135399856903\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.06783764265688308 TEST LOSS: 0.11051361968595158\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.06753570595628805 TEST LOSS: 0.1064198474037365\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.0736511684063361 TEST LOSS: 0.11374391305737826\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.064774923613142 TEST LOSS: 0.10388750681894716\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.0671651696178205 TEST LOSS: 0.1081344191376559\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.06570774050140818 TEST LOSS: 0.10449017236557465\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.07307003079690454 TEST LOSS: 0.1088973160517064\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.06478313305041408 TEST LOSS: 0.10560892403739028\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.06658043347372568 TEST LOSS: 0.1040026023753244\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.05854405186277668 TEST LOSS: 0.09380206313815034\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.06834970677115224 TEST LOSS: 0.10899732473369841\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.06764976540070433 TEST LOSS: 0.10779295178766364\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.06416055911147049 TEST LOSS: 0.10542193530601171\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.07181670423931331 TEST LOSS: 0.11308857843128786\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.06961212839994665 TEST LOSS: 0.11089331072419678\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.06620805283464583 TEST LOSS: 0.1077363207350373\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.056321184382542765 TEST LOSS: 0.0978166779155127\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.06865416147561974 TEST LOSS: 0.10813521464293167\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.06685425204199716 TEST LOSS: 0.11005225660265447\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.06415497803955768 TEST LOSS: 0.10548547780977585\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.06863033356365064 TEST LOSS: 0.10890066046645701\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.056241855883215126 TEST LOSS: 0.09777304271472025\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.07440696617408071 TEST LOSS: 0.11559676243694982\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.07065370026937909 TEST LOSS: 0.11074540194478244\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.06733922373433864 TEST LOSS: 0.10632652992962692\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.07894052797533833 TEST LOSS: 0.11733127106141086\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000017810EFB2E8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.23794265634912207 TEST LOSS: 0.2755983471096893\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.23800624178836458 TEST LOSS: 0.277996028308143\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.23800624178836458 TEST LOSS: 0.1821357991694132\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.20005170983715126 TEST LOSS: 0.16857077777799165\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.19356962022548999 TEST LOSS: 0.16828842420756418\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.13041678066813728 TEST LOSS: 0.15009751063138102\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.1180033089868385 TEST LOSS: 0.1353514198247597\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.12361679925026965 TEST LOSS: 0.13457994800082246\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.11985582728943871 TEST LOSS: 0.1316113178441252\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.11640002268561071 TEST LOSS: 0.11617320870634551\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.10959549959017295 TEST LOSS: 0.11813100949062404\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.1116189760604592 TEST LOSS: 0.11883515710001022\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.10436717351493648 TEST LOSS: 0.11207265199996341\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.11187678774729488 TEST LOSS: 0.11310288291191231\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.10301362971394558 TEST LOSS: 0.1179455041435055\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.10191797860267904 TEST LOSS: 0.11365428550748308\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.09839940465962749 TEST LOSS: 0.10844105033022514\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.0923629203176078 TEST LOSS: 0.10465221491720865\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.0997475286312673 TEST LOSS: 0.10549908313970585\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.08909391157511658 TEST LOSS: 0.09958322347523134\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.09047969571926505 TEST LOSS: 0.0961879981549281\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.0909582068944729 TEST LOSS: 0.0988856164785566\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.08820897511418117 TEST LOSS: 0.09820074744239587\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.08695233040599874 TEST LOSS: 0.09690671667666641\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.090758769080889 TEST LOSS: 0.0950464521655747\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.0846527557775291 TEST LOSS: 0.09367923951543677\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.08524797867830555 TEST LOSS: 0.09927507755084126\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.08515027626798041 TEST LOSS: 0.09062783674027337\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.08559387929849449 TEST LOSS: 0.09759167698428448\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.08889708331863477 TEST LOSS: 0.0977444294078503\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.08438826975235288 TEST LOSS: 0.09383731741635627\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.08673465322583199 TEST LOSS: 0.09540647071347835\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.08418401399354257 TEST LOSS: 0.09184040406666567\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.08688674390910532 TEST LOSS: 0.09238828235534341\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.0828617520261593 TEST LOSS: 0.09458036083525531\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.08745532014613622 TEST LOSS: 0.09331448091122285\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.08528205584862618 TEST LOSS: 0.09402070974536089\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.08458938051203384 TEST LOSS: 0.09347745753867788\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.08174604337131687 TEST LOSS: 0.09519108177187822\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.08403923814132287 TEST LOSS: 0.0924732431473811\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.08134628265913035 TEST LOSS: 0.09481567551299033\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.08716753803704282 TEST LOSS: 0.09687323567634096\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.0890675876267489 TEST LOSS: 0.10326719188834918\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.08619021071797671 TEST LOSS: 0.10272821441437943\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.08650571384919267 TEST LOSS: 0.09564665642595895\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.08669059544779704 TEST LOSS: 0.09729824714608022\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.08579718340302131 TEST LOSS: 0.09661949111401051\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.08526002987389932 TEST LOSS: 0.0975566814225948\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.08307961307374857 TEST LOSS: 0.09760495899915668\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.08362589964348094 TEST LOSS: 0.09900317512279014\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.08524753100988 TEST LOSS: 0.09880341299611477\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000017813288518>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.2885050293128917 TEST LOSS: 0.29233185232237285\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.237475334745778 TEST LOSS: 0.2747259982003687\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.19530268282306004 TEST LOSS: 0.22887495412680475\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.18945712227551295 TEST LOSS: 0.22179469412460254\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.17704088016395542 TEST LOSS: 0.17344312003183432\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.172417097306285 TEST LOSS: 0.16112312154346417\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.16279208961221722 TEST LOSS: 0.15473921175159408\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.1316332161435583 TEST LOSS: 0.12194794808874929\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.13492829506786583 TEST LOSS: 0.12231671460279292\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.1219114168859798 TEST LOSS: 0.11806030290681677\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.10396788630969969 TEST LOSS: 0.10358463760721787\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.10129511727754559 TEST LOSS: 0.10312759171504583\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.10138474352206701 TEST LOSS: 0.10325323629335315\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.10188177178899255 TEST LOSS: 0.10195771221343558\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.10278496428809822 TEST LOSS: 0.09893738748977796\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.09702133867754417 TEST LOSS: 0.09420649192316131\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.09894529937013694 TEST LOSS: 0.09306605278975615\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.091986218522738 TEST LOSS: 0.09136696094507031\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.08542014331930026 TEST LOSS: 0.08239935085230543\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.0817494060266193 TEST LOSS: 0.09403082226952227\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.08708886857189796 TEST LOSS: 0.08408485603136637\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.09314258086678198 TEST LOSS: 0.08485436667542409\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.08829258955800727 TEST LOSS: 0.08813738898393542\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.08496205980481643 TEST LOSS: 0.07723851295456059\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.0813009804992708 TEST LOSS: 0.07157714986039677\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.07639085696612247 TEST LOSS: 0.0714769637665848\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.08396473205809742 TEST LOSS: 0.07763163527377206\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.08895234260954618 TEST LOSS: 0.0824599290612296\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.07756588841610405 TEST LOSS: 0.07217055777831186\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.07822275125980443 TEST LOSS: 0.07874085063530083\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.0791035200712738 TEST LOSS: 0.07154514658992192\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.07882045113004496 TEST LOSS: 0.07502330687432711\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.08007171701325505 TEST LOSS: 0.07543427722615327\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.08449852014360008 TEST LOSS: 0.06860012157422626\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.07994749969220205 TEST LOSS: 0.074698210670644\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.08278838222047749 TEST LOSS: 0.07899913356087693\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.08383319390050978 TEST LOSS: 0.07092971109374091\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.08311317388470367 TEST LOSS: 0.0749430964364553\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.08356772973584034 TEST LOSS: 0.07153775918542372\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.07898729689287304 TEST LOSS: 0.072723334100414\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.08331169637759626 TEST LOSS: 0.07738410177383877\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.0866377952570382 TEST LOSS: 0.06867564044374444\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.08168657397922 TEST LOSS: 0.07725979074562214\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.08335094088164546 TEST LOSS: 0.0696507471253934\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.08585340245213913 TEST LOSS: 0.06634026977805733\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.08754666282984423 TEST LOSS: 0.07123233476401228\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.0794034917270684 TEST LOSS: 0.07205377255978158\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.07940787045906719 TEST LOSS: 0.06959162769813867\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.08149684184850334 TEST LOSS: 0.06630436331400123\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.08059811549309262 TEST LOSS: 0.06820258179236739\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.08348549365322558 TEST LOSS: 0.06678847586050624\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x00000178132E6FD0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.306187457565687 TEST LOSS: 0.24004665072301545\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.20525852979378512 TEST LOSS: 0.23404914331307836\n",
      "0.20525852979378512 0.11628987962572217\n",
      "COMPUTING FOR ITERATION NUMBER 5\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000017813336630>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.26830907049162805 TEST LOSS: 0.23246593484680408\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.26895802992902645 TEST LOSS: 0.21358492220188044\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.25617269340857385 TEST LOSS: 0.1822244013820981\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.24021895972341956 TEST LOSS: 0.18218204610062974\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.19308754043838264 TEST LOSS: 0.17194792915753837\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.19121524605434717 TEST LOSS: 0.17027357781987784\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.1768520740333426 TEST LOSS: 0.16403110790891684\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.14800755098308843 TEST LOSS: 0.1534557289843806\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.14383467175791573 TEST LOSS: 0.13717687852654759\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.13989428853365368 TEST LOSS: 0.12053762174490187\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.12159192830407352 TEST LOSS: 0.11553965171268313\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.12877907520999177 TEST LOSS: 0.11746469086283438\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.11972312686218914 TEST LOSS: 0.11119897467977866\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.10473616115216325 TEST LOSS: 0.10017506727638499\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.11286862629288597 TEST LOSS: 0.10281362733406763\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.10603611853145326 TEST LOSS: 0.11004973954255728\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.10561808733808964 TEST LOSS: 0.0997080743576606\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.10773725129416037 TEST LOSS: 0.09265024517205438\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.10270323658211311 TEST LOSS: 0.09609667620902197\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.10461427363441106 TEST LOSS: 0.09679488951442332\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.09950428757885334 TEST LOSS: 0.09464880184636551\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.08805377558961511 TEST LOSS: 0.09227391006788219\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.09671642883062394 TEST LOSS: 0.09713700324811994\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.09239959338585232 TEST LOSS: 0.09848238332236683\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.09871112033692014 TEST LOSS: 0.09802077972939156\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.09053807638702625 TEST LOSS: 0.08646793478936168\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.08456988751525783 TEST LOSS: 0.08412816710397734\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.08845443379323163 TEST LOSS: 0.0872870885679231\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.09188313552489653 TEST LOSS: 0.08513232888663447\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.09045591747186482 TEST LOSS: 0.07912077304349724\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.08176239298361171 TEST LOSS: 0.07803955362566042\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.09234018585451846 TEST LOSS: 0.07899764751913294\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.08478317769595896 TEST LOSS: 0.07447535646153071\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.09212170866835458 TEST LOSS: 0.08007003402452763\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.09320277505940383 TEST LOSS: 0.0783103478502516\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.0901945481828407 TEST LOSS: 0.07335241295595255\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.08301345314518535 TEST LOSS: 0.07031291920585034\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.09975543013408554 TEST LOSS: 0.0745942374499457\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.08278617450556683 TEST LOSS: 0.0727309176829631\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.08873387451900634 TEST LOSS: 0.0708754444142265\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.07989131871863513 TEST LOSS: 0.07312578721940047\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.08461285518626202 TEST LOSS: 0.07555246861135977\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.0918384010131412 TEST LOSS: 0.07344863270613655\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.09231059943809723 TEST LOSS: 0.07085183918893986\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.0918844163131333 TEST LOSS: 0.07885197597506796\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.09224227098014659 TEST LOSS: 0.07290424962673941\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.09241528090548962 TEST LOSS: 0.0766809689982447\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.10362992799096268 TEST LOSS: 0.07651959155090969\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.08760101202665128 TEST LOSS: 0.07218370923278887\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.09224382004136918 TEST LOSS: 0.07414531823842986\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.09531818219006424 TEST LOSS: 0.07436131078021802\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000017810E3CE10>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.2210643787158902 TEST LOSS: 0.25376024592051577\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.2148236175186681 TEST LOSS: 0.1805896877040729\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.20865374315844698 TEST LOSS: 0.16923140778988727\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.19463449306305067 TEST LOSS: 0.16265575589990144\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.1558814375246365 TEST LOSS: 0.1472499025699335\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.144326244334552 TEST LOSS: 0.13629663370216263\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.1395686252444284 TEST LOSS: 0.12141234299814906\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.1381301627221979 TEST LOSS: 0.11773868870652443\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.1372608028574659 TEST LOSS: 0.1168589427937061\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.11999074225558784 TEST LOSS: 0.10377998497760521\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.1250851622435784 TEST LOSS: 0.10380588991166281\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.1158487884563587 TEST LOSS: 0.09210126939754303\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.12053296031153139 TEST LOSS: 0.09348644506027391\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.11883430691927056 TEST LOSS: 0.09123092924690256\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.10945449049178858 TEST LOSS: 0.0824768702267855\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.11128084739599563 TEST LOSS: 0.0892420638276268\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.10651037101672005 TEST LOSS: 0.07976774325770224\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.10254657238504143 TEST LOSS: 0.07823373063784354\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.10590064173548884 TEST LOSS: 0.075986195030583\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.10431263943282239 TEST LOSS: 0.06981556952018016\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.1009840532096245 TEST LOSS: 0.06570075827595599\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.09894107077562496 TEST LOSS: 0.07255201936886954\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.09341707129241136 TEST LOSS: 0.06518951016451963\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.09289317696596494 TEST LOSS: 0.06201828084367546\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.0896889210718438 TEST LOSS: 0.0627751299547523\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.09149074756912208 TEST LOSS: 0.05948705008130158\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.08381668757311395 TEST LOSS: 0.061641785909040146\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.09439629827270835 TEST LOSS: 0.06019133455039046\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.09728019374856953 TEST LOSS: 0.057861093729565466\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.0873446194983052 TEST LOSS: 0.0572953719071447\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.08285647017771247 TEST LOSS: 0.059456280298331\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.08671725778381438 TEST LOSS: 0.062486908642938294\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.08675492885658932 TEST LOSS: 0.05609100558138783\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.08026573315766718 TEST LOSS: 0.06565938202020535\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.09207897728881612 TEST LOSS: 0.055953832869969675\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.09089647454863689 TEST LOSS: 0.05777760120111586\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.09826483058296963 TEST LOSS: 0.06256720951062313\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.08472265887490868 TEST LOSS: 0.05372351427073881\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.08646743819654377 TEST LOSS: 0.056334484495496134\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.08476555977366845 TEST LOSS: 0.056641465338219336\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.09123151625221211 TEST LOSS: 0.059419201770976246\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.08820228498703658 TEST LOSS: 0.056350780137207526\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.08269441966435166 TEST LOSS: 0.05720458020201424\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.0764785513528208 TEST LOSS: 0.06648691448334432\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.0898360427847894 TEST LOSS: 0.055000035112642745\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.08424447003829108 TEST LOSS: 0.05407340949794362\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.0843121427155683 TEST LOSS: 0.05484392096425973\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.0902517697648967 TEST LOSS: 0.05368812800985918\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.08379847638984424 TEST LOSS: 0.05431784702960483\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.08878997845969105 TEST LOSS: 0.052719739869833575\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.08848005618640431 TEST LOSS: 0.06213361750487411\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000017813288198>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.2588356589934475 TEST LOSS: 0.25740831543696224\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.24110356104256814 TEST LOSS: 0.25740831543696224\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.228804477090426 TEST LOSS: 0.20620290716059092\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.20546209334008356 TEST LOSS: 0.17733587767447548\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.19142317733210767 TEST LOSS: 0.1535941701680279\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.18696921585690449 TEST LOSS: 0.1539214581900275\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.15904459609017788 TEST LOSS: 0.13681712782121766\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.16243759108694827 TEST LOSS: 0.15273782725967514\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.14550120648735004 TEST LOSS: 0.12321598625141668\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.13702912705485498 TEST LOSS: 0.1225579988859706\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.12448118363823438 TEST LOSS: 0.11658203993235819\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.12744662460058873 TEST LOSS: 0.1105185824831512\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.11892718371082675 TEST LOSS: 0.1041569645575435\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.11265950892724903 TEST LOSS: 0.10372714584464732\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.11482341984122897 TEST LOSS: 0.10209690489579264\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.1046895839479752 TEST LOSS: 0.09344558586561424\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.10642695460732782 TEST LOSS: 0.08473951540905922\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.10762007282411547 TEST LOSS: 0.08050843737591544\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.11156015540339274 TEST LOSS: 0.08698345931567623\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.11134706368829789 TEST LOSS: 0.08768496525623116\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.10828867988645406 TEST LOSS: 0.08504722410063541\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.10473439033183272 TEST LOSS: 0.08189673184126947\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.10666472921381176 TEST LOSS: 0.08266838228432316\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.1013619451935268 TEST LOSS: 0.0756991766615814\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.0987767362647953 TEST LOSS: 0.07570367646874758\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.10232519492316815 TEST LOSS: 0.07811084492648872\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.10178822818023865 TEST LOSS: 0.07029473894150318\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.10469893526489446 TEST LOSS: 0.08662456343309073\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.09849233487601644 TEST LOSS: 0.07280763616729698\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.1021875985274493 TEST LOSS: 0.07653910439817369\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.1014768258698314 TEST LOSS: 0.07359861732484498\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.09996149810213799 TEST LOSS: 0.06930360906056518\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.10177587041122237 TEST LOSS: 0.0712133531623377\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.10071159011304641 TEST LOSS: 0.07115205610171334\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.09592663926939565 TEST LOSS: 0.06159160367609046\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.09849481219407391 TEST LOSS: 0.06978973367969053\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.09824268516596923 TEST LOSS: 0.07452035106852681\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.09868512168720854 TEST LOSS: 0.06920931105572062\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.10007642670955656 TEST LOSS: 0.07357666331781504\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.09816762030947945 TEST LOSS: 0.06862455566067355\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.09710645832014576 TEST LOSS: 0.07186889433230574\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.09654805110747332 TEST LOSS: 0.06882584891277915\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.09912583474698848 TEST LOSS: 0.06899886477580347\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.10215659575441204 TEST LOSS: 0.07559835810546171\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.09764184369602277 TEST LOSS: 0.07227167961605098\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.09591940323841851 TEST LOSS: 0.06783809122514084\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.10219808694156168 TEST LOSS: 0.07534758510855637\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.09755658530205222 TEST LOSS: 0.07358946248240662\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.10297474939617811 TEST LOSS: 0.07700353566457684\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.09995937617394489 TEST LOSS: 0.07016909389463175\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.10106429235142189 TEST LOSS: 0.07647431521569019\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x00000178110349E8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.19853681903589937 TEST LOSS: 0.24556277909559263\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.19255269363620242 TEST LOSS: 0.23707342940659842\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.16575349517193413 TEST LOSS: 0.20878642856761226\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.15065875733571246 TEST LOSS: 0.16268650344158822\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.14024328363512953 TEST LOSS: 0.1469244680504809\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.12434418641769517 TEST LOSS: 0.1444928849764445\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.10975332999391127 TEST LOSS: 0.11819828028108709\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.10900327557270681 TEST LOSS: 0.12601028037403506\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.10089843527761609 TEST LOSS: 0.12983337324099567\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.09272678775755973 TEST LOSS: 0.10267867430048862\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.09374411553734165 TEST LOSS: 0.10843731558088789\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.08491146868986373 TEST LOSS: 0.09552369315875966\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.08611921197494034 TEST LOSS: 0.10086086850188657\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.0694922607141807 TEST LOSS: 0.10240892348054746\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.07210633506336543 TEST LOSS: 0.08387704596359716\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.06835748466493499 TEST LOSS: 0.09078964431139236\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.06538145515399492 TEST LOSS: 0.08896332791178416\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.06515233985290075 TEST LOSS: 0.08403241914671873\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.06798581984675502 TEST LOSS: 0.07123023872689942\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.06806440156474863 TEST LOSS: 0.07451817076075162\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.06081388373471573 TEST LOSS: 0.06941830881727068\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.06336881062690464 TEST LOSS: 0.06972078172025302\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.06589169236548591 TEST LOSS: 0.06903709761364935\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.06421133272040222 TEST LOSS: 0.06367001396278367\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.06452514622520801 TEST LOSS: 0.06343474045486439\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.05978658592775576 TEST LOSS: 0.06754858891701952\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.06477334281817876 TEST LOSS: 0.060275136159405385\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.06082698709809623 TEST LOSS: 0.0642713139960271\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.05893929926812652 TEST LOSS: 0.06758767294133779\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.06461265878960476 TEST LOSS: 0.06205684151645275\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.06598287914485293 TEST LOSS: 0.06109618360964385\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.055977321017439435 TEST LOSS: 0.06875814057929158\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.060436158238624874 TEST LOSS: 0.06588767396224449\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.06284684215277803 TEST LOSS: 0.06401036912366322\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.061454940152709234 TEST LOSS: 0.06052722536326381\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.06117938302987213 TEST LOSS: 0.06472708604635426\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.06683123655037092 TEST LOSS: 0.06360690993156487\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.06123720404447607 TEST LOSS: 0.060677767414178956\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.06175231765745623 TEST LOSS: 0.06221305225169611\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.05562249037217164 TEST LOSS: 0.06841892019203984\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.057316706503576224 TEST LOSS: 0.06094170846266221\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.06469693272540775 TEST LOSS: 0.05896454703558755\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.061581505839378915 TEST LOSS: 0.054994421665824675\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.05884395079071269 TEST LOSS: 0.06217642062816347\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.05733959036372722 TEST LOSS: 0.057526702179756244\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.05939502761174798 TEST LOSS: 0.06065457425999715\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.056021621749743726 TEST LOSS: 0.06625049704818717\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.06140430161451092 TEST LOSS: 0.05562467379980194\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.05463550450242279 TEST LOSS: 0.06507260941926438\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.05674808846238671 TEST LOSS: 0.05793905984795985\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.05899210227308442 TEST LOSS: 0.060708135723539655\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x00000178110262B0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.2731763931956767 TEST LOSS: 0.3293297001418093\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.2095714579284546 TEST LOSS: 0.18885336559918336\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.19127985250509955 TEST LOSS: 0.16888123102717553\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.15247687109609226 TEST LOSS: 0.13983788945374892\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.12892607209904894 TEST LOSS: 0.13381397738101505\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.1354353616766964 TEST LOSS: 0.15125424424560785\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.12240563395424531 TEST LOSS: 0.1400847146097319\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.11957223414861073 TEST LOSS: 0.1475917777292346\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.10908711652611452 TEST LOSS: 0.1381873574348759\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.11316240914725234 TEST LOSS: 0.14185310945818475\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.1007879471407606 TEST LOSS: 0.12556723874122314\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.09565285334460188 TEST LOSS: 0.11934567749883712\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.08728872824324373 TEST LOSS: 0.12201008912108233\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.10494583477032 TEST LOSS: 0.13030523743864003\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.10624804981313786 TEST LOSS: 0.13365146864472688\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.08803376488323336 TEST LOSS: 0.11148896359463063\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.08930718859080591 TEST LOSS: 0.12179845571982102\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.09087852791745352 TEST LOSS: 0.11989751447964493\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.09032989508540162 TEST LOSS: 0.11218194949864652\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.07732243765229944 TEST LOSS: 0.10770705594581738\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.07962287335559337 TEST LOSS: 0.11035790854565293\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.07328358216799134 TEST LOSS: 0.08914065307229864\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.0802907044202079 TEST LOSS: 0.10459733741339129\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.07311535331490214 TEST LOSS: 0.10911838403548443\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.0802874145479557 TEST LOSS: 0.12049993080310875\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.08232627742147453 TEST LOSS: 0.10893866629569482\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.07693688516787033 TEST LOSS: 0.10733543530869812\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.0741551897832543 TEST LOSS: 0.10409259319861441\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.06986492287661843 TEST LOSS: 0.0953161264696621\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.07138170848998174 TEST LOSS: 0.10788247468113332\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.07709373739645888 TEST LOSS: 0.113608076617339\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.07958901570474362 TEST LOSS: 0.1144140628160249\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.07403994241596015 TEST LOSS: 0.10927475179234848\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.07065525111432124 TEST LOSS: 0.09368208613895003\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.07569483919838543 TEST LOSS: 0.11212307496768414\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.07025583940033023 TEST LOSS: 0.0959235992429447\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.06583904568118241 TEST LOSS: 0.09377654977287261\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.06927320086593532 TEST LOSS: 0.09969872224876042\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.0737464455139945 TEST LOSS: 0.10745732016089776\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.07486940096102279 TEST LOSS: 0.10845979507231347\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.07788290885524518 TEST LOSS: 0.111120367599261\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.07138578800602896 TEST LOSS: 0.10236536596361193\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.07302143992381858 TEST LOSS: 0.10618043698979254\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.07850441346721888 TEST LOSS: 0.10895205698131714\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.08241385800847248 TEST LOSS: 0.11173716903964494\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.07677243711155192 TEST LOSS: 0.10108190934744163\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.0751514915661099 TEST LOSS: 0.10018088661013867\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.07285493711435083 TEST LOSS: 0.10370321730881099\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.07491491191362613 TEST LOSS: 0.10361531742882216\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.0779997810091808 TEST LOSS: 0.10039506238723374\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.07538848775588819 TEST LOSS: 0.10418068400895553\n",
      "0.0666715119583594 0.07632143561667973\n",
      "COMPUTING FOR ITERATION NUMBER 6\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x00000178135A8A58>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.2829357344445625 TEST LOSS: 0.2889309344568096\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.28353967909957817 TEST LOSS: 0.275533462337731\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.28353967909957817 TEST LOSS: 0.275533462337731\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.25572975390192 TEST LOSS: 0.21097681158250903\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.23875758071092593 TEST LOSS: 0.22769005857925212\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.19004458749082376 TEST LOSS: 0.19086710887379166\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.1581141620987592 TEST LOSS: 0.167333606990664\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.15181006611577477 TEST LOSS: 0.15704660597926964\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.13415124659264765 TEST LOSS: 0.12994885816868043\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.1189262648366498 TEST LOSS: 0.13768570086499782\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.11130664615493448 TEST LOSS: 0.12259641472446409\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.11376260398996801 TEST LOSS: 0.12920862970033792\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.08440672611089413 TEST LOSS: 0.11944751536657343\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.09763065177446456 TEST LOSS: 0.1226322410861339\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.09800850268421947 TEST LOSS: 0.12249636996201846\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.08789327758005143 TEST LOSS: 0.11381966820560448\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.08581148849632571 TEST LOSS: 0.1071285384855198\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.09475143542526124 TEST LOSS: 0.11398473523602592\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.08338877766973073 TEST LOSS: 0.11091424310772811\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.09936361950254884 TEST LOSS: 0.11082644088262729\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.09515023368970552 TEST LOSS: 0.10964312321746797\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.08922851436017637 TEST LOSS: 0.10893282737783833\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.07857066672737814 TEST LOSS: 0.10038102970007769\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.07997286778453243 TEST LOSS: 0.10094594602265006\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.0841392656241449 TEST LOSS: 0.10539094085046177\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.08207046921414311 TEST LOSS: 0.09895753189412995\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.0860637573692636 TEST LOSS: 0.10264803358605354\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.0725894059645332 TEST LOSS: 0.09945309702582864\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.08558758349021725 TEST LOSS: 0.10000886409593165\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.0824504216361216 TEST LOSS: 0.09700419848268842\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.07266854768330608 TEST LOSS: 0.0974415989885195\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.07107822725262268 TEST LOSS: 0.09493998732025721\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.06849205240790368 TEST LOSS: 0.09293855964508874\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.07471910330261357 TEST LOSS: 0.0956113838111102\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.0726629176787709 TEST LOSS: 0.09542412640664226\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.06923035238695105 TEST LOSS: 0.09400050741459803\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.07085731422912028 TEST LOSS: 0.09298435293569979\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.071576397335352 TEST LOSS: 0.0943951772689232\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.08366473178627229 TEST LOSS: 0.09782323073018571\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.0722790816222488 TEST LOSS: 0.09183073891730897\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.06735570879549369 TEST LOSS: 0.09213476788836446\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.0665631774261918 TEST LOSS: 0.09287686737909845\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.0770911372838884 TEST LOSS: 0.0954755797045086\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.079794982569028 TEST LOSS: 0.09496376710408498\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.07233908564037057 TEST LOSS: 0.09349227376884126\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.07175733898979007 TEST LOSS: 0.0937465892544994\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.07916138020519198 TEST LOSS: 0.09568935241412213\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.07640242317976648 TEST LOSS: 0.09122610240498072\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.06966328658240585 TEST LOSS: 0.09175983437279511\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.06748493406789594 TEST LOSS: 0.08898641185725577\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.07529163959923833 TEST LOSS: 0.09267189765995226\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x00000178133362E8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.27817343958055174 TEST LOSS: 0.26794006384765284\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.2734096460206074 TEST LOSS: 0.2630003777471034\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.23567906799666075 TEST LOSS: 0.2213694413834359\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.22951152775383526 TEST LOSS: 0.21736293688197303\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.21018874986535707 TEST LOSS: 0.1774332262046624\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.20375306159933312 TEST LOSS: 0.17729257245801666\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.1994232865231869 TEST LOSS: 0.16770364838633844\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.17256006456081086 TEST LOSS: 0.16798464596203147\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.17243514926125306 TEST LOSS: 0.15518584641826713\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.13218688811559573 TEST LOSS: 0.1450906437344704\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.11573453564706122 TEST LOSS: 0.13160586646588576\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.10840383792640622 TEST LOSS: 0.12826220585698372\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.10255668313123781 TEST LOSS: 0.12285132996194606\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.09088404848418451 TEST LOSS: 0.11408086326795197\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.09389878967333141 TEST LOSS: 0.1054831788693043\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.10599615108985665 TEST LOSS: 0.11251680472256088\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.10374100358186139 TEST LOSS: 0.11433392667499812\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.1031754150676597 TEST LOSS: 0.10933827469958428\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.08719505875307548 TEST LOSS: 0.09129983730409538\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.0862304638159962 TEST LOSS: 0.08838679023289178\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.08505649417203626 TEST LOSS: 0.08794708769253883\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.0866289575566154 TEST LOSS: 0.08866572173994564\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.09307012316675707 TEST LOSS: 0.10217001877368838\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.08175009804787008 TEST LOSS: 0.0884652688901138\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.09395349532787652 TEST LOSS: 0.09243654822250817\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.08092746624135295 TEST LOSS: 0.0768666785831113\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.08112468080012201 TEST LOSS: 0.08129034694846167\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.092290755605064 TEST LOSS: 0.08517090187190193\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.08014554265804662 TEST LOSS: 0.0778543366163747\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.0763008786721668 TEST LOSS: 0.07274676929655526\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.08669545062134597 TEST LOSS: 0.08230949596171028\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.07976634065011401 TEST LOSS: 0.08623882105256253\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.08161499455849226 TEST LOSS: 0.08315308325500965\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.08611633880136131 TEST LOSS: 0.0888799260264759\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.08017674124071027 TEST LOSS: 0.08349403702860525\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.07030294949095409 TEST LOSS: 0.06950262444514585\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.06836531351417151 TEST LOSS: 0.06980510044269161\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.08461006803368047 TEST LOSS: 0.0831425279977781\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.07438065870347754 TEST LOSS: 0.08044535496829461\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.07188666580350193 TEST LOSS: 0.0726575662593327\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.07459578582577298 TEST LOSS: 0.07862786465158979\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.07794757940521527 TEST LOSS: 0.07953851937250536\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.0712037834779618 TEST LOSS: 0.07484086137182315\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.07553876773601338 TEST LOSS: 0.07785431593952069\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.06927715717280433 TEST LOSS: 0.07181201778035684\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.07060159740826992 TEST LOSS: 0.07913706192775721\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.07516093022431088 TEST LOSS: 0.08371733540244387\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.0729575277600768 TEST LOSS: 0.07560778793307113\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.06906686231937541 TEST LOSS: 0.06954479672576418\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.07674071912447794 TEST LOSS: 0.08580885631722322\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.07161625999109676 TEST LOSS: 0.07424938452131656\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000017811039DA0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.2455986989433552 TEST LOSS: 0.29137656485461794\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.24413489513460507 TEST LOSS: 0.23955338957978142\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.22658747858764383 TEST LOSS: 0.2158313712139482\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.17661698563463474 TEST LOSS: 0.16037555923018137\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.18260741112206716 TEST LOSS: 0.1640953037998511\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.14632882608495523 TEST LOSS: 0.13940982994663856\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.14812875189813082 TEST LOSS: 0.1447209003264049\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.12926212162260475 TEST LOSS: 0.1314336150700483\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.12087900471059701 TEST LOSS: 0.13138532147094872\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.12039463808330453 TEST LOSS: 0.11690714636689882\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.11340905932207222 TEST LOSS: 0.11938829684400089\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.09794998019887767 TEST LOSS: 0.10803350901267122\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.09712962076695061 TEST LOSS: 0.10102904487891966\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.0964067621234397 TEST LOSS: 0.10615639848952962\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.09773223916276778 TEST LOSS: 0.1054934356879562\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.09204903729789676 TEST LOSS: 0.10606920507488131\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.09772667559349017 TEST LOSS: 0.10870563098212353\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.09186155852942843 TEST LOSS: 0.1066611397312194\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.09359541499059182 TEST LOSS: 0.09547116001939933\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.09043901940798346 TEST LOSS: 0.09323314266963097\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.08825239124329202 TEST LOSS: 0.08455694129181246\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.08780257971485161 TEST LOSS: 0.08692375734048598\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.08771318961517073 TEST LOSS: 0.09476466425229813\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.08723104177744878 TEST LOSS: 0.089882223576371\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.08836617423353521 TEST LOSS: 0.10175177297822034\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.0876154232618838 TEST LOSS: 0.09074807204793484\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.08747501339169624 TEST LOSS: 0.09768579505434416\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.0825547005102765 TEST LOSS: 0.07445750266287525\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.08562730638057206 TEST LOSS: 0.08374348202359132\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.08359883232181063 TEST LOSS: 0.07862762059564381\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.08850298318682391 TEST LOSS: 0.10494745978604983\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.08539220592953171 TEST LOSS: 0.08850019697008696\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.08690613264715553 TEST LOSS: 0.09205302095299597\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.07958889483073962 TEST LOSS: 0.07536437897917461\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.08524615722799846 TEST LOSS: 0.09473711618939484\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.08178952731615086 TEST LOSS: 0.08496093456445226\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.08172368554937584 TEST LOSS: 0.07317667830076642\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.08499792138037036 TEST LOSS: 0.08627078342480428\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.08365174058673817 TEST LOSS: 0.08752958340046872\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.0827233585188468 TEST LOSS: 0.08669063918387636\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.08534518009726097 TEST LOSS: 0.10010937322588805\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.07958140537640605 TEST LOSS: 0.07771198617618155\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.08288703307751408 TEST LOSS: 0.08000650537824404\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.08070935485048596 TEST LOSS: 0.07746326036361585\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.07889197451631015 TEST LOSS: 0.07780278788037984\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.08273070186310276 TEST LOSS: 0.08508033655131987\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.08590211473750906 TEST LOSS: 0.09425352706444962\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.08011719500801641 TEST LOSS: 0.0805738097760016\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.0841344031538671 TEST LOSS: 0.08572104932087793\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.08612389294850713 TEST LOSS: 0.08086597102795616\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.0821280042912534 TEST LOSS: 0.08691226428826519\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x00000178110263C8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.20363843908873888 TEST LOSS: 0.2853032114447502\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.19160177687423263 TEST LOSS: 0.23771503210634254\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.1844395144168302 TEST LOSS: 0.2220039819633951\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.15899422410461697 TEST LOSS: 0.18668415377637287\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.14938908971193698 TEST LOSS: 0.17344693046551082\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.14481672890519567 TEST LOSS: 0.16782689883167523\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.12088892363449406 TEST LOSS: 0.14997503329380735\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.10553649868676612 TEST LOSS: 0.1426259058780008\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.11601236016851997 TEST LOSS: 0.14244855479119264\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.10294382835458375 TEST LOSS: 0.13323083920175127\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.09317791200200926 TEST LOSS: 0.1269520786198123\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.08302946501587767 TEST LOSS: 0.11583856925783474\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.08353120191317537 TEST LOSS: 0.12136985064362454\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.07923425751624487 TEST LOSS: 0.11759059960612986\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.07485194836962572 TEST LOSS: 0.11397080688514004\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.0696978650429017 TEST LOSS: 0.11427302873604714\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.07448044158175016 TEST LOSS: 0.12101073472096552\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.06907990635919897 TEST LOSS: 0.10876196151624505\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.07014743335545752 TEST LOSS: 0.11277616232723207\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.07037017260889372 TEST LOSS: 0.1033043644439774\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.06538199237745318 TEST LOSS: 0.10021760768371203\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.06594501896367388 TEST LOSS: 0.09620683349232559\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.06721474110695598 TEST LOSS: 0.09830522056824045\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.06602254324897404 TEST LOSS: 0.09539841879081655\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.06035528220430329 TEST LOSS: 0.09001374223299424\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.06380308699157913 TEST LOSS: 0.09476073967777189\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.062395727670249757 TEST LOSS: 0.09413172977576025\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.05764599381923195 TEST LOSS: 0.09314928996188632\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.05568897705109143 TEST LOSS: 0.09414647393042445\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.06088906522911767 TEST LOSS: 0.09035153544916529\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.05923103977983526 TEST LOSS: 0.09144147300019809\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.05433358800072922 TEST LOSS: 0.09371345832666138\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.057453116374283235 TEST LOSS: 0.09328618143151168\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.0622491812929229 TEST LOSS: 0.09179976235759199\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.05672393114279147 TEST LOSS: 0.08631603672991087\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.058560254406834135 TEST LOSS: 0.0895565735917462\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.05849196084049313 TEST LOSS: 0.08973342084349673\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.05572158744626741 TEST LOSS: 0.08840151913786266\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.0598759458116793 TEST LOSS: 0.09063949360986923\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.05777761497337331 TEST LOSS: 0.09282964585520309\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.062004424573404826 TEST LOSS: 0.0948060262442233\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.054853472010514465 TEST LOSS: 0.0901390011122501\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.057824799236409555 TEST LOSS: 0.08740737262167911\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.0589639478814145 TEST LOSS: 0.08900384326082277\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.0555518079259879 TEST LOSS: 0.0865008734540051\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.054678560749661015 TEST LOSS: 0.09051165279886869\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.05756799117848233 TEST LOSS: 0.09060830466830644\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.059403473364412665 TEST LOSS: 0.08428192546617302\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.05459464356311469 TEST LOSS: 0.08350212726431085\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.05672765257402069 TEST LOSS: 0.08574711408136518\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.056700662767677365 TEST LOSS: 0.08414143426133472\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001781189F438>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.2654731709605892 TEST LOSS: 0.17825218821907368\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.1699884808262051 TEST LOSS: 0.15563821714716733\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.17990760561293567 TEST LOSS: 0.16276892280823083\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.18309785539202603 TEST LOSS: 0.1619266111181276\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.15793133893605835 TEST LOSS: 0.1548626324587573\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.15968454101216964 TEST LOSS: 0.15266132190153195\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.14229605957069053 TEST LOSS: 0.13539126836007656\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.13146468024409552 TEST LOSS: 0.12014184639848645\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.12320605853887855 TEST LOSS: 0.10860451789495416\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.11653341628415854 TEST LOSS: 0.10191006866620658\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.12052480355625765 TEST LOSS: 0.09609625586856278\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.11973015634437888 TEST LOSS: 0.0934405932609298\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.11523087725934578 TEST LOSS: 0.08505814415496771\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.1134915747283709 TEST LOSS: 0.09558111746468868\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.10952826666100673 TEST LOSS: 0.08816784513480859\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.10946766270454643 TEST LOSS: 0.08595798944417643\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.10500862204393954 TEST LOSS: 0.09041698792024004\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.08414129714199485 TEST LOSS: 0.07395861561421875\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.0910484796137892 TEST LOSS: 0.07995169919977543\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.09201922338552597 TEST LOSS: 0.08265043280747422\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.0935369314536955 TEST LOSS: 0.07882402562708847\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.08511486902892706 TEST LOSS: 0.06770346933622676\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.08461578763996065 TEST LOSS: 0.07570920998469949\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.08505845354723468 TEST LOSS: 0.07442654887447032\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.08051892859268511 TEST LOSS: 0.06891128727388443\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.08070671533590981 TEST LOSS: 0.07376689635853452\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.08967574929186432 TEST LOSS: 0.07178975873838717\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.08527857932667701 TEST LOSS: 0.07233941639282915\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.08301327752147394 TEST LOSS: 0.07163608567924408\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.08357821018910785 TEST LOSS: 0.07123328390460976\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.08170195446942745 TEST LOSS: 0.06981005764711332\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.08923947901244755 TEST LOSS: 0.0718254104530778\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.08142709778272947 TEST LOSS: 0.06944347013716315\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.08880908910407798 TEST LOSS: 0.0705869507016357\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.07884172808561057 TEST LOSS: 0.06920640260551647\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.08193938616727918 TEST LOSS: 0.07080507333040377\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.08051646304329961 TEST LOSS: 0.06969276697511896\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.0853918377768395 TEST LOSS: 0.07186546434108455\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.08049307756921506 TEST LOSS: 0.07235662254511462\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.08434817836530348 TEST LOSS: 0.07311093117792174\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.08167486276275468 TEST LOSS: 0.07079836048641479\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.08361439165607973 TEST LOSS: 0.06946609405057101\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.08665938517007943 TEST LOSS: 0.06926254776223752\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.0825850385125456 TEST LOSS: 0.07055374755399127\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.08081271349328453 TEST LOSS: 0.06975590148653314\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.08147269522418893 TEST LOSS: 0.07022979838594803\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.08190919214127812 TEST LOSS: 0.07112281790826254\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.08665533365057312 TEST LOSS: 0.07128969940751291\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.0841968431712372 TEST LOSS: 0.07059838944308873\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.08562330807857114 TEST LOSS: 0.07055330782606233\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.08784924913309167 TEST LOSS: 0.07245605292699044\n",
      "0.07758427110823957 0.07947099453458595\n",
      "COMPUTING FOR ITERATION NUMBER 7\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001781100B278>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.3000331487162357 TEST LOSS: 0.26533179446839883\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.3165801918843916 TEST LOSS: 0.25672106054500293\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.18539273716257487 TEST LOSS: 0.22466279550871368\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.16223012234635747 TEST LOSS: 0.20014556645825543\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.15315042229271375 TEST LOSS: 0.16936388246956074\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.1308597897664933 TEST LOSS: 0.13255202863058343\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.13464241269338845 TEST LOSS: 0.12349215360991381\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.12909232908258922 TEST LOSS: 0.1140765176571116\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.11644402306754739 TEST LOSS: 0.1045081205254138\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.10158699635390371 TEST LOSS: 0.09663377006378118\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.10310438750816359 TEST LOSS: 0.08622772708619336\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.1067269845139573 TEST LOSS: 0.09228049982281705\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.10567606508382682 TEST LOSS: 0.08613702976949192\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.09077032186397521 TEST LOSS: 0.07901125475388665\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.09433469877008144 TEST LOSS: 0.09170575736626624\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.09441474123877522 TEST LOSS: 0.08488038934224226\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.08482897528660956 TEST LOSS: 0.08497649245997972\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.08996251718363638 TEST LOSS: 0.09100716281085487\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.10055079222881233 TEST LOSS: 0.08972270330648294\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.07585788111160058 TEST LOSS: 0.08215207267724381\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.07651630508401426 TEST LOSS: 0.08176568133055133\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.07316499071740898 TEST LOSS: 0.0811593915382098\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.0692543755222998 TEST LOSS: 0.07733159569736867\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.06734065026816533 TEST LOSS: 0.07647806873346082\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.07480432193739894 TEST LOSS: 0.07483527014455588\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.07074105436357066 TEST LOSS: 0.07707822089772556\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.07275974683774931 TEST LOSS: 0.0764518242847388\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.06647948026245327 TEST LOSS: 0.0730020018664668\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.06055216209476919 TEST LOSS: 0.07134096846760428\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.08071692039722675 TEST LOSS: 0.07587740040444342\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.07913218762784635 TEST LOSS: 0.07870465170104207\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.06866378908483811 TEST LOSS: 0.06914714297494405\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.0698606106999274 TEST LOSS: 0.0782020609508463\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.07568053701251605 TEST LOSS: 0.07391651268959817\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.07160609432890361 TEST LOSS: 0.07251727152945062\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.07262875075478717 TEST LOSS: 0.07408565603960701\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.07088654302162696 TEST LOSS: 0.07218318756603734\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.07373684277696378 TEST LOSS: 0.07895356271734014\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.08116137337624382 TEST LOSS: 0.07658112221270104\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.06889915359943193 TEST LOSS: 0.06878671004743415\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.07285814383246177 TEST LOSS: 0.07347599589332302\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.07040885340409378 TEST LOSS: 0.07513260092100513\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.0733946480766964 TEST LOSS: 0.06745455134813375\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.0679035388726524 TEST LOSS: 0.06682415287171185\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.07016234123512385 TEST LOSS: 0.06992249329829626\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.07498107895764834 TEST LOSS: 0.0736940994049046\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.07206954885380058 TEST LOSS: 0.07784971135655515\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.06470523082069111 TEST LOSS: 0.06985095004898786\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.06874762048249608 TEST LOSS: 0.07159693748540033\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.07834974478709726 TEST LOSS: 0.07404650787066142\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.07438806673583159 TEST LOSS: 0.07208664568395765\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x00000178135AB0F0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.24808631940610476 TEST LOSS: 0.292914580056546\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.21463946653472038 TEST LOSS: 0.22099311748435166\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.19185124064948564 TEST LOSS: 0.21240474123492925\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.16316171818030892 TEST LOSS: 0.1865140366896287\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.12795367308042832 TEST LOSS: 0.14612978599979598\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.1255108876646669 TEST LOSS: 0.13752533753628682\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.12778464748541565 TEST LOSS: 0.13181365378498439\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.11979610892370064 TEST LOSS: 0.12906212153239796\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.1109900635508172 TEST LOSS: 0.12192669822644707\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.11389066637653308 TEST LOSS: 0.12603651498279106\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.10964974311276125 TEST LOSS: 0.11816970187674403\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.1091519707414665 TEST LOSS: 0.12033240649760038\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.10817632341064959 TEST LOSS: 0.11964501902713288\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.1034254951235015 TEST LOSS: 0.121966268667893\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.10739475987728625 TEST LOSS: 0.11297277925146963\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.10274370192261686 TEST LOSS: 0.11180663410255551\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.1019528364070608 TEST LOSS: 0.10891743369320821\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.10861027215729716 TEST LOSS: 0.10774736165578555\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.09290687193285242 TEST LOSS: 0.10599744791821332\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.08776621779924655 TEST LOSS: 0.10553943285404493\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.09063107091236139 TEST LOSS: 0.10668169534638229\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.08436653700158507 TEST LOSS: 0.10279793927296513\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.0836601854856178 TEST LOSS: 0.10279476019548\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.0862673810150064 TEST LOSS: 0.10191219929517717\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.08602249780842038 TEST LOSS: 0.10148381407692825\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.07504555882712421 TEST LOSS: 0.10038737162164213\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.07939279643557003 TEST LOSS: 0.10137955149696622\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.08213814015216397 TEST LOSS: 0.10048425634995828\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.07333396784779149 TEST LOSS: 0.0997550715936117\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.08395467170167534 TEST LOSS: 0.10020217187323456\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.07634887090579873 TEST LOSS: 0.10144867462119932\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.07731524155946642 TEST LOSS: 0.09984252881943503\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.0794608121788709 TEST LOSS: 0.09812160022307032\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.07663025615349428 TEST LOSS: 0.10008606037600057\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.07647200962512052 TEST LOSS: 0.09618396506568971\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.07406053047155489 TEST LOSS: 0.09642113728433425\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.07732901586697973 TEST LOSS: 0.09584994322469817\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.08055965881114849 TEST LOSS: 0.09876072359953414\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.07911196350075182 TEST LOSS: 0.0957092014994785\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.07645720407121784 TEST LOSS: 0.0983777404486553\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.07858892584118747 TEST LOSS: 0.09563900904482843\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.0785386765058176 TEST LOSS: 0.09647151628592109\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.08119854370751182 TEST LOSS: 0.09814851908554832\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.07853251392881722 TEST LOSS: 0.09771463649509124\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.0770197033534507 TEST LOSS: 0.09905725277759513\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.07618124644305635 TEST LOSS: 0.09648410863470099\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.07432263747347109 TEST LOSS: 0.09658491141682272\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.07889551328676461 TEST LOSS: 0.09910854689497282\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.07489088967364953 TEST LOSS: 0.09905027816111588\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.07668010527017027 TEST LOSS: 0.09886913124195258\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.07192625609562218 TEST LOSS: 0.09594316684797852\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x00000178137602E8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.20680364446981672 TEST LOSS: 0.1845689938951821\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.1897720442566447 TEST LOSS: 0.17601558342161125\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.16439685339137136 TEST LOSS: 0.16092527756767153\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.15361137324877025 TEST LOSS: 0.14465960194399122\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.1418328974844897 TEST LOSS: 0.139313234059227\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.13822211958677982 TEST LOSS: 0.13218608116812697\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.12452578765582305 TEST LOSS: 0.11631003502391118\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.12712162121029713 TEST LOSS: 0.11923594093014436\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.11678692344254439 TEST LOSS: 0.10663965148901387\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.10858613901653423 TEST LOSS: 0.09871477880955774\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.09988950067154431 TEST LOSS: 0.08799651749474414\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.10719148729040873 TEST LOSS: 0.09572355818919578\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.10678290220337407 TEST LOSS: 0.08896715327709667\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.09067874491179254 TEST LOSS: 0.07347389003705872\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.09464201164894852 TEST LOSS: 0.07835100291972028\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.095980505171003 TEST LOSS: 0.08178694502180699\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.09019396414527463 TEST LOSS: 0.0663044643603255\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.08986177756978024 TEST LOSS: 0.07179851693924064\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.0836031308564254 TEST LOSS: 0.06608131813769177\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.08104320796456198 TEST LOSS: 0.0605814597115334\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.07972109818075149 TEST LOSS: 0.059547022415581526\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.07837558418939296 TEST LOSS: 0.06292096905432847\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.0758315653832703 TEST LOSS: 0.05999819965430211\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.07624176239933551 TEST LOSS: 0.06526165613990248\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.07176514862157704 TEST LOSS: 0.05875941833844934\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.0703058038368707 TEST LOSS: 0.052413975651288754\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.07140424215399699 TEST LOSS: 0.05882094147028551\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.06973016154949241 TEST LOSS: 0.05427343419624927\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.07372595003559694 TEST LOSS: 0.05807205887394876\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.07063636872889217 TEST LOSS: 0.06119843896438132\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.07672779865434501 TEST LOSS: 0.06284238035695157\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.0715912896363331 TEST LOSS: 0.05335425038489234\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.07088651134066104 TEST LOSS: 0.057229686966284825\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.07057778640843289 TEST LOSS: 0.05789357864613492\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.07331102829554242 TEST LOSS: 0.0568748475966531\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.07003735371664686 TEST LOSS: 0.05668240881731821\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.07082056668907981 TEST LOSS: 0.05452272404306527\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.07001663041333252 TEST LOSS: 0.05626373651819957\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.0662937132420798 TEST LOSS: 0.05448514282263096\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.07206979609025065 TEST LOSS: 0.0582351402005999\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.07080593569934225 TEST LOSS: 0.06280999916700784\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.07026187297866263 TEST LOSS: 0.05784973449681451\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.07385662548316803 TEST LOSS: 0.061849620109004355\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.07131111722143717 TEST LOSS: 0.0544412807277432\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.07367484332043782 TEST LOSS: 0.06208127028577847\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.07046381668738262 TEST LOSS: 0.0551183642690393\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.07214579482427956 TEST LOSS: 0.0602852907941649\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.07268549316356558 TEST LOSS: 0.057355304641104464\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.07033780062851609 TEST LOSS: 0.05798481138702649\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.07288203598965894 TEST LOSS: 0.0579090511765816\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.07022218359385934 TEST LOSS: 0.057418692561397255\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x00000178117CE390>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.27631426120252567 TEST LOSS: 0.2255706531302074\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.23859837582565235 TEST LOSS: 0.21542534716663445\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.22046450883371388 TEST LOSS: 0.21006194602114286\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.18903421634732107 TEST LOSS: 0.18948340235140135\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.17179037759483837 TEST LOSS: 0.18347560823439127\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.1604614396851489 TEST LOSS: 0.1627691861943028\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.15556566797652485 TEST LOSS: 0.16837087502922296\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.14401417458169197 TEST LOSS: 0.13486654501370113\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.1394660855884332 TEST LOSS: 0.12955367361895434\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.13911623066645987 TEST LOSS: 0.14011293684508727\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.1203148375783616 TEST LOSS: 0.11298321459439206\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.1198401774622331 TEST LOSS: 0.10556792884155905\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.1205731237151773 TEST LOSS: 0.10413159821169415\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.12847561359117038 TEST LOSS: 0.11331198395907363\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.11831445392919078 TEST LOSS: 0.10518570390062496\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.11496989964012885 TEST LOSS: 0.09609702375734662\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.12063864355383644 TEST LOSS: 0.10102798305102903\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.1140747382613319 TEST LOSS: 0.09010472211564508\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.11047057633747465 TEST LOSS: 0.09662969322406086\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.10641889849133127 TEST LOSS: 0.0814630512444156\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.11024263945473817 TEST LOSS: 0.08930805612048111\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.10662289794843913 TEST LOSS: 0.09399470824930783\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.10354000444276529 TEST LOSS: 0.08856400175419743\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.1007659088594079 TEST LOSS: 0.08103749941632171\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.09935384244973562 TEST LOSS: 0.07754254894157943\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.1009723241436068 TEST LOSS: 0.08428787720187955\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.10257921355868048 TEST LOSS: 0.07769754599528453\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.10428076036115073 TEST LOSS: 0.07647417640428808\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.09988392875069298 TEST LOSS: 0.0702019089499779\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.10209983519079757 TEST LOSS: 0.0838511238263734\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.10189922230433689 TEST LOSS: 0.07562661041221853\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.10141628443346509 TEST LOSS: 0.07759329404678705\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.10266193274194867 TEST LOSS: 0.07728930031419286\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.10128831586712242 TEST LOSS: 0.0809775614712639\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.11086798022122824 TEST LOSS: 0.07430173379914583\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.10599899921941695 TEST LOSS: 0.07239901219900245\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.10678011854189018 TEST LOSS: 0.08146345217353121\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.10836593498241136 TEST LOSS: 0.07588735814305435\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.10607024688107186 TEST LOSS: 0.07635897233894591\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.10324208559228071 TEST LOSS: 0.07998565211848048\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.10426335179522114 TEST LOSS: 0.07552901792076257\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.1025798122392638 TEST LOSS: 0.07729033141320157\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.10606812814146385 TEST LOSS: 0.07485022508443288\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.10916603414712941 TEST LOSS: 0.07638814144250354\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.10874400818324712 TEST LOSS: 0.07786559563105873\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.10888990094556136 TEST LOSS: 0.08045053399398269\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.10743435014498981 TEST LOSS: 0.08119955175539269\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.10793517615482312 TEST LOSS: 0.08011263482856269\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.10465615066118737 TEST LOSS: 0.08005115106770354\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.11397562765753656 TEST LOSS: 0.078177720039552\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.11266520742386701 TEST LOSS: 0.07680098795183656\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x00000178117DF4A8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.2533420641441245 TEST LOSS: 0.3563038545849327\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.25337439380805954 TEST LOSS: 0.3114380816413377\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.2064467201564002 TEST LOSS: 0.22002884396269703\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.18797518707987732 TEST LOSS: 0.1677172973329873\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.16542411981316296 TEST LOSS: 0.16441111429513894\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.1637435193825228 TEST LOSS: 0.17531733159171423\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.16106540531246014 TEST LOSS: 0.16006416077348598\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.154810890214743 TEST LOSS: 0.14558822756765258\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.15551925526861554 TEST LOSS: 0.144905834165328\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.13481881816104196 TEST LOSS: 0.12635750903176143\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.15239828184643942 TEST LOSS: 0.1469969844923629\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.13760076982496072 TEST LOSS: 0.13848419728508204\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.13440147925428547 TEST LOSS: 0.1259739569809175\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.1273021774870262 TEST LOSS: 0.12938592383042466\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.11868421974066277 TEST LOSS: 0.12929126881390926\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.12355363805211336 TEST LOSS: 0.13919281776650347\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.12042570259634583 TEST LOSS: 0.1351098631969753\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.11284799216405883 TEST LOSS: 0.12296029948391834\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.09824360667782805 TEST LOSS: 0.11853231869515118\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.1043475507721507 TEST LOSS: 0.12026550710256488\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.10382166055237373 TEST LOSS: 0.11462204677581361\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.09908971352973404 TEST LOSS: 0.11697826784062716\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.0971563449533099 TEST LOSS: 0.10796555762667119\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.10137134305196352 TEST LOSS: 0.1107116215700837\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.09293788915855104 TEST LOSS: 0.09605131112908541\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.09939358751043677 TEST LOSS: 0.11851604014023158\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.09178352258084989 TEST LOSS: 0.11414568373627659\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.09560300047782758 TEST LOSS: 0.12160643460384266\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.08900929836514741 TEST LOSS: 0.11657392544465539\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.08396170698889117 TEST LOSS: 0.10654490183715322\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.08382875479931444 TEST LOSS: 0.10148642225837132\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.07989117146618685 TEST LOSS: 0.0997000257663977\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.08375835152626834 TEST LOSS: 0.10727100946196985\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.07969163473067685 TEST LOSS: 0.0968241589500179\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.09153169046857852 TEST LOSS: 0.12381562566276234\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.0851947854028044 TEST LOSS: 0.11072663880899859\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.08693564470172714 TEST LOSS: 0.11266143907595916\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.07984362600494496 TEST LOSS: 0.10877876220764825\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.08390097057288431 TEST LOSS: 0.11230657596845656\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.0771465993841254 TEST LOSS: 0.10013702108031709\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.07698169250308835 TEST LOSS: 0.09961005219462674\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.07961478217543429 TEST LOSS: 0.10594138670406279\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.07588197900539108 TEST LOSS: 0.09965292078792591\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.07827866223938058 TEST LOSS: 0.09821289456946992\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.07627310174570615 TEST LOSS: 0.09395016594971949\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.08218143903318756 TEST LOSS: 0.10533942804715318\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.08258251901923473 TEST LOSS: 0.11362202186955284\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.07589726254537976 TEST LOSS: 0.1028339105978275\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.08261774767563711 TEST LOSS: 0.10880707920557152\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.0770103087791716 TEST LOSS: 0.10186313582635703\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.07813836698611101 TEST LOSS: 0.10796245942341741\n",
      "0.07309655093133632 0.07852626632020968\n",
      "COMPUTING FOR ITERATION NUMBER 8\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x00000178117CE550>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.24652880334237307 TEST LOSS: 0.29200710134511104\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.2085457458981359 TEST LOSS: 0.28692521049450176\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.19270938349192365 TEST LOSS: 0.23844307900490846\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.18570460552852824 TEST LOSS: 0.20946541783370431\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.14298614999341158 TEST LOSS: 0.16039986102087664\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.13588541529331682 TEST LOSS: 0.1617487797641437\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.12175940866875253 TEST LOSS: 0.14949675554995728\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.12140904942927559 TEST LOSS: 0.15109893517339906\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.11175777478701826 TEST LOSS: 0.12867145329395616\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.1079285080416344 TEST LOSS: 0.12562176953453133\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.11306089472930794 TEST LOSS: 0.13085702670123334\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.10954278651925548 TEST LOSS: 0.12834093204411642\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.10173042812439238 TEST LOSS: 0.11226642202822718\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.10659626604434955 TEST LOSS: 0.11999211246962803\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.10180507465737106 TEST LOSS: 0.11332606433241636\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.09414933603460217 TEST LOSS: 0.10598317603789173\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.08829742616649662 TEST LOSS: 0.10241869881382944\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.08781180531807822 TEST LOSS: 0.1037932667583475\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.0800220903427926 TEST LOSS: 0.0995317199547676\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.0758704053811973 TEST LOSS: 0.0988036784640497\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.07831387138570334 TEST LOSS: 0.10232693559444786\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.07458211435692311 TEST LOSS: 0.09832782130823498\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.07937536178043547 TEST LOSS: 0.10480929296478353\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.07616826626555737 TEST LOSS: 0.09826576567377701\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.07276688442607163 TEST LOSS: 0.09822150743760952\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.07250066585094016 TEST LOSS: 0.09375700623953116\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.0701426278716252 TEST LOSS: 0.09454979608330419\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.07096306282502811 TEST LOSS: 0.09551431080563719\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.07031196475444607 TEST LOSS: 0.09591482722122496\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.07559631502367889 TEST LOSS: 0.10169159300026687\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.07481586254912591 TEST LOSS: 0.09977572684225322\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.07338971797594525 TEST LOSS: 0.0874740955833502\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.07042905698616735 TEST LOSS: 0.09733659633683354\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.07220967010846062 TEST LOSS: 0.09520465089459036\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.07187912032829229 TEST LOSS: 0.09783721055062533\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.06940718479189266 TEST LOSS: 0.09425183409233052\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.07504638221963467 TEST LOSS: 0.09536145292091562\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.0750808875359969 TEST LOSS: 0.09399055730700726\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.0735622488001672 TEST LOSS: 0.0939296925906099\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.07090819456585963 TEST LOSS: 0.09143168097984711\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.07096714596438443 TEST LOSS: 0.09493784722159643\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.0736795187091901 TEST LOSS: 0.09647241463729339\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.06850096756997437 TEST LOSS: 0.09521400998086356\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.06797804517918345 TEST LOSS: 0.09135414983683841\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.06770869673651657 TEST LOSS: 0.08875801486269116\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.07190953140187929 TEST LOSS: 0.09695697822063805\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.06758424913330542 TEST LOSS: 0.0875557167359409\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.07322071501228089 TEST LOSS: 0.0863335527019649\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.07492773625703292 TEST LOSS: 0.096711229989498\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.07222114170768985 TEST LOSS: 0.08714581089431558\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.07629528550426236 TEST LOSS: 0.09486789275776326\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000017810E9A240>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.19670666503812692 TEST LOSS: 0.1908708049985923\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.17442449769334104 TEST LOSS: 0.18578652048931726\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.16921279732104497 TEST LOSS: 0.18132270919741175\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.15134829116187587 TEST LOSS: 0.1523994218622864\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.14305220187886297 TEST LOSS: 0.14876657750656666\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.13251865017891284 TEST LOSS: 0.13451877312857669\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.11290268720291789 TEST LOSS: 0.12153291911390564\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.09596315352974 TEST LOSS: 0.10526455973466027\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.10204787272452445 TEST LOSS: 0.11241875458320096\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.10122397727394225 TEST LOSS: 0.09925770204318372\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.09264534223089792 TEST LOSS: 0.08930675613379854\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.08961585421430909 TEST LOSS: 0.09595232531017486\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.08407134664895248 TEST LOSS: 0.08558842865042299\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.0842412408258261 TEST LOSS: 0.08462617487428682\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.08327260210919893 TEST LOSS: 0.07882488474744985\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.07805846395357681 TEST LOSS: 0.07529045956323299\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.08057778401347342 TEST LOSS: 0.08968467152244973\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.07656677630775648 TEST LOSS: 0.08061549568400513\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.07017088063554072 TEST LOSS: 0.07529724827490766\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.07186324860154583 TEST LOSS: 0.08102382873568585\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.06831460512297412 TEST LOSS: 0.07916083427532863\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.06711709870065725 TEST LOSS: 0.0741546219422067\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.06602724465072932 TEST LOSS: 0.06635318922271985\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.062410283933290366 TEST LOSS: 0.07160338487163613\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.06469821741482612 TEST LOSS: 0.0645694282574112\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.06321678314559927 TEST LOSS: 0.07073100543724925\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.06444867562169733 TEST LOSS: 0.06791539871762062\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.058882497633943466 TEST LOSS: 0.06467379634717128\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.06147081638433834 TEST LOSS: 0.065265056030578\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.06469682952785803 TEST LOSS: 0.06587985174483152\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.06447137924343617 TEST LOSS: 0.06409041893571706\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.06520953846055512 TEST LOSS: 0.06780474505069665\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.060549170238060196 TEST LOSS: 0.06726035287047634\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.060301958523808576 TEST LOSS: 0.0640949507025024\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.06626149514847632 TEST LOSS: 0.07020045053442273\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.06222464437936346 TEST LOSS: 0.06670235091435484\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.06205382278735573 TEST LOSS: 0.06045040932632756\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.06743313360567159 TEST LOSS: 0.06547769087691278\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.0654849223793385 TEST LOSS: 0.06224295514226496\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.06463272900053342 TEST LOSS: 0.06909317687053343\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.06423718433777664 TEST LOSS: 0.06282725922039008\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.06590308868585644 TEST LOSS: 0.06574223296205689\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.06651960406269407 TEST LOSS: 0.0655605128165563\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.06498155259400687 TEST LOSS: 0.061725080049577837\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.06676268259758245 TEST LOSS: 0.06111823594396036\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.06590554374070126 TEST LOSS: 0.06468409937984092\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.06832032855620135 TEST LOSS: 0.06384253785667825\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.06630862283220525 TEST LOSS: 0.06386595002907934\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.06349681906557068 TEST LOSS: 0.06429634799493852\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.06670574177829533 TEST LOSS: 0.06110193677950636\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.0682668999945019 TEST LOSS: 0.05892072916008914\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000017810E3CC88>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.2579172993742619 TEST LOSS: 0.2504434849982219\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.25818055979850163 TEST LOSS: 0.2159494461461504\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.19953981502293064 TEST LOSS: 0.16849759817167148\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.1978963069270046 TEST LOSS: 0.1753109028889403\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.1896419521659285 TEST LOSS: 0.1673203431956908\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.1853637521862379 TEST LOSS: 0.16579202035258556\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.1653432173200291 TEST LOSS: 0.15433298464423345\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.1334230442579098 TEST LOSS: 0.14068025392824432\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.1246514116320465 TEST LOSS: 0.12543319175514736\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.12213318866784165 TEST LOSS: 0.12138736755937948\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.12616310083542853 TEST LOSS: 0.11901295211781206\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.12013672920853291 TEST LOSS: 0.11589777423353499\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.11723870148082975 TEST LOSS: 0.11763011057212733\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.11174400373319174 TEST LOSS: 0.11508365659234612\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.1219894194864055 TEST LOSS: 0.11290878107113274\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.11655857962759363 TEST LOSS: 0.11225640450051486\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.10768986958039242 TEST LOSS: 0.10861137660687797\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.11178046398998517 TEST LOSS: 0.10858089168880736\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.10875792232775815 TEST LOSS: 0.10420048992771173\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.10441450773108416 TEST LOSS: 0.09693887582126366\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.10131993893797125 TEST LOSS: 0.09299785343707984\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.10429036735005418 TEST LOSS: 0.09572934152205705\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.10546609798749412 TEST LOSS: 0.09545324548551147\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.10014435846989224 TEST LOSS: 0.08108197826556544\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.10188234949662683 TEST LOSS: 0.08138792819393526\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.10389702409735252 TEST LOSS: 0.08261999953425246\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.10186595516655339 TEST LOSS: 0.07526464921205615\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.10402827127801204 TEST LOSS: 0.08085763235319865\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.09585315832080789 TEST LOSS: 0.06941475597412279\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.09359024533054613 TEST LOSS: 0.07415194749928769\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.09718587135231414 TEST LOSS: 0.06880057295956839\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.09337998347226659 TEST LOSS: 0.06735321997691918\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.09584251671171086 TEST LOSS: 0.07362338124827648\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.09440346564351834 TEST LOSS: 0.06744857587592128\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.09303983757349653 TEST LOSS: 0.06860207790446969\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.09354208259877175 TEST LOSS: 0.07010551149894037\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.09080745662921808 TEST LOSS: 0.06658006536881052\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.09212853891076517 TEST LOSS: 0.06822727580614998\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.09106998953096887 TEST LOSS: 0.06513213240032711\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.08871993490093613 TEST LOSS: 0.06495469390391585\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.0920628210731183 TEST LOSS: 0.07029692583885432\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.09175811520075769 TEST LOSS: 0.06481058746619171\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.08999903535624677 TEST LOSS: 0.0686420668246898\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.09200649226152423 TEST LOSS: 0.06739364846770463\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.09179776502904913 TEST LOSS: 0.06829663639083633\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.08887261959212338 TEST LOSS: 0.06537330256308833\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.08945236093560674 TEST LOSS: 0.06980234307442834\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.08921661251893889 TEST LOSS: 0.06690425225569815\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.09037335479206188 TEST LOSS: 0.06615018768064213\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.09023102565765838 TEST LOSS: 0.06721062965743856\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.0890280106421204 TEST LOSS: 0.07066052446705716\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001781100B128>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.2173048744169802 TEST LOSS: 0.3181410404701372\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.20154902069362632 TEST LOSS: 0.2056184398693915\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.19348323479099047 TEST LOSS: 0.18199395247090233\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.17755764987567726 TEST LOSS: 0.1492613909789429\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.1752715037336718 TEST LOSS: 0.15408997326042598\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.16477477810566593 TEST LOSS: 0.14149987078916676\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.14798672032081436 TEST LOSS: 0.10964084127286869\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.14657380738964432 TEST LOSS: 0.1095498564688512\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.1380663291196006 TEST LOSS: 0.1008125064862429\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.1377625246740336 TEST LOSS: 0.09781144052433144\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.13520916733572605 TEST LOSS: 0.10071584038497437\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.11918420100498202 TEST LOSS: 0.07895371670377234\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.12429696092951464 TEST LOSS: 0.09268114910735854\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.1187291530710029 TEST LOSS: 0.09120140139209633\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.1174223628593259 TEST LOSS: 0.08343290227043236\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.10979486791300842 TEST LOSS: 0.07746291875055024\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.11167682660929813 TEST LOSS: 0.08174246666269581\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.10644914641339158 TEST LOSS: 0.0752095105676484\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.10009244485378016 TEST LOSS: 0.06811196843276526\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.0984676957980089 TEST LOSS: 0.06223030033391771\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.09734671745531477 TEST LOSS: 0.0644657146668863\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.10430617229133317 TEST LOSS: 0.0759139110760626\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.09033404705509182 TEST LOSS: 0.07068758000011104\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.09653076539640526 TEST LOSS: 0.06858957446679953\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.08997537721677855 TEST LOSS: 0.0653581719838849\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.09628041615275665 TEST LOSS: 0.07763008360268714\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.09104268271514109 TEST LOSS: 0.0750747130014678\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.09154003783535057 TEST LOSS: 0.07499673103016546\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.08806002443617279 TEST LOSS: 0.06631698945038933\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.09014127462178849 TEST LOSS: 0.07121079531117437\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.08910513395725422 TEST LOSS: 0.05911934288415276\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.08708213506130012 TEST LOSS: 0.06000285117410601\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.0946168926138036 TEST LOSS: 0.0740609062291753\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.08889767407794202 TEST LOSS: 0.0816609364750048\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.08961209055084025 TEST LOSS: 0.08336472908359994\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.08388894532621838 TEST LOSS: 0.061116902601551205\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.08416439350855111 TEST LOSS: 0.07142515332180178\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.08782899286238359 TEST LOSS: 0.06934278713460988\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.0850723278546279 TEST LOSS: 0.06901482360398127\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.0863572696398912 TEST LOSS: 0.05756968459169999\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.0866641277996194 TEST LOSS: 0.06483141689095968\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.08513836841011428 TEST LOSS: 0.07040067991004112\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.08581436093615454 TEST LOSS: 0.07092060437326694\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.08683920123693237 TEST LOSS: 0.0665419020053449\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.08391206063501436 TEST LOSS: 0.06331474849663347\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.08513179225467406 TEST LOSS: 0.07785328654763887\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.08690968625943175 TEST LOSS: 0.0746639745275913\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.08401798147107484 TEST LOSS: 0.06555725848627617\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.08523612777081525 TEST LOSS: 0.0704206920656688\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.08451057941609944 TEST LOSS: 0.07560958796412824\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.08429354876872058 TEST LOSS: 0.07082282243978036\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x00000178118C9F60>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.23717794323699262 TEST LOSS: 0.35311705132080756\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.23717794323699262 TEST LOSS: 0.35416760426726324\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.23717794323699262 TEST LOSS: 0.35416760426726324\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.1937040042708308 TEST LOSS: 0.2539380780222519\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.16695140375002226 TEST LOSS: 0.2419303360565303\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.15112387229896804 TEST LOSS: 0.24012658046175303\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.13943378298580553 TEST LOSS: 0.23020050875795373\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.1254452303915142 TEST LOSS: 0.2288754254379778\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.11418078568702691 TEST LOSS: 0.2024339455375297\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.1196856217711598 TEST LOSS: 0.20001928504434024\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.10779846111858121 TEST LOSS: 0.1604922801690353\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.10349705170924793 TEST LOSS: 0.14833144124191092\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.10489016527245794 TEST LOSS: 0.1574505867140832\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.09793184416556737 TEST LOSS: 0.13357230540612083\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.10050005752358117 TEST LOSS: 0.14733992407866828\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.09878146251033777 TEST LOSS: 0.14132145768101145\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.09305009429675351 TEST LOSS: 0.1229655481567852\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.09697002188346845 TEST LOSS: 0.13572044508298495\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.09863165370750947 TEST LOSS: 0.13792087592984234\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.09897491199262459 TEST LOSS: 0.14510267824229695\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.0968817888568806 TEST LOSS: 0.1444921896460021\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.10028507436615539 TEST LOSS: 0.13874618647092993\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.09378178164457097 TEST LOSS: 0.13562927154000556\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.09176091236388118 TEST LOSS: 0.12829559450899988\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.09179138422314008 TEST LOSS: 0.12534877194809052\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.09023725442155311 TEST LOSS: 0.1294418777785521\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.09241426844853044 TEST LOSS: 0.12850681171304368\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.08353236195027865 TEST LOSS: 0.12592474154828528\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.08358725114384456 TEST LOSS: 0.12804095130378976\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.0858299841568301 TEST LOSS: 0.13218163444050796\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.08186835555915101 TEST LOSS: 0.12251710912579174\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.08687371674622027 TEST LOSS: 0.1283821369904959\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.07919295067506243 TEST LOSS: 0.1164380333779264\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.08060054011457683 TEST LOSS: 0.12433757817200657\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.07857140557369247 TEST LOSS: 0.12263838802765817\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.08215741464092331 TEST LOSS: 0.1238853086599359\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.07380184725796103 TEST LOSS: 0.10959645055058734\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.07698770552060612 TEST LOSS: 0.12281678774223229\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.07357129396582665 TEST LOSS: 0.11609317122785048\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.0759560336169104 TEST LOSS: 0.11612865283701852\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.07986465365297497 TEST LOSS: 0.12092602531287205\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.08617394385192517 TEST LOSS: 0.13320091251242433\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.0797019359700815 TEST LOSS: 0.12376106249653361\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.07801769314413337 TEST LOSS: 0.12156738681368792\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.07552286304673314 TEST LOSS: 0.11605635836793671\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.07889113031453227 TEST LOSS: 0.12073662166861587\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.0816890329599266 TEST LOSS: 0.12373241431910909\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.07313045519749184 TEST LOSS: 0.1134999846041525\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.08079412822827085 TEST LOSS: 0.11654569490394547\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.07530611465410482 TEST LOSS: 0.11264174026784732\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.07659553451818248 TEST LOSS: 0.11645723285803139\n",
      "0.07249215060760424 0.07721592931564149\n",
      "COMPUTING FOR ITERATION NUMBER 9\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001781330F780>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.20649379939336965 TEST LOSS: 0.26612544346564293\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.2021440036005366 TEST LOSS: 0.266154161274331\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.193808419541998 TEST LOSS: 0.21955442658214513\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.19336364269455325 TEST LOSS: 0.18336876085104092\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.1717191511353637 TEST LOSS: 0.15689031419662783\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.1612341234197971 TEST LOSS: 0.1555378273880757\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.15369914560054485 TEST LOSS: 0.13696584229811146\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.15571419042257806 TEST LOSS: 0.1334988793092768\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.15609294173312288 TEST LOSS: 0.13712553729296859\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.14827487685368773 TEST LOSS: 0.13234685224027049\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.1247174438979133 TEST LOSS: 0.11681631956408386\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.12549149549442967 TEST LOSS: 0.11791557490667594\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.12235467456796223 TEST LOSS: 0.11479970591087081\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.11561209176294307 TEST LOSS: 0.11418683293600457\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.11362864578925434 TEST LOSS: 0.10523467982378903\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.11081505804884297 TEST LOSS: 0.11096427698453397\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.1070241750211415 TEST LOSS: 0.09976393375583213\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.10806535571700822 TEST LOSS: 0.10539776174162198\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.10401710542704337 TEST LOSS: 0.10619736145990612\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.10551680193608494 TEST LOSS: 0.09912389524847344\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.09766175402166816 TEST LOSS: 0.09677353602824111\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.10247551898196054 TEST LOSS: 0.09531177791731732\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.11096815823606766 TEST LOSS: 0.10812796284965193\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.1063140142238361 TEST LOSS: 0.1029121185154733\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.09643543533237016 TEST LOSS: 0.09469754721248698\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.10558894010077398 TEST LOSS: 0.09956314788410787\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.09385247558650325 TEST LOSS: 0.09179492839694439\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.09505079487300717 TEST LOSS: 0.08378852567016049\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.1057021829155705 TEST LOSS: 0.10680835888060013\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.09013107365910092 TEST LOSS: 0.0814543780748534\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.10420500389356524 TEST LOSS: 0.10462994758894613\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.10606306675339824 TEST LOSS: 0.09719957906066647\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.09816264785084008 TEST LOSS: 0.09120385537991937\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.09883587323369233 TEST LOSS: 0.09143133982810338\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.08820358423808825 TEST LOSS: 0.07362630694086818\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.1075008847440324 TEST LOSS: 0.10055297547855122\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.09951025780191534 TEST LOSS: 0.09332254149347002\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.0992885024259051 TEST LOSS: 0.09261103185754845\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.10563229123133061 TEST LOSS: 0.09900626755611312\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.09861775687038105 TEST LOSS: 0.09031068720587396\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.10359745493738454 TEST LOSS: 0.09405230043784593\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.10001505020801499 TEST LOSS: 0.09419781134166226\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.09774788880984821 TEST LOSS: 0.09151068665871516\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.09928695655202059 TEST LOSS: 0.09252878266571922\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.10538809781946955 TEST LOSS: 0.10049316691054157\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.10439169610156376 TEST LOSS: 0.09026939326741704\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.10237809100671567 TEST LOSS: 0.09638794693782879\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.10313217406025342 TEST LOSS: 0.09781512592147278\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.0950418625627831 TEST LOSS: 0.08626603233385258\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.09267600106654017 TEST LOSS: 0.08250994261202471\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.10155082242948187 TEST LOSS: 0.08992111792432039\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x00000178117DFDA0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.28206072507163016 TEST LOSS: 0.19782519797127499\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.23268607908219477 TEST LOSS: 0.1531389358218083\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.21423853090518624 TEST LOSS: 0.14235037615992538\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.16530345057362078 TEST LOSS: 0.11434325070024029\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.1803656112824826 TEST LOSS: 0.1043062904683619\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.15098870117603233 TEST LOSS: 0.09558401628225413\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.14665743793877095 TEST LOSS: 0.08418688825763168\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.13855618865431266 TEST LOSS: 0.08377284747295478\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.1225335826272166 TEST LOSS: 0.07379289039855498\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.12046399215607911 TEST LOSS: 0.07358529282742736\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.10522579207502747 TEST LOSS: 0.06082950452992049\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.10082069647043916 TEST LOSS: 0.05741669625902557\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.09465263785776244 TEST LOSS: 0.05283343273363986\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.10736414605048532 TEST LOSS: 0.063553155667663\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.1029871198822193 TEST LOSS: 0.057630096415972464\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.10064980389995427 TEST LOSS: 0.05544605186090981\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.08928008867296955 TEST LOSS: 0.04697385639703915\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.09828025694024216 TEST LOSS: 0.05368746663062203\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.08892993770204528 TEST LOSS: 0.046532848537700046\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.09247533272847773 TEST LOSS: 0.047569321763248365\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.08341904529783234 TEST LOSS: 0.04455975584096289\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.08743073185109326 TEST LOSS: 0.046560727724362254\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.07817413179280908 TEST LOSS: 0.04236839766548871\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.09157445728179738 TEST LOSS: 0.046728809034458106\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.08039438369986744 TEST LOSS: 0.04244511905977446\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.08961807329757342 TEST LOSS: 0.04600877591398063\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.08811274756425572 TEST LOSS: 0.04810164373496583\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.0741225149193261 TEST LOSS: 0.042636823309214325\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.06884914984771598 TEST LOSS: 0.04598743826911198\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.08056824886207242 TEST LOSS: 0.04642632342365775\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.07623030419675317 TEST LOSS: 0.04685334159868755\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.07790530532786882 TEST LOSS: 0.04996780866880506\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.0811003068692359 TEST LOSS: 0.0456840537902836\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.07688368405046898 TEST LOSS: 0.04586025224666701\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.0818246434753556 TEST LOSS: 0.05005742685164912\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.08014152338604272 TEST LOSS: 0.04739541304810753\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.08229360099032963 TEST LOSS: 0.04915955258662164\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.07124285700864472 TEST LOSS: 0.04812463875928099\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.06727422111699911 TEST LOSS: 0.04413337898716513\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.08693989691906466 TEST LOSS: 0.05028860796944193\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.07323055650110173 TEST LOSS: 0.04499170280724382\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.07997669066761681 TEST LOSS: 0.04592813616313072\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.08128781248969355 TEST LOSS: 0.04758950136921841\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.07758868360395049 TEST LOSS: 0.045353901510470335\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.07631951541310981 TEST LOSS: 0.04851645387613066\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.07900850994147975 TEST LOSS: 0.048329605685335654\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.08315914427852421 TEST LOSS: 0.050463309581537226\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.0769599249085033 TEST LOSS: 0.04874653498730726\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.09318505397671337 TEST LOSS: 0.05641946065648677\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.08603778100658095 TEST LOSS: 0.051758201822963146\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.08172311929601339 TEST LOSS: 0.04853382735271204\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001781182A2B0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.3125981392911344 TEST LOSS: 0.20115979936811337\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.3114028887847771 TEST LOSS: 0.20115979936811337\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.1912923477265715 TEST LOSS: 0.1507857910201864\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.1986065143361027 TEST LOSS: 0.1455894638239259\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.15757144971855186 TEST LOSS: 0.1376008035268141\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.1469144603678926 TEST LOSS: 0.12779244347070765\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.11600087407445966 TEST LOSS: 0.11520011183204548\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.12610023056043226 TEST LOSS: 0.10809633129754423\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.10674146322504108 TEST LOSS: 0.101524833008585\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.10273133059765367 TEST LOSS: 0.09557609377934892\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.10857254029181648 TEST LOSS: 0.09838757076561465\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.1098549218951589 TEST LOSS: 0.0904398118807406\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.09588437073303058 TEST LOSS: 0.08797658240345672\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.09724534957483053 TEST LOSS: 0.0881557395497987\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.09402163557008766 TEST LOSS: 0.08317343173259427\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.08828619179449075 TEST LOSS: 0.08235379318869471\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.09260329143172928 TEST LOSS: 0.07656276720496584\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.08182871988301026 TEST LOSS: 0.08310685352179815\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.08111024766327814 TEST LOSS: 0.08080693218656529\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.07908262137708547 TEST LOSS: 0.07867842204999995\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.07393445451796583 TEST LOSS: 0.07566202698594064\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.08162816208799686 TEST LOSS: 0.06931255937202133\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.09062577355760318 TEST LOSS: 0.06539719829529682\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.07918167018224866 TEST LOSS: 0.07235317967883828\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.08418326604558322 TEST LOSS: 0.0669264680147669\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.07501233655930069 TEST LOSS: 0.07104531708723288\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.08307292355668208 TEST LOSS: 0.06194049472915441\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.07549303315155151 TEST LOSS: 0.07052975262159152\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.08609303280849942 TEST LOSS: 0.06528808132793812\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.07638917167146142 TEST LOSS: 0.06659619772185603\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.08998613850188038 TEST LOSS: 0.06416000950506091\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.07799678061555528 TEST LOSS: 0.06997703477905741\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.08504571322684161 TEST LOSS: 0.06548316627152502\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.08365943185955949 TEST LOSS: 0.06569731265508455\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.08656606200692515 TEST LOSS: 0.06136620436812882\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.07761684879057164 TEST LOSS: 0.06424502634160094\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.07841874329154995 TEST LOSS: 0.06658453275648916\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.08310542859988934 TEST LOSS: 0.06336379235476987\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.07818085771178317 TEST LOSS: 0.06729406697094958\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.08108107716412423 TEST LOSS: 0.06583700638849097\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.08995416820771171 TEST LOSS: 0.06547875949506378\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.08311963165503408 TEST LOSS: 0.06702075337972507\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.08733147217029179 TEST LOSS: 0.06108887770957975\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.07771354676944094 TEST LOSS: 0.07227687964992706\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.07952818946826659 TEST LOSS: 0.06521562946268576\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.07667169211505619 TEST LOSS: 0.06391747231956017\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.0883263031349491 TEST LOSS: 0.06064840818453917\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.08332279517525469 TEST LOSS: 0.05972886030644436\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.08325925967586167 TEST LOSS: 0.060931920398525595\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.08323379778012024 TEST LOSS: 0.06385151077343956\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.08243946537831852 TEST LOSS: 0.0640566718434577\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000017810E9A208>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.22436517296682976 TEST LOSS: 0.29345675483025907\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.22436517296682976 TEST LOSS: 0.2832321859999485\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.16601424921183017 TEST LOSS: 0.17464511183245765\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.1569992561084472 TEST LOSS: 0.17059264214081973\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.14138847445642483 TEST LOSS: 0.15907635258815467\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.13691104144758426 TEST LOSS: 0.16604079637228983\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.12518301148646255 TEST LOSS: 0.1512538126830212\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.10576372690261791 TEST LOSS: 0.1429951133694981\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.09791894659756487 TEST LOSS: 0.13458670295393685\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.10244104085746013 TEST LOSS: 0.13816619773942468\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.089274592675219 TEST LOSS: 0.12239973318909331\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.08926592617858468 TEST LOSS: 0.12147653105384876\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.08291295524018383 TEST LOSS: 0.12637554691906375\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.08323290813818135 TEST LOSS: 0.12830826221675612\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.08134609147356421 TEST LOSS: 0.11511277557459218\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.08043700130210277 TEST LOSS: 0.1149426813361261\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.07972813832192142 TEST LOSS: 0.11376118108614643\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.0779354789299211 TEST LOSS: 0.11144604238799163\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.07964564860421663 TEST LOSS: 0.11232569559070368\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.07913284932047839 TEST LOSS: 0.11544117921304999\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.07761039082609132 TEST LOSS: 0.10578364692944459\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.0808805526353288 TEST LOSS: 0.10733586099289823\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.07752142819492512 TEST LOSS: 0.10473516886928441\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.07926211253995843 TEST LOSS: 0.10592410109855811\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.07885220084565961 TEST LOSS: 0.10135921696286798\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.0754591335029199 TEST LOSS: 0.10331489938703847\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.07699692580452921 TEST LOSS: 0.10716195889075247\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.0732033030177155 TEST LOSS: 0.09455615242144969\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.07414618603321971 TEST LOSS: 0.09916548463961992\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.07614425232413542 TEST LOSS: 0.1003890363212577\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.07986881985374185 TEST LOSS: 0.10760312572883783\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.07343594956553649 TEST LOSS: 0.09513944156971865\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.07406272685923496 TEST LOSS: 0.09793336476535279\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.07378743108953958 TEST LOSS: 0.09512947624289503\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.07285471084368024 TEST LOSS: 0.09434224766160619\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.07560539813167258 TEST LOSS: 0.09953578729789632\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.07321805723993098 TEST LOSS: 0.09506722065775997\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.07445840101262183 TEST LOSS: 0.09879693458378534\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.07684833367861674 TEST LOSS: 0.0972710616651112\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.07690267602808244 TEST LOSS: 0.09857582070638196\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.07566799475317239 TEST LOSS: 0.09314800958326773\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.07338380136869534 TEST LOSS: 0.08929201451142703\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.07251693009000063 TEST LOSS: 0.09145159797725644\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.0719491170724717 TEST LOSS: 0.08879037957434022\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.07132235627773043 TEST LOSS: 0.08836439639020871\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.07415896275084391 TEST LOSS: 0.09471658958870477\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.07273779239771304 TEST LOSS: 0.09729332952415291\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.07452759116848492 TEST LOSS: 0.09395838903899896\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.07340348956821871 TEST LOSS: 0.09325076413184473\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.07425565925671736 TEST LOSS: 0.09979731267348721\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.07737127034447557 TEST LOSS: 0.10196111857360096\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000017810E3C0F0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.25970191768087997 TEST LOSS: 0.23704068925101654\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.25970191768087997 TEST LOSS: 0.23704068925101654\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.24140009090029368 TEST LOSS: 0.2141554815935342\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.21653258559468097 TEST LOSS: 0.18018381974939396\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.2024348537595763 TEST LOSS: 0.15634438461921873\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.18756644370735945 TEST LOSS: 0.16341184957864657\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.13302075215425777 TEST LOSS: 0.14073238876104083\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.13383791194185748 TEST LOSS: 0.14032665394366642\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.12244306531899965 TEST LOSS: 0.1323643891156\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.11343735468604468 TEST LOSS: 0.12502950173678964\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.12546888278946733 TEST LOSS: 0.12370399468200362\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.10381038959665238 TEST LOSS: 0.12007310199948128\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.1176829667978986 TEST LOSS: 0.12063891155706068\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.10176164842291223 TEST LOSS: 0.11551722971492832\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.09923254417368302 TEST LOSS: 0.11303956406337753\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.10214923692658441 TEST LOSS: 0.11571548890438814\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.1006423595361455 TEST LOSS: 0.11044709711711863\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.09943157182019323 TEST LOSS: 0.1088217511600027\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.10081336652483296 TEST LOSS: 0.10839869057261291\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.08882164236128674 TEST LOSS: 0.10197251600330372\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.09080912245952126 TEST LOSS: 0.1022834798657663\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.08931339613787678 TEST LOSS: 0.1013819970801916\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.09371992630745897 TEST LOSS: 0.10309903304877499\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.09763909180748244 TEST LOSS: 0.10169153917810499\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.08832493311806106 TEST LOSS: 0.06950552059776875\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.09676102670262253 TEST LOSS: 0.09361690393380541\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.09316306295934211 TEST LOSS: 0.09385428188513703\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.09607405693541184 TEST LOSS: 0.10198059019066524\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.08782817594542092 TEST LOSS: 0.08478320143122492\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.08351295958845693 TEST LOSS: 0.08133541951525738\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.08282238165238742 TEST LOSS: 0.07783146992037582\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.08560482778199507 TEST LOSS: 0.08329257408089703\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.08633014236536915 TEST LOSS: 0.07347715285642835\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.08204017998958534 TEST LOSS: 0.07165784412164537\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.08250838773119928 TEST LOSS: 0.07461683914477184\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.08036664645664846 TEST LOSS: 0.07690361175666431\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.08069082295397129 TEST LOSS: 0.06990292643568541\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.0884980161601076 TEST LOSS: 0.07381903464760048\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.08381815664430556 TEST LOSS: 0.07145224267739891\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.0818762945454404 TEST LOSS: 0.06849828236147233\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.07869184660947956 TEST LOSS: 0.06989411986227552\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.07866877768792851 TEST LOSS: 0.06952237141789334\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.08311224235342979 TEST LOSS: 0.07010577038189998\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.08306480791709496 TEST LOSS: 0.07256450661908644\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.0815311285058127 TEST LOSS: 0.06853584264607551\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.08510452748548192 TEST LOSS: 0.07203189918357987\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.08662842618713337 TEST LOSS: 0.07582052358960037\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.08426827158045404 TEST LOSS: 0.07253533562169184\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.08156271495120984 TEST LOSS: 0.07289834649772152\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.08613584772895799 TEST LOSS: 0.07629521728465077\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.08385511031403461 TEST LOSS: 0.07444988877695088\n",
      "0.07639966566428688 0.06995634298818795\n",
      "COMPUTING FOR ITERATION NUMBER 10\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000017810D51F28>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.25928843842671473 TEST LOSS: 0.21211882520757122\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.22245329900837094 TEST LOSS: 0.2112488364737478\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.19534119031636107 TEST LOSS: 0.16991347168430476\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.1899990441860187 TEST LOSS: 0.1444744332951858\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.17859757853074917 TEST LOSS: 0.14363787388221327\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.16338525097935963 TEST LOSS: 0.1293994924657815\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.14504364748332035 TEST LOSS: 0.13207366705195137\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.14629172653322714 TEST LOSS: 0.1255146195151478\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.15700881126295965 TEST LOSS: 0.13072583775534613\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.12292686608184811 TEST LOSS: 0.10529503669589052\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.13692523137635748 TEST LOSS: 0.11506066868378764\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.12579985270649088 TEST LOSS: 0.10903198409801536\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.1269323629418115 TEST LOSS: 0.10266252413550683\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.13526431957595433 TEST LOSS: 0.10885031689335836\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.11704486049237421 TEST LOSS: 0.10043654352779569\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.11313486880737475 TEST LOSS: 0.10211557353261841\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.12488236363696623 TEST LOSS: 0.09974421874872183\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.10894368974173965 TEST LOSS: 0.09474465256030008\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.11831371893077344 TEST LOSS: 0.0977039369576062\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.10655977361589869 TEST LOSS: 0.0937555041570008\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.11068484815881076 TEST LOSS: 0.09773191353444743\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.10878103584554459 TEST LOSS: 0.09474496547418829\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.11323936952838391 TEST LOSS: 0.0907879332086789\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.0995016312779677 TEST LOSS: 0.08751119170529327\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.09993477117833653 TEST LOSS: 0.09154850396194604\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.08987857303057273 TEST LOSS: 0.08169336502661999\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.09207030649010801 TEST LOSS: 0.08443983799957314\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.11059322796631833 TEST LOSS: 0.09430969006657841\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.08976483902483909 TEST LOSS: 0.08188346635690782\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.0881332061898218 TEST LOSS: 0.08498144169702342\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.0931899351765164 TEST LOSS: 0.08368063453101765\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.09357871464868042 TEST LOSS: 0.0836431661784708\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.09396544630195784 TEST LOSS: 0.0840456828066696\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.08449262328837875 TEST LOSS: 0.0793322324982591\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.08751782937180337 TEST LOSS: 0.07762748838739766\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.08363769472904316 TEST LOSS: 0.0777394276387534\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.09569826437424582 TEST LOSS: 0.08415272983477892\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.09516510982890987 TEST LOSS: 0.0832749202347182\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.09494444298118497 TEST LOSS: 0.08081641790637115\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.09749066912896186 TEST LOSS: 0.08410365069188724\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.09872565831716107 TEST LOSS: 0.08160820675718328\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.09398082313846674 TEST LOSS: 0.07905572571543822\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.09073197226890654 TEST LOSS: 0.0779563595316786\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.09215901495483342 TEST LOSS: 0.078710735542822\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.09218949156470493 TEST LOSS: 0.0795919351788646\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.08878384133844708 TEST LOSS: 0.07685467623497036\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.09446294899693115 TEST LOSS: 0.07706721252578766\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.09362476271047593 TEST LOSS: 0.07690186762064596\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.09915828494164382 TEST LOSS: 0.08097871082307996\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.09209148341795682 TEST LOSS: 0.07687304086947594\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.08717111334656755 TEST LOSS: 0.0762584600187677\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000017810C50780>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.2484626112566648 TEST LOSS: 0.3060430629032032\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.2373105324757753 TEST LOSS: 0.2818751739599756\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.20967818443777989 TEST LOSS: 0.2082022545415241\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.20416888639243805 TEST LOSS: 0.19648797640475\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.18125300057140434 TEST LOSS: 0.19043536945399664\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.18066921280194084 TEST LOSS: 0.20278015995519033\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.1694697731345832 TEST LOSS: 0.18412373994787226\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.1565284019843111 TEST LOSS: 0.17181312551011438\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.16022038961408067 TEST LOSS: 0.17310619166518573\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.15994155584832642 TEST LOSS: 0.17079722039343026\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.1523034722862943 TEST LOSS: 0.16336627966346273\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.15062711288227013 TEST LOSS: 0.16595298546323087\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.15567124496755338 TEST LOSS: 0.16595012467081924\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.1472105549559017 TEST LOSS: 0.16059186564607542\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.14869621764521673 TEST LOSS: 0.15774612962453874\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.13135398521570746 TEST LOSS: 0.15850610723454797\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.1344295553623392 TEST LOSS: 0.15656512206455553\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.11858253696297784 TEST LOSS: 0.15522172949913055\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.11678676480121865 TEST LOSS: 0.1495156437762866\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.10736672160489248 TEST LOSS: 0.13955218525186977\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.1202540452665456 TEST LOSS: 0.14930453790155537\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.11100002600804718 TEST LOSS: 0.14564619188652844\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.10975717195779582 TEST LOSS: 0.13905269669780607\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.10246288934626525 TEST LOSS: 0.1317401672286709\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.10731668343799963 TEST LOSS: 0.13703879958494955\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.09570636389143185 TEST LOSS: 0.12923352547523267\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.09912804294032446 TEST LOSS: 0.12389670596694044\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.10363913352407603 TEST LOSS: 0.1350506753160038\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.10494274738625596 TEST LOSS: 0.13188274024266625\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.09515257843568821 TEST LOSS: 0.1268498106844228\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.09319056910892358 TEST LOSS: 0.12803698975747432\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.09544758820460095 TEST LOSS: 0.12456229339485726\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.09728490959569136 TEST LOSS: 0.1254922508876292\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.09387252395019235 TEST LOSS: 0.11707292763770102\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.09537976555193817 TEST LOSS: 0.11757857182259587\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.10516744162921819 TEST LOSS: 0.13433927678615243\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.10100062951816813 TEST LOSS: 0.12662864543628832\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.09400391019516718 TEST LOSS: 0.12259801042901584\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.09535366215344553 TEST LOSS: 0.12435218105504602\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.09921945726469053 TEST LOSS: 0.1268350945108151\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.09517778518963597 TEST LOSS: 0.1257692992599977\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.09187028769304595 TEST LOSS: 0.12530010916551915\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.08959502466639899 TEST LOSS: 0.12032575701240973\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.09332126956997504 TEST LOSS: 0.12461821571574791\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.0999095066447987 TEST LOSS: 0.13075001058223681\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.10150390303856051 TEST LOSS: 0.13184035760606355\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.09769784230460876 TEST LOSS: 0.12596479117500178\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.09622865160231525 TEST LOSS: 0.12301124954041513\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.09890435876110323 TEST LOSS: 0.1271973757321819\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.09932595524912088 TEST LOSS: 0.12391013483768547\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.10203140868764106 TEST LOSS: 0.1302342695095193\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000017810D81630>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.2886645445419935 TEST LOSS: 0.20582694403519797\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.28795484104905955 TEST LOSS: 0.20687583599723364\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.28795484104905955 TEST LOSS: 0.20687583599723364\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.28795484104905955 TEST LOSS: 0.20687583599723364\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.28795484104905955 TEST LOSS: 0.20687583599723364\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.28795484104905955 TEST LOSS: 0.20687583599723364\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.2622759692749778 TEST LOSS: 0.2058574928019579\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.2081390601240875 TEST LOSS: 0.17864384920383483\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.19448937004335648 TEST LOSS: 0.16480472322869705\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.17596997616348717 TEST LOSS: 0.16069583992083267\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.16499104608437415 TEST LOSS: 0.13998727433308977\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.14776966526802068 TEST LOSS: 0.14020847941737147\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.1463807525270443 TEST LOSS: 0.11106819604275472\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.1296803896339737 TEST LOSS: 0.10588150810024717\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.12978254584433843 TEST LOSS: 0.10449847039838524\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.13162784871056055 TEST LOSS: 0.09977201952691135\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.12296386717755614 TEST LOSS: 0.09145761228046628\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.1169980855371549 TEST LOSS: 0.0905457394884533\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.109876588754393 TEST LOSS: 0.08962095898908774\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.09958280227563991 TEST LOSS: 0.08122856277422906\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.10626860041682887 TEST LOSS: 0.08445395411706232\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.10345531711324274 TEST LOSS: 0.08367363211925599\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.10910288207344061 TEST LOSS: 0.0895398174192009\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.10519306404902602 TEST LOSS: 0.08139457723732837\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.09786541003853652 TEST LOSS: 0.08270494302750608\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.10118895937356116 TEST LOSS: 0.07807837776095458\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.08480364951164045 TEST LOSS: 0.07675969821477295\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.09235829177803459 TEST LOSS: 0.07612370919818973\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.09550484125313281 TEST LOSS: 0.07453673037580791\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.07971015011937554 TEST LOSS: 0.07306583276496172\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.0793194116591686 TEST LOSS: 0.07184598283782395\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.0854395275577469 TEST LOSS: 0.07154625046385409\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.08108599523421535 TEST LOSS: 0.06671808461110935\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.08100351463088323 TEST LOSS: 0.07118247079628517\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.07560065718569002 TEST LOSS: 0.06603356490573044\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.07613623803412828 TEST LOSS: 0.06342336755589727\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.07437942811421894 TEST LOSS: 0.07154425719251017\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.07332082169785473 TEST LOSS: 0.06385691176502373\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.07890743882914868 TEST LOSS: 0.06053574985931928\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.0752501504092619 TEST LOSS: 0.06160517019561302\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.07821552381316788 TEST LOSS: 0.0596317555303901\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.07820625920631577 TEST LOSS: 0.05822576029557442\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.07687969061974813 TEST LOSS: 0.05742921991495066\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.07428368750145012 TEST LOSS: 0.059081600798435434\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.075623571375132 TEST LOSS: 0.05533254390199409\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.07822529412362772 TEST LOSS: 0.052301020444721895\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.07305621131945254 TEST LOSS: 0.058722604364663644\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.07472201435290861 TEST LOSS: 0.05526494358986792\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.07731717266639801 TEST LOSS: 0.054686174945781554\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.07466669670420197 TEST LOSS: 0.054200039301350575\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.07256035356045844 TEST LOSS: 0.05402440150442943\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x00000178132F39B0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.23357311771388511 TEST LOSS: 0.3613999856566942\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.23369269952192198 TEST LOSS: 0.3613999856566942\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.23369269952192198 TEST LOSS: 0.3613999856566942\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.23369269952192198 TEST LOSS: 0.3613999856566942\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.23369269952192198 TEST LOSS: 0.33525565761498716\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.19850179413532443 TEST LOSS: 0.3011934064578031\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.19070278979661787 TEST LOSS: 0.30373342274812215\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.17720039904938448 TEST LOSS: 0.19692198350229567\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.17081868604121075 TEST LOSS: 0.19815213501740817\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.14945874035337595 TEST LOSS: 0.1590828970479894\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.14144314845217712 TEST LOSS: 0.1459818079013374\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.13885840049953957 TEST LOSS: 0.1397277462936481\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.13885675487964888 TEST LOSS: 0.1333304651392604\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.13588093079737062 TEST LOSS: 0.12838012919230396\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.1259493815905073 TEST LOSS: 0.1260283871108968\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.1149041065616664 TEST LOSS: 0.11253856799480459\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.11760046744875992 TEST LOSS: 0.11821038981123158\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.11267766416035897 TEST LOSS: 0.09956743277456492\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.10709682992156538 TEST LOSS: 0.10379003886127673\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.10410202530140503 TEST LOSS: 0.09414045945298016\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.1003957457132687 TEST LOSS: 0.09321688223904889\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.10007979609341916 TEST LOSS: 0.09431483328924728\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.09150109158741443 TEST LOSS: 0.09167181419636956\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.09843814141977444 TEST LOSS: 0.09913507236445103\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.08833334786597997 TEST LOSS: 0.0852552246642885\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.08671163522942806 TEST LOSS: 0.08528572728475294\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.08417549892029465 TEST LOSS: 0.07958889310069066\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.08741075810442848 TEST LOSS: 0.09036923747692206\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.0858680048351857 TEST LOSS: 0.0884827821797671\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.08320307386488583 TEST LOSS: 0.0949394703275273\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.08058919350901585 TEST LOSS: 0.0850234686250718\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.08380868344048759 TEST LOSS: 0.09926437492356258\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.07784852750287251 TEST LOSS: 0.08646452131896226\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.07230058811464686 TEST LOSS: 0.07770393603334672\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.07594616666361868 TEST LOSS: 0.08400952674512759\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.08634441201157106 TEST LOSS: 0.09823029505537721\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.07948885801046984 TEST LOSS: 0.08828555932489716\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.07034386074405555 TEST LOSS: 0.06866436822669711\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.08068232635686227 TEST LOSS: 0.09280499811821527\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.07255952369966176 TEST LOSS: 0.07415877477379464\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.07935795342177793 TEST LOSS: 0.0880643642488778\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.07990561057149992 TEST LOSS: 0.09152707628346098\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.0822026146714349 TEST LOSS: 0.08707110305691126\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.0757179915340684 TEST LOSS: 0.07650963363307633\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.07404566531059065 TEST LOSS: 0.07971781227433306\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.07782679924369319 TEST LOSS: 0.07359456436901883\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.07844758446333612 TEST LOSS: 0.08611353324054334\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.07684473475750063 TEST LOSS: 0.08142820624415716\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.07740220628271542 TEST LOSS: 0.09176956478996101\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.0764956591294595 TEST LOSS: 0.08374724202560277\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.0851087294256459 TEST LOSS: 0.10424280111021088\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x00000178117DF9E8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.2112650717908953 TEST LOSS: 0.24945620516659675\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.18365702279540824 TEST LOSS: 0.21556740364286048\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.1822140041077807 TEST LOSS: 0.22104387531626732\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.1504694217213725 TEST LOSS: 0.17623803916225741\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.14269573521324103 TEST LOSS: 0.16408271379710734\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.12401009775826721 TEST LOSS: 0.13634692748681865\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.1279804031372894 TEST LOSS: 0.14078901477949568\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.1237834189141392 TEST LOSS: 0.128647869795553\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.1186301191140038 TEST LOSS: 0.12992860400280318\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.11659798684562996 TEST LOSS: 0.11741758272929058\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.10502668984726085 TEST LOSS: 0.10856427337304558\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.10103897369965628 TEST LOSS: 0.09966436047111508\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.09921599086021912 TEST LOSS: 0.10246532131672711\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.10356881603759945 TEST LOSS: 0.10407232030450939\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.09397459767297736 TEST LOSS: 0.0885491805847071\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.09733200656908149 TEST LOSS: 0.0948822276256927\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.09052748167468558 TEST LOSS: 0.09105669048683525\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.08597456136852358 TEST LOSS: 0.0866493455225014\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.09549010168571836 TEST LOSS: 0.0926026984560811\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.08689162158766786 TEST LOSS: 0.07721056914124538\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.08627729144574074 TEST LOSS: 0.08400643774170866\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.0877738985388031 TEST LOSS: 0.08089089523157916\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.08889365952187689 TEST LOSS: 0.08235163947904918\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.08569523415106392 TEST LOSS: 0.07350801347236482\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.08945885144208518 TEST LOSS: 0.08293827168000144\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.08342446951298275 TEST LOSS: 0.07626594128224813\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.08329370554773932 TEST LOSS: 0.08186749917462113\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.08746364325801821 TEST LOSS: 0.0797825526036186\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.08467886014568235 TEST LOSS: 0.07375582148574336\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.08833226391247506 TEST LOSS: 0.081399603054794\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.08834448197439955 TEST LOSS: 0.07871329239865456\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.08352944927877887 TEST LOSS: 0.08169419938446633\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.08266696398556858 TEST LOSS: 0.07585874744559076\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.08175458257585813 TEST LOSS: 0.0779717929363429\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.08532271786145244 TEST LOSS: 0.08166816004458122\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.08266084910182893 TEST LOSS: 0.07829738765663619\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.07995475419720949 TEST LOSS: 0.07593256678774896\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.08073505746889514 TEST LOSS: 0.08006901233017154\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.0808925351677235 TEST LOSS: 0.07982110428321851\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.08171781402805363 TEST LOSS: 0.08094120990278819\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.0821068430438965 TEST LOSS: 0.08085677676197418\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.08031583512267734 TEST LOSS: 0.07625447805346282\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.08056822939890018 TEST LOSS: 0.07853242959038083\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.07998624086330872 TEST LOSS: 0.08015866374250653\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.08211924718462373 TEST LOSS: 0.08022052076861873\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.07724575828882604 TEST LOSS: 0.08116179424283328\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.08290224339134998 TEST LOSS: 0.07821612498808309\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.08565857570145373 TEST LOSS: 0.0795803100557188\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.08571988455956543 TEST LOSS: 0.07832123926999246\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.08467523126205906 TEST LOSS: 0.08191703548728406\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.08502455017332192 TEST LOSS: 0.08089618438093467\n",
      "0.07724575828882604 0.08026685686784801\n",
      "0.0871519830041301 0.08093715539601934\n"
     ]
    }
   ],
   "source": [
    "# FOR DIFFERENT NUMBER OF MOMENTS AND THE SAME NUMBER OF PROCESSORS\n",
    "\n",
    "iteration_number = 10\n",
    "random_seed_list = list(range(iteration_number))\n",
    "#number_of_moments = list(range(1,11))\n",
    "number_of_moments = [4]\n",
    "final_val_loss, final_test_loss = [], []\n",
    "\n",
    "for moments in number_of_moments:\n",
    "    print(\"COMPUTING FOR \" + str(moments) + \" MOMENTS\")\n",
    "    validation_loss_list, test_loss_list = [], []\n",
    "    for index in range(iteration_number):\n",
    "        print('COMPUTING FOR ITERATION NUMBER ' + str(index+1))\n",
    "        lowest_val_loss, loss_test_list = inference_attention(random_seed_list[index], 2, 5, True, moments, False)\n",
    "        validation_loss_list.append(np.mean(lowest_val_loss))\n",
    "        test_loss_list.append(np.mean(loss_test_list))\n",
    "        print(np.mean(lowest_val_loss), np.mean(loss_test_list))\n",
    "        \n",
    "    final_val_loss.append(np.mean(validation_loss_list))\n",
    "    final_test_loss.append(np.mean(test_loss_list)) \n",
    "    print(np.mean(validation_loss_list), np.mean(test_loss_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPUTING FOR 4 PROCESSING STEPS\n",
      "COMPUTING FOR ITERATION NUMBER 1\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x00000178120A12E8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.2039271056784303 TEST LOSS: 0.27437457289539063\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.1389623935155821 TEST LOSS: 0.19282574451072707\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.12229717915451975 TEST LOSS: 0.16599759855139154\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.11931291757571419 TEST LOSS: 0.15387303612672618\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.10693726425794364 TEST LOSS: 0.13030656412277508\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.10417363630383303 TEST LOSS: 0.1302450700146913\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.11446635175391122 TEST LOSS: 0.11789052164381389\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.10546600796775067 TEST LOSS: 0.12022416032204175\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.10938979225538194 TEST LOSS: 0.12074482127877482\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.10520574146045009 TEST LOSS: 0.12197196176883249\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.10619438424075701 TEST LOSS: 0.12020141496256016\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.1059666439853664 TEST LOSS: 0.11329571311019551\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.10632621341364695 TEST LOSS: 0.11161423476921215\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.10341619523818801 TEST LOSS: 0.11560241213172463\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.10826367219396169 TEST LOSS: 0.09954835874750699\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.10691112013893281 TEST LOSS: 0.11644258860581945\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.10641284323884488 TEST LOSS: 0.10668993389019656\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.10513672688188747 TEST LOSS: 0.10763420713759238\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.10587033842729994 TEST LOSS: 0.1073852875474343\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.1044485692451995 TEST LOSS: 0.1071798059025119\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.10506737922004832 TEST LOSS: 0.10079495352365166\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.10319270079228049 TEST LOSS: 0.10050995306196348\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.10555443205715134 TEST LOSS: 0.10408778086960337\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.10424553476147207 TEST LOSS: 0.11557575833272693\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.10423193959521779 TEST LOSS: 0.09884042058946772\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.10298911653774234 TEST LOSS: 0.10224459483016678\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.1052976712306029 TEST LOSS: 0.10183383589570519\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.10573050804072458 TEST LOSS: 0.10460732891506522\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.10573004721843528 TEST LOSS: 0.09331087488744846\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.10852731183126875 TEST LOSS: 0.08589002726067056\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.11059304416697913 TEST LOSS: 0.10020003122094256\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.10541135639727989 TEST LOSS: 0.0993419773086952\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.10591916001198316 TEST LOSS: 0.08547720244423274\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.1057263496569113 TEST LOSS: 0.10940475245403676\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.10750044112863424 TEST LOSS: 0.08844055663434684\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.10725449066336457 TEST LOSS: 0.09506350872541049\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.10449298515831434 TEST LOSS: 0.10242490191973413\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.10539965994688023 TEST LOSS: 0.103021715633244\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.1046814375881796 TEST LOSS: 0.09268902623288144\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.10435970936023009 TEST LOSS: 0.09648576604310258\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.10572494560251819 TEST LOSS: 0.09573954021958174\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.10492420746019326 TEST LOSS: 0.09302422205533743\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.10470042028551464 TEST LOSS: 0.09492261336199884\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.10514161601978145 TEST LOSS: 0.09966615954373664\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.10705733847427228 TEST LOSS: 0.10504535733362852\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.10598380871628416 TEST LOSS: 0.0945768464253349\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.10847005719826253 TEST LOSS: 0.09799173210537956\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.10568215236331384 TEST LOSS: 0.1010874288039861\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.10668400661192867 TEST LOSS: 0.10519228952724059\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.10782348732135702 TEST LOSS: 0.09373168757199929\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.10339812552653645 TEST LOSS: 0.08649572276320189\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000017810E30320>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.2657298312860847 TEST LOSS: 0.25635495440361405\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.1825109166430107 TEST LOSS: 0.18227283297788563\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.1735493440431109 TEST LOSS: 0.18233136007737796\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.14690402342835104 TEST LOSS: 0.15969348236215106\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.1276928443143144 TEST LOSS: 0.14356560421841383\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.12693082764381133 TEST LOSS: 0.1422325282328332\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.10832362074132837 TEST LOSS: 0.12879777925753882\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.10465129713283419 TEST LOSS: 0.1220873415342397\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.10345865220147858 TEST LOSS: 0.12742432183472777\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.10371584126101062 TEST LOSS: 0.12318051572083528\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.11475879666119565 TEST LOSS: 0.13296503747624536\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.1030315526792778 TEST LOSS: 0.12520068377903165\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.10276981976655578 TEST LOSS: 0.1258809190302471\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.09175547777367583 TEST LOSS: 0.12043279648028897\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.10492969174208686 TEST LOSS: 0.12718547883359618\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.08968722234162337 TEST LOSS: 0.11435738847520704\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.08933737739033948 TEST LOSS: 0.11382904259671667\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.09927831690620095 TEST LOSS: 0.11993060478231224\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.08843520728354888 TEST LOSS: 0.10909331772173904\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.08807709983994402 TEST LOSS: 0.11358818568344282\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.0945677418863186 TEST LOSS: 0.11658303089970082\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.09001248263120534 TEST LOSS: 0.11158572388421285\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.08111652685968948 TEST LOSS: 0.10862823095341334\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.09377243082883412 TEST LOSS: 0.11697729978506745\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.1003689945721219 TEST LOSS: 0.11559802110821825\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.08364837704273999 TEST LOSS: 0.10464160637655348\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.09211338063715706 TEST LOSS: 0.11415015449568489\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.08759269419308773 TEST LOSS: 0.1065869977469382\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.08780437149272159 TEST LOSS: 0.11231561943494983\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.09674814691738746 TEST LOSS: 0.11478518150538214\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.08557087811550176 TEST LOSS: 0.1067070125983292\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.09515225729941545 TEST LOSS: 0.12278742760633438\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.09013849841178918 TEST LOSS: 0.11095701157837429\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.09116520453351289 TEST LOSS: 0.10896586264063547\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.09124840539085742 TEST LOSS: 0.1152739334949503\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.09631243185967174 TEST LOSS: 0.11369350406965346\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.08931885805287343 TEST LOSS: 0.11321096110715674\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.08302680119420969 TEST LOSS: 0.10508014025958666\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.09835962039402257 TEST LOSS: 0.11983536572106082\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.09366278570258058 TEST LOSS: 0.11705381324188266\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.08702600827869351 TEST LOSS: 0.1095317793056016\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.09199897100486386 TEST LOSS: 0.10885593285355477\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.08497990711111511 TEST LOSS: 0.10857692621973883\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.08333777894671054 TEST LOSS: 0.10683578875843641\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.09145452879544778 TEST LOSS: 0.11178301387787705\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.08209719408143301 TEST LOSS: 0.10702033533599022\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.08566511760689746 TEST LOSS: 0.10497310467380347\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.09372234633931975 TEST LOSS: 0.11456301049716434\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.09257010146682046 TEST LOSS: 0.1145469417282539\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.09067873572072646 TEST LOSS: 0.11334217699434138\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.08742622661879607 TEST LOSS: 0.10551375716726315\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000017813318A20>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.240501027342741 TEST LOSS: 0.24697236170952405\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.14305109681774916 TEST LOSS: 0.18875992902146696\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.12070875420351905 TEST LOSS: 0.14755766123376987\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.11225324265308373 TEST LOSS: 0.11549427200573133\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.11047199841409829 TEST LOSS: 0.10649164509509733\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.10480136250875585 TEST LOSS: 0.11543135639736556\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.09869850570339758 TEST LOSS: 0.10778711574811665\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.09853446074968923 TEST LOSS: 0.11752527915112318\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.09811393821863942 TEST LOSS: 0.11469452359742116\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.09537460176205373 TEST LOSS: 0.10513846266525832\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.1002868444904248 TEST LOSS: 0.10082966434814282\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.09402732175855202 TEST LOSS: 0.10396734534089751\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.09681193469617978 TEST LOSS: 0.10192178527574308\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.09315872074556336 TEST LOSS: 0.10291303077550473\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.09232330395446511 TEST LOSS: 0.099299301788154\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.09348048705192144 TEST LOSS: 0.10662548972109955\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.0955451979899677 TEST LOSS: 0.09314946910253731\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.09147474551176467 TEST LOSS: 0.09611630596962895\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.08991990239711116 TEST LOSS: 0.09546358121015493\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.09273251423554578 TEST LOSS: 0.10167604623725598\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.09089010162841099 TEST LOSS: 0.09290638581923313\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.08843006889755503 TEST LOSS: 0.09382531981379581\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.08633474950571887 TEST LOSS: 0.1005789166989616\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.08714706274687965 TEST LOSS: 0.0924428304803854\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.08909466317334723 TEST LOSS: 0.09243957207557253\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.088181537484034 TEST LOSS: 0.09153759948655915\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.08718658817067698 TEST LOSS: 0.09662240498293564\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.08684681123633024 TEST LOSS: 0.09271699596074107\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.08879244788789951 TEST LOSS: 0.08784024964878294\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.08283395921672852 TEST LOSS: 0.09624867938450318\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.08690589665811072 TEST LOSS: 0.09493538356651669\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.08788663418306028 TEST LOSS: 0.09304375146367477\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.08476393805069429 TEST LOSS: 0.09791024685009263\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.08333642883158703 TEST LOSS: 0.0929979648570905\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.0873725800366727 TEST LOSS: 0.08977501858564885\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.0855475672900713 TEST LOSS: 0.08891533767786128\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.08254504917393152 TEST LOSS: 0.08787112901389635\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.08296423715053407 TEST LOSS: 0.09627761362376651\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.08706163160162177 TEST LOSS: 0.09210439855266904\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.08336884531200728 TEST LOSS: 0.09389644347320895\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.08123975207355735 TEST LOSS: 0.09026453775064006\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.0827388969275824 TEST LOSS: 0.08544543831273299\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.08063166661818658 TEST LOSS: 0.09424381278638264\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.08401846226640924 TEST LOSS: 0.08999361107036079\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.07984041840079101 TEST LOSS: 0.08742006519764141\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.08202976393240591 TEST LOSS: 0.09277847266084281\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.08068964855796487 TEST LOSS: 0.08904600130867532\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.07654293574898348 TEST LOSS: 0.08870018246159503\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.0792593457732729 TEST LOSS: 0.0866876486684814\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.08023289874721169 TEST LOSS: 0.08746772437950602\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.08006126433315335 TEST LOSS: 0.08813028993783675\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x00000178121EE9B0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.22547161390743087 TEST LOSS: 0.27495773717829136\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.14816059701327064 TEST LOSS: 0.19463690324069974\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.12248557984632531 TEST LOSS: 0.16486566733157518\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.10530849305581198 TEST LOSS: 0.139724521010211\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.09925991106416471 TEST LOSS: 0.1307735643895324\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.08296156564201873 TEST LOSS: 0.11026460041680694\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.09607837299580929 TEST LOSS: 0.12036450731693527\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.07915989776901554 TEST LOSS: 0.10944698899171407\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.07117215876398719 TEST LOSS: 0.10397435839300302\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.07863638297366857 TEST LOSS: 0.10900483166304972\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.0614674355415582 TEST LOSS: 0.10427760277128899\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.07358674192037226 TEST LOSS: 0.10561081196286141\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.06812007820383108 TEST LOSS: 0.10466620283097937\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.07283775982355398 TEST LOSS: 0.10576188296677294\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.0804420907762504 TEST LOSS: 0.11191532780055292\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.06541928020444512 TEST LOSS: 0.10730949882428592\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.061377388928589356 TEST LOSS: 0.10029236221957556\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.06442767013998951 TEST LOSS: 0.10025363250199795\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.06997792693587417 TEST LOSS: 0.10099638687529609\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.08041010028918254 TEST LOSS: 0.10363267188768996\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.07792693324314635 TEST LOSS: 0.1109197496028494\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.07231727917476978 TEST LOSS: 0.10275266685603025\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.0690502172213633 TEST LOSS: 0.10694685753584565\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.06355720067678772 TEST LOSS: 0.10669384172334032\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.06556090762012066 TEST LOSS: 0.10724626695383395\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.07677928634693294 TEST LOSS: 0.11291018654775375\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.06438409640212335 TEST LOSS: 0.098778660372959\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.06477626845183787 TEST LOSS: 0.10067910526694356\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.0620450249199676 TEST LOSS: 0.09818119989595699\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.07350403763240224 TEST LOSS: 0.10683100005684949\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.06545747599229779 TEST LOSS: 0.10396092678396283\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.061301471353760836 TEST LOSS: 0.10096627425777253\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.06455161536250768 TEST LOSS: 0.10270303884863177\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.07882114977698784 TEST LOSS: 0.1020330309116535\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.06654818955273215 TEST LOSS: 0.10016625396496331\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.06736501720156853 TEST LOSS: 0.10308937825688481\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.058193849926791136 TEST LOSS: 0.09865414031861398\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.05527174894643203 TEST LOSS: 0.09720740821398188\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.06971634607647892 TEST LOSS: 0.10121425013505256\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.05264783253884521 TEST LOSS: 0.10105374165838568\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.06553263684560919 TEST LOSS: 0.1009089354035235\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.055497308248601614 TEST LOSS: 0.10089182179624663\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.05832266719322441 TEST LOSS: 0.10106601356013542\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.05774571193137135 TEST LOSS: 0.10091069520561073\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.0687397697425238 TEST LOSS: 0.1092443811692521\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.06286247227745435 TEST LOSS: 0.10299147783913248\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.06843855468443785 TEST LOSS: 0.10474605189950996\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.051509830954657464 TEST LOSS: 0.09844511839879458\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.06457698299406239 TEST LOSS: 0.10939389025294798\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.049902406298312184 TEST LOSS: 0.10114236040783477\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.0571227371435513 TEST LOSS: 0.10193830478083872\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001781209D0F0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.24424145343768214 TEST LOSS: 0.2370125504824027\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.17033250483029272 TEST LOSS: 0.15782805687586246\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.1228693312934148 TEST LOSS: 0.11364785002031781\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.1072596211867951 TEST LOSS: 0.09316221091545003\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.09141038273789293 TEST LOSS: 0.08516256056264035\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.08273736092893254 TEST LOSS: 0.07897611277804897\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.08582599488706723 TEST LOSS: 0.08079812699965278\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.08326089119283564 TEST LOSS: 0.07835990080044358\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.08172932355266323 TEST LOSS: 0.07905191547541524\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.07550625271248282 TEST LOSS: 0.0748325989929468\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.08511405426184657 TEST LOSS: 0.08183698966070616\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.08639872580135784 TEST LOSS: 0.07609339386312317\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.07926596370964724 TEST LOSS: 0.07721313805158937\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.07470196400254654 TEST LOSS: 0.07256043729634072\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.0763319410763761 TEST LOSS: 0.07285171092276306\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.0713083749813213 TEST LOSS: 0.07588271053208073\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.07379936683965918 TEST LOSS: 0.07419125527413001\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.07675312589361832 TEST LOSS: 0.07564074087685523\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.07570241692679844 TEST LOSS: 0.07438904349358633\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.07748005113828586 TEST LOSS: 0.071783998805889\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.07862235166391228 TEST LOSS: 0.07310576318399321\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.07430115853750222 TEST LOSS: 0.07338761856408738\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.07639237420298137 TEST LOSS: 0.07142323133229718\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.07967714059235002 TEST LOSS: 0.0741582247363481\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.07783404166332128 TEST LOSS: 0.07328359487763782\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.0811638780902552 TEST LOSS: 0.07269493967455773\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.07472869716013422 TEST LOSS: 0.07091729877587473\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.07553344021845605 TEST LOSS: 0.07274013112940642\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.07322309153914061 TEST LOSS: 0.07160041539048337\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.07235437206012232 TEST LOSS: 0.07239288524442537\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.07886336381068852 TEST LOSS: 0.07344054996834821\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.07257655278454479 TEST LOSS: 0.07175681592423774\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.0711915264694045 TEST LOSS: 0.07391672125346355\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.07406651544164854 TEST LOSS: 0.07066330269436573\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.07316005115305513 TEST LOSS: 0.07648089923377446\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.07848240486954391 TEST LOSS: 0.07550449045624971\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.07611796251962767 TEST LOSS: 0.07519010431222659\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.07342326806752564 TEST LOSS: 0.07242468356442566\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.07981454468476949 TEST LOSS: 0.07325456334417871\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.07090912202670338 TEST LOSS: 0.06964699270921842\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.07402040710579598 TEST LOSS: 0.0708992962544616\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.07237424036347125 TEST LOSS: 0.07549207778621643\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.07522797783586145 TEST LOSS: 0.07095627369292436\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.0742122522100174 TEST LOSS: 0.07392747272106058\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.0788481375189402 TEST LOSS: 0.07249423800702214\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.0734882340179154 TEST LOSS: 0.06920290046119648\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.07377802582530953 TEST LOSS: 0.07347350319132553\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.07663976786565925 TEST LOSS: 0.07288853984218224\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.07236321782262789 TEST LOSS: 0.06987540233813133\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.07193004495384414 TEST LOSS: 0.06982708327099367\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.07357018818496712 TEST LOSS: 0.07538571386900896\n",
      "0.07034207550194446 0.0937293360287909\n",
      "COMPUTING FOR ITERATION NUMBER 2\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000017810D4C6D8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.26062918674556435 TEST LOSS: 0.2075461564205646\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.17782848994764577 TEST LOSS: 0.14881440872993806\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.1456476242223764 TEST LOSS: 0.11970067500254768\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.13437468018156648 TEST LOSS: 0.10310530963781787\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.12402153909458746 TEST LOSS: 0.09776004665909452\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.1305994289582231 TEST LOSS: 0.09664049871588988\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.12278314751303833 TEST LOSS: 0.0893755568966071\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.11425886232933138 TEST LOSS: 0.08467378800659243\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.11636138907932532 TEST LOSS: 0.08585395118946036\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.11701640455153099 TEST LOSS: 0.08493885599918165\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.11491119144947848 TEST LOSS: 0.08554745891165974\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.1157421733569025 TEST LOSS: 0.08885735842463142\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.11553376029567994 TEST LOSS: 0.08359568494285664\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.11343395877906495 TEST LOSS: 0.08279549892346133\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.12015243153547472 TEST LOSS: 0.08526410557504646\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.10961536436763182 TEST LOSS: 0.08366190719457464\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.11533555931072814 TEST LOSS: 0.08735800420382776\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.1179409108035596 TEST LOSS: 0.08388801524208998\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.11147435595230443 TEST LOSS: 0.08429023274477258\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.11647677908805999 TEST LOSS: 0.08468453414912898\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.11547935815444808 TEST LOSS: 0.07985691405676669\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.11291414307955577 TEST LOSS: 0.08399890055774348\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.1148609677862894 TEST LOSS: 0.08636606218520618\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.10920081059018813 TEST LOSS: 0.08425008637012348\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.10673035792951292 TEST LOSS: 0.08088794909980737\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.11117638401079565 TEST LOSS: 0.0849780023039417\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.10760489956265817 TEST LOSS: 0.08347404829127514\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.11151051216425337 TEST LOSS: 0.08328233224000656\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.10766282574433216 TEST LOSS: 0.08042450520431543\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.11522087729236355 TEST LOSS: 0.08246218461545604\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.11052660891108082 TEST LOSS: 0.08213903729312698\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.11358625910387209 TEST LOSS: 0.07906345254688943\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.10693183746106008 TEST LOSS: 0.08531588827011956\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.11137990865175587 TEST LOSS: 0.08413734469551842\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.11070949640710151 TEST LOSS: 0.07812873153776824\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.11452659431570858 TEST LOSS: 0.08030366231719147\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.10766633620163035 TEST LOSS: 0.08124787816941476\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.11062666983313253 TEST LOSS: 0.08237953709696191\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.10949456676137448 TEST LOSS: 0.07940724084390659\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.11347547201273556 TEST LOSS: 0.08408592755326605\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.10800866810456537 TEST LOSS: 0.08089333971345851\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.10863079658094787 TEST LOSS: 0.07900824352799364\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.10931386122849321 TEST LOSS: 0.079634911559658\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.10990156928898474 TEST LOSS: 0.07770495881216485\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.1141786347309745 TEST LOSS: 0.08579004623099272\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.11676248795659011 TEST LOSS: 0.08621162980498193\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.11121340104159037 TEST LOSS: 0.077818601643713\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.11191352146608535 TEST LOSS: 0.07563179889156355\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.11436303564936412 TEST LOSS: 0.07875906864864629\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.11245796350831304 TEST LOSS: 0.07824517485693967\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.10963085192185819 TEST LOSS: 0.07746043941343342\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x00000178121EE048>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.21070162217519264 TEST LOSS: 0.26067915801078406\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.147968403550881 TEST LOSS: 0.18202083349873646\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.11562477986422605 TEST LOSS: 0.13688460466853625\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.10788610966430073 TEST LOSS: 0.1263324141128162\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.09162350046922138 TEST LOSS: 0.1177236181589213\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.09126757067925496 TEST LOSS: 0.11476785769026072\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.08872271042455085 TEST LOSS: 0.10760868569847643\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.08975309075180177 TEST LOSS: 0.10226492797218473\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.09089891385252004 TEST LOSS: 0.10352580937809569\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.08793774104198784 TEST LOSS: 0.09971488486324183\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.08493802187042049 TEST LOSS: 0.09643774475971882\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.08577679850509713 TEST LOSS: 0.10018682342457975\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.08324599230165045 TEST LOSS: 0.10141984367376464\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.08004672552997646 TEST LOSS: 0.09479623705458219\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.07985933342417256 TEST LOSS: 0.09795166320202042\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.07982783585717527 TEST LOSS: 0.09824445944246685\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.08385069417537994 TEST LOSS: 0.09927369567790124\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.0818525287997963 TEST LOSS: 0.10161841052090999\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.07985841428991394 TEST LOSS: 0.09883391909026638\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.08208011611389329 TEST LOSS: 0.09745152358252922\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.08180360208250965 TEST LOSS: 0.09631054053600817\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.08077761692871861 TEST LOSS: 0.10449560419011876\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.08013568425225788 TEST LOSS: 0.09601364431751955\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.0808188804120409 TEST LOSS: 0.10091337068807954\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.07742691340138504 TEST LOSS: 0.10469108123319043\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.08003154172463867 TEST LOSS: 0.09594143358968557\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.0791202014999467 TEST LOSS: 0.09494200391065802\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.07855513044117017 TEST LOSS: 0.09541200901842875\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.0771948171463986 TEST LOSS: 0.09384923679043568\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.07836917687772582 TEST LOSS: 0.09715685382664915\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.079133538797456 TEST LOSS: 0.09246096786570439\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.07790321516551256 TEST LOSS: 0.09744682967414649\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.07713528108703482 TEST LOSS: 0.09787949353236114\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.07752140722939564 TEST LOSS: 0.09557903618318321\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.07649483659509299 TEST LOSS: 0.09558599863114274\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.08044274187912025 TEST LOSS: 0.09688928192771637\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.07857781692711163 TEST LOSS: 0.09496031489272082\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.08168179382341854 TEST LOSS: 0.0989415555667578\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.0772392471946275 TEST LOSS: 0.09638096779507063\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.07618063905795838 TEST LOSS: 0.09623642507138455\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.0760970617598826 TEST LOSS: 0.0964436507732787\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.0781033927263998 TEST LOSS: 0.09507037198470349\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.07501703058321714 TEST LOSS: 0.09537580854424785\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.07725324511196283 TEST LOSS: 0.09500086840142472\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.0791967183495196 TEST LOSS: 0.09500048595685427\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.07849370792471155 TEST LOSS: 0.09603640780967927\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.07606294656658984 TEST LOSS: 0.09343087706412223\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.07316240081106387 TEST LOSS: 0.09705975757812559\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.07638556810904107 TEST LOSS: 0.09706924981518207\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.07895293411103627 TEST LOSS: 0.09520651022524514\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.08078293994323256 TEST LOSS: 0.09752035192289867\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000017811092240>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.19708778396452287 TEST LOSS: 0.18663136801695693\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.1529326755536151 TEST LOSS: 0.1486537963899788\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.11756719392957206 TEST LOSS: 0.12090801824455508\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.0836352617897286 TEST LOSS: 0.10104003634010801\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.08351643377052398 TEST LOSS: 0.09341558376221733\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.08442491981304583 TEST LOSS: 0.09038969075178875\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.0783429920853609 TEST LOSS: 0.08991684816796583\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.08030317103474426 TEST LOSS: 0.08832077330497709\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.08806313820755853 TEST LOSS: 0.08892457985078145\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.07707353597033148 TEST LOSS: 0.08836809626811919\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.07615859327954606 TEST LOSS: 0.09001014654496786\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.078978449589234 TEST LOSS: 0.08793624779280726\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.07704623599282419 TEST LOSS: 0.08720292702026042\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.07989765984093362 TEST LOSS: 0.08551381195142425\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.07936056321869879 TEST LOSS: 0.08429050503844467\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.0799663572525281 TEST LOSS: 0.0855323684753726\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.08010276684299257 TEST LOSS: 0.08609488048980228\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.07614929924400633 TEST LOSS: 0.08372636005232677\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.0794341678030559 TEST LOSS: 0.08030993135089551\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.07863082833013238 TEST LOSS: 0.08599727573098248\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.07867136484745535 TEST LOSS: 0.08234293219419984\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.07980107637249895 TEST LOSS: 0.0814992367497553\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.08395171356289215 TEST LOSS: 0.08810991627696173\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.0811977064444792 TEST LOSS: 0.0845879674775902\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.07841795832389573 TEST LOSS: 0.07910090121433555\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.07624678845576938 TEST LOSS: 0.08236156823818191\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.0785114540173668 TEST LOSS: 0.08399601260488687\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.07616120288180016 TEST LOSS: 0.0781887171929105\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.08242305106846914 TEST LOSS: 0.0764804832546722\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.07727586191712649 TEST LOSS: 0.07849617875337446\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.07777851336940998 TEST LOSS: 0.07914733342095522\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.08092683619470827 TEST LOSS: 0.0794801527815536\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.07912265628287542 TEST LOSS: 0.07580205317447274\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.07478657748886879 TEST LOSS: 0.08388713255588197\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.07746409851407504 TEST LOSS: 0.08021102371538727\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.08101971349328078 TEST LOSS: 0.07672938119204732\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.07757959495152215 TEST LOSS: 0.07763842666753991\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.0796553286149123 TEST LOSS: 0.07771167176885604\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.08078573666456097 TEST LOSS: 0.07667798805547993\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.07597137449040624 TEST LOSS: 0.0750686620222725\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.08290591331415159 TEST LOSS: 0.07757068732445481\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.08030797909941985 TEST LOSS: 0.0774629294786525\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.07866489944769821 TEST LOSS: 0.07729106091214084\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.07996649499510063 TEST LOSS: 0.07580992026368687\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.08043697160723232 TEST LOSS: 0.07519198905205164\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.08014541121291162 TEST LOSS: 0.07792963590488099\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.08237768230621872 TEST LOSS: 0.07800168320870803\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.07870753047511828 TEST LOSS: 0.07433733370311005\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.07672940401736968 TEST LOSS: 0.07338157503384779\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.07819782622224287 TEST LOSS: 0.07658502422184398\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.07702255071853115 TEST LOSS: 0.07685744520126872\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x00000178121EEA90>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.30716715840000386 TEST LOSS: 0.26628340709607046\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.21084157996721553 TEST LOSS: 0.17532933086687497\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.18694604755570232 TEST LOSS: 0.15379863604401317\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.14843126227338557 TEST LOSS: 0.13180845593607268\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.14168047306254591 TEST LOSS: 0.12595572960144688\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.1452219179522571 TEST LOSS: 0.1262589137458136\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.13611527673044743 TEST LOSS: 0.12364132369001055\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.12797985970605436 TEST LOSS: 0.12044430197508028\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.12740502287240787 TEST LOSS: 0.12157496835649581\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.1311877498675065 TEST LOSS: 0.1230526305939979\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.12351665043470615 TEST LOSS: 0.11543374077400434\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.1239532003176114 TEST LOSS: 0.11647228864798673\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.12628728107514217 TEST LOSS: 0.12163879952014191\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.11505366407359063 TEST LOSS: 0.11416811902022081\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.12214789335871896 TEST LOSS: 0.11750713954140724\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.11266904539915804 TEST LOSS: 0.11261094704234247\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.1111652668630475 TEST LOSS: 0.11300320408418431\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.10817203431188079 TEST LOSS: 0.10922350497307413\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.12789887297326763 TEST LOSS: 0.11702426021422636\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.12275651831865056 TEST LOSS: 0.11197690759901636\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.1281921832776431 TEST LOSS: 0.11748714676438392\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.13143265837141235 TEST LOSS: 0.11458233371999954\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.11963405040197427 TEST LOSS: 0.1144476875032894\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.11298424816141563 TEST LOSS: 0.11102744587713248\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.11037919683406301 TEST LOSS: 0.10957471600420314\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.12177453984123722 TEST LOSS: 0.11259721773715581\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.11603369012278524 TEST LOSS: 0.1133107792559558\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.12248507084475525 TEST LOSS: 0.11718440149739288\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.10909127195597222 TEST LOSS: 0.10923351524647552\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.11370999116170659 TEST LOSS: 0.11367981312198172\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.12143846436238105 TEST LOSS: 0.11649287210578749\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.11109309196108677 TEST LOSS: 0.11268558980324667\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.12980260807741462 TEST LOSS: 0.11684697516854546\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.11429126565053406 TEST LOSS: 0.11310177305323435\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.10859742991011771 TEST LOSS: 0.110353078476945\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.11536539370060071 TEST LOSS: 0.10836615907354187\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.10695759774628646 TEST LOSS: 0.10721060300821841\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.10277937714510677 TEST LOSS: 0.10459095039514764\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.11842384790145145 TEST LOSS: 0.1121874028410575\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.11587673276869866 TEST LOSS: 0.11371738526122827\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.11457176862833787 TEST LOSS: 0.10985484785708585\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.11097762451237901 TEST LOSS: 0.10680457210522946\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.106770697342535 TEST LOSS: 0.10533330314265639\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.10727473958066727 TEST LOSS: 0.10557348424201593\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.11320112056458968 TEST LOSS: 0.11101894700614488\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.11703020239674375 TEST LOSS: 0.11499950662704916\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.11017158915455977 TEST LOSS: 0.10870891712720518\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.11296730146107613 TEST LOSS: 0.11136981877247044\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.1063388241317028 TEST LOSS: 0.10780600110309264\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.12271559639914503 TEST LOSS: 0.1157370833123315\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.10816480114291567 TEST LOSS: 0.10759253406318346\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001781225F278>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.30691995898835306 TEST LOSS: 0.25775768822828055\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.1845937911202937 TEST LOSS: 0.15899025848100504\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.17721713649100473 TEST LOSS: 0.14628655637297355\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.14817270908645494 TEST LOSS: 0.12558208188819991\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.14441249918931473 TEST LOSS: 0.1250066691090278\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.12461226636758493 TEST LOSS: 0.11049384222379346\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.11955256057349087 TEST LOSS: 0.10725836084799001\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.12035721171852594 TEST LOSS: 0.1084771420916659\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.10241655178618539 TEST LOSS: 0.09771375608367618\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.10662123140584966 TEST LOSS: 0.10123646406045718\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.11043489425965797 TEST LOSS: 0.0993064437054067\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.10610391478510646 TEST LOSS: 0.09996550135490617\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.1047544878863056 TEST LOSS: 0.09733441294166406\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.11387516964650918 TEST LOSS: 0.10172581541687677\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.12077536284468858 TEST LOSS: 0.0988338055607696\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.11486059411915903 TEST LOSS: 0.09794792132270635\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.1119487231481849 TEST LOSS: 0.0961229006897499\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.12113127981007361 TEST LOSS: 0.10162015129576249\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.11619198110666663 TEST LOSS: 0.09752504259607704\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.11935112086347109 TEST LOSS: 0.10000117680619888\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.11143351851676232 TEST LOSS: 0.09411894190009774\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.1047964831498336 TEST LOSS: 0.08967292425768705\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.10770461095483003 TEST LOSS: 0.09618281565190508\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.1007196832004559 TEST LOSS: 0.08822651453872886\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.10119479328852798 TEST LOSS: 0.09247886451594489\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.1107537487351406 TEST LOSS: 0.09146035805545533\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.0992331670328555 TEST LOSS: 0.08606483691056029\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.10543582250477863 TEST LOSS: 0.08883290475199003\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.11026463622471429 TEST LOSS: 0.09032065938505784\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.10216241644206163 TEST LOSS: 0.09100165626883831\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.10364369137779675 TEST LOSS: 0.08566717107515641\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.09365804622196874 TEST LOSS: 0.08346362434173009\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.11287768446516132 TEST LOSS: 0.08957976764496516\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.11799971355955038 TEST LOSS: 0.0960714475724768\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.09487194436724088 TEST LOSS: 0.08350028667054986\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.10577500381300095 TEST LOSS: 0.08752809749230075\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.11399125768735525 TEST LOSS: 0.0874159745189963\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.09764346318429377 TEST LOSS: 0.08505506768413257\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.1034454068029868 TEST LOSS: 0.0863880997357498\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.09750839217399648 TEST LOSS: 0.08410195036797129\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.09284194207048732 TEST LOSS: 0.08366967899209209\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.10181524048508976 TEST LOSS: 0.08699535883702471\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.09952541431382783 TEST LOSS: 0.08615926353121901\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.11283312925209037 TEST LOSS: 0.08904566639890216\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.10753208968660348 TEST LOSS: 0.09079740514654401\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.10474803032587564 TEST LOSS: 0.08983076239909961\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.09356960033088928 TEST LOSS: 0.08372396480328079\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.09634576227648955 TEST LOSS: 0.08602742707166013\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.10032242999355892 TEST LOSS: 0.08804847204717456\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.10462883427923263 TEST LOSS: 0.08768052362723702\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.09913373295730325 TEST LOSS: 0.08523886759922869\n",
      "0.09121996876013065 0.090279391325054\n",
      "COMPUTING FOR ITERATION NUMBER 3\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001781A67C400>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.21830576902032459 TEST LOSS: 0.30016870375678006\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.1452280810536843 TEST LOSS: 0.1855947262850698\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.12653566617390782 TEST LOSS: 0.16360525032489565\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.10714491499799862 TEST LOSS: 0.13424376037836627\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.10233524431344893 TEST LOSS: 0.10865534998980432\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.1033774945789344 TEST LOSS: 0.11309422244048287\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.09999983599937222 TEST LOSS: 0.09692422842474217\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.1043195896621233 TEST LOSS: 0.1080721469425604\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.10534077737279382 TEST LOSS: 0.12631297679569292\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.10570251726868228 TEST LOSS: 0.10760715243907949\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.10446072728823137 TEST LOSS: 0.10615576270305499\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.1030432525389915 TEST LOSS: 0.10603283193805006\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.10139073783131433 TEST LOSS: 0.08912916280888435\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.10166961640404171 TEST LOSS: 0.09158636009287038\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.09930916060734853 TEST LOSS: 0.08106652523874557\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.10445093689675844 TEST LOSS: 0.10448814524881349\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.10295442344877764 TEST LOSS: 0.11180468347821551\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.10252226639919473 TEST LOSS: 0.09085517697928253\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.10045033985828071 TEST LOSS: 0.08744693557748594\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.10127824711375456 TEST LOSS: 0.09984804412470012\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.10355022548963339 TEST LOSS: 0.09811359525447574\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.09973964741972473 TEST LOSS: 0.0957706842508488\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.10145723724123468 TEST LOSS: 0.09724281238082666\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.10323293935970523 TEST LOSS: 0.10325370602663814\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.1001067113682673 TEST LOSS: 0.08423398812289741\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.09987274206485026 TEST LOSS: 0.09941546712213786\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.10178561272010274 TEST LOSS: 0.09591985172808254\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.09927681118871187 TEST LOSS: 0.08933757803634451\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.10014528084831932 TEST LOSS: 0.0854967927884629\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.09959671679640884 TEST LOSS: 0.08946684861611007\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.09911596653617162 TEST LOSS: 0.0869873156262715\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.09993519320976593 TEST LOSS: 0.085108547644085\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.09919726012753895 TEST LOSS: 0.09102351987804312\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.09818801210248103 TEST LOSS: 0.09224676111959224\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.10022665488022854 TEST LOSS: 0.09209236816246613\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.10244590216991976 TEST LOSS: 0.09238306561983313\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.09826616022274905 TEST LOSS: 0.10208974663598432\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.09877460002888806 TEST LOSS: 0.0971871828660497\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.10055499573933353 TEST LOSS: 0.08879719709687353\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.09670928545916904 TEST LOSS: 0.09650504756152053\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.0982476039926951 TEST LOSS: 0.08913100950693165\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.09626287049129163 TEST LOSS: 0.0983123333130762\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.0969002988984827 TEST LOSS: 0.09603586151686007\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.09797970928410758 TEST LOSS: 0.08426067717270175\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.10110861226109713 TEST LOSS: 0.08595871848174236\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.09931934794456339 TEST LOSS: 0.0899994110880354\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.10108375840388593 TEST LOSS: 0.08923642433930837\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.09739611720141898 TEST LOSS: 0.08511981953987781\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.0957385350795764 TEST LOSS: 0.08689674065348942\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.09983318166078255 TEST LOSS: 0.07578623848970768\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.09841455213926462 TEST LOSS: 0.09152248424010342\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000017813318438>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.21545537932272005 TEST LOSS: 0.2391138401706003\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.13973323008446004 TEST LOSS: 0.15659136191345113\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.11150417715737267 TEST LOSS: 0.12486299508040632\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.10368858525570766 TEST LOSS: 0.11520457303716983\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.09541772412754114 TEST LOSS: 0.10483536880077701\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.09765151940775042 TEST LOSS: 0.11505214823531452\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.09474576453494382 TEST LOSS: 0.09343114923111158\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.09262982106350426 TEST LOSS: 0.08279420363232597\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.09485594116120803 TEST LOSS: 0.10222458577299125\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.09364181292170416 TEST LOSS: 0.0840514223059064\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.09557583648410149 TEST LOSS: 0.10094925817316931\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.09309508535137477 TEST LOSS: 0.08374786528671063\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.09512870322593439 TEST LOSS: 0.07944985081025002\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.09421999186387434 TEST LOSS: 0.07687188078623731\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.09635548336273107 TEST LOSS: 0.08126734531424153\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.09600798395789434 TEST LOSS: 0.07440020681665409\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.09748590597622576 TEST LOSS: 0.08613473705727184\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.0950837141752082 TEST LOSS: 0.07996857377509996\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.09297520824767928 TEST LOSS: 0.07067023644519674\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.09506764972598501 TEST LOSS: 0.07093705877743214\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.09604979261923113 TEST LOSS: 0.07685254907692178\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.09327697476103655 TEST LOSS: 0.08255123255168587\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.09328383799826144 TEST LOSS: 0.08332270007818399\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.09221818786043874 TEST LOSS: 0.08416986066123824\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.09171629177820671 TEST LOSS: 0.08399263445718072\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.09513299240160171 TEST LOSS: 0.08181877183380223\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.09194875525381127 TEST LOSS: 0.08019767444386597\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.09075916863004108 TEST LOSS: 0.08192761060051441\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.09467573096766617 TEST LOSS: 0.08339299826833052\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.09272956546220547 TEST LOSS: 0.07988897314209634\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.09433999551778083 TEST LOSS: 0.08431185897490695\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.09123270136454387 TEST LOSS: 0.07891136364457461\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.09300609826256116 TEST LOSS: 0.07827659304143819\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.0931059114947179 TEST LOSS: 0.08323616862445836\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.09095756826241501 TEST LOSS: 0.08008482386949238\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.08975267364312765 TEST LOSS: 0.0777380404008205\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.09005019604733039 TEST LOSS: 0.07541012806116601\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.09023433826046143 TEST LOSS: 0.07933105564635935\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.09574693293997047 TEST LOSS: 0.0711022373599955\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.09186863378943638 TEST LOSS: 0.07755307707672879\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.0897722082055684 TEST LOSS: 0.07964101741149705\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.08969905318086013 TEST LOSS: 0.06979793819271211\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.09022153325331257 TEST LOSS: 0.07156555240166464\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.0907946653597396 TEST LOSS: 0.06992526539024026\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.09043398756508109 TEST LOSS: 0.081482333213995\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.08743450776671972 TEST LOSS: 0.07178917642826085\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.08815951160275638 TEST LOSS: 0.07311265651425256\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.08730113845704367 TEST LOSS: 0.07702087328229863\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.09181001407552886 TEST LOSS: 0.0865160137687561\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.09174986157595286 TEST LOSS: 0.07785256560925555\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.08859659603081155 TEST LOSS: 0.07434364305588279\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001781A683A58>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.24455817301851762 TEST LOSS: 0.1824458751093269\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.1639027001037035 TEST LOSS: 0.13756276716886331\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.1300296158232727 TEST LOSS: 0.1116314956073662\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.12098087831302162 TEST LOSS: 0.0925752756151118\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.10816497840821226 TEST LOSS: 0.07915887225690647\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.11432073307524404 TEST LOSS: 0.08024697700376524\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.09462733758324009 TEST LOSS: 0.07202068554664288\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.0956916660038903 TEST LOSS: 0.06962892253152392\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.10202604251515911 TEST LOSS: 0.07426660451186642\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.0925770365342094 TEST LOSS: 0.07429921455045133\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.0957741753157856 TEST LOSS: 0.07270578497974509\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.09348020653776175 TEST LOSS: 0.0708134376457296\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.09374968830312212 TEST LOSS: 0.06954640090672864\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.0918215484991106 TEST LOSS: 0.07123806154187859\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.09289452937624204 TEST LOSS: 0.06896438402163069\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.09671307765070947 TEST LOSS: 0.07007392592581155\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.09314592118031004 TEST LOSS: 0.07106361681636668\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.08696062821096173 TEST LOSS: 0.06915184267904174\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.08921176188971347 TEST LOSS: 0.06943317823591977\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.08408977314400871 TEST LOSS: 0.07001131469630326\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.08677411496563979 TEST LOSS: 0.0704683983412681\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.09262005419292424 TEST LOSS: 0.069835172262424\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.08847152085670486 TEST LOSS: 0.07032379962571844\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.08830811837110424 TEST LOSS: 0.06853290637731226\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.08553974231337248 TEST LOSS: 0.06793224511923476\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.0899304090418522 TEST LOSS: 0.06925707113016479\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.08891270611952863 TEST LOSS: 0.06684616512919511\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.08473957206348948 TEST LOSS: 0.07014349352493467\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.08784729949975605 TEST LOSS: 0.06921283037297742\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.09039541496878206 TEST LOSS: 0.0672743592957795\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.08411592330304589 TEST LOSS: 0.06970455765502753\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.08532772975200194 TEST LOSS: 0.0706165604167726\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.09266413230681483 TEST LOSS: 0.06897933777488222\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.08403965420711687 TEST LOSS: 0.06615518853281539\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.08579466487668147 TEST LOSS: 0.06764595451577114\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.0881109064418557 TEST LOSS: 0.06913186813735611\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.0941467423840893 TEST LOSS: 0.06924430034578437\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.09065389717152504 TEST LOSS: 0.06557642078880518\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.0849572134605867 TEST LOSS: 0.06381179891598877\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.09559858210161584 TEST LOSS: 0.07159252209616161\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.08807871697876656 TEST LOSS: 0.06759038445418021\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.08696533482812074 TEST LOSS: 0.0688143197717765\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.08697040407327064 TEST LOSS: 0.06730990008377943\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.0839199632052422 TEST LOSS: 0.06695861973332563\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.08879034792594737 TEST LOSS: 0.06640586052680024\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.083948447726038 TEST LOSS: 0.06729316597950531\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.086891808874989 TEST LOSS: 0.0663227194934757\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.0827240369155029 TEST LOSS: 0.06642272224161723\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.08408019614845158 TEST LOSS: 0.06497561841368193\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.08791348908191574 TEST LOSS: 0.0674768994240066\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.08865191073443268 TEST LOSS: 0.06579035758972451\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x00000178117CEE10>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.214247283916612 TEST LOSS: 0.26602877302971045\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.14856075905908186 TEST LOSS: 0.16717729177065738\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.13191662158464013 TEST LOSS: 0.1515940124070784\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.11577419260143924 TEST LOSS: 0.12312389117754122\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.10704404287326376 TEST LOSS: 0.1268636908659521\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.09443006232660105 TEST LOSS: 0.103527607993954\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.0984929073984602 TEST LOSS: 0.09679362417830581\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.08848715732006905 TEST LOSS: 0.09681749680723843\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.09267465184412363 TEST LOSS: 0.08945280732045266\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.08427822415152726 TEST LOSS: 0.0877980947664779\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.08359529300247792 TEST LOSS: 0.08870774243585401\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.08139823024813982 TEST LOSS: 0.0917184623441486\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.0789490864151755 TEST LOSS: 0.08696734626557172\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.08455474284870508 TEST LOSS: 0.07891904735692129\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.08105140610765846 TEST LOSS: 0.09049154310681848\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.07883931950251592 TEST LOSS: 0.08510851031621021\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.08142027379099794 TEST LOSS: 0.07683678051438754\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.07965887697171829 TEST LOSS: 0.07339988238600859\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.07785619433769235 TEST LOSS: 0.08385455590626256\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.08039772455368978 TEST LOSS: 0.07771601125219771\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.08064076396314922 TEST LOSS: 0.09663435779066971\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.08175469950764536 TEST LOSS: 0.08510203263395781\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.08486399839341645 TEST LOSS: 0.07150430567044219\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.0791232324402234 TEST LOSS: 0.08558404140332283\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.08355687652363217 TEST LOSS: 0.07159294777453705\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.0800540030706801 TEST LOSS: 0.07887557159291464\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.0822695730540022 TEST LOSS: 0.07770631493933072\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.07585712713362695 TEST LOSS: 0.0762958029163693\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.08227733300065175 TEST LOSS: 0.07506665148951176\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.07851993758023375 TEST LOSS: 0.07701453028582815\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.07832695372390343 TEST LOSS: 0.08279103642656936\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.0784389273610905 TEST LOSS: 0.0728270205449962\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.08167274011106801 TEST LOSS: 0.07107468999581273\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.07874729677931976 TEST LOSS: 0.07426142721185246\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.08046101249281022 TEST LOSS: 0.0661948441832244\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.0777071366956332 TEST LOSS: 0.07748194177413517\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.08026755146924534 TEST LOSS: 0.08737616670248279\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.07978527807951459 TEST LOSS: 0.07067192047932087\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.07518767758195637 TEST LOSS: 0.06998789871367822\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.08069060123458209 TEST LOSS: 0.06977055607045378\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.07684761291280551 TEST LOSS: 0.07333350157024418\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.0788537009273118 TEST LOSS: 0.08026035264898092\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.0805426511884557 TEST LOSS: 0.07297775700801934\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.07601590465408362 TEST LOSS: 0.07174644055671195\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.08117850044648295 TEST LOSS: 0.08032275830946475\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.08163204685332276 TEST LOSS: 0.07103105716202636\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.07971916793000576 TEST LOSS: 0.0646325821283997\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.07983588933110888 TEST LOSS: 0.06544769915190897\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.07646180087199711 TEST LOSS: 0.0712222875554302\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.0779701318917667 TEST LOSS: 0.07890683514433598\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.08168697085148223 TEST LOSS: 0.06571948263626613\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x00000178136F8550>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.3503749252689154 TEST LOSS: 0.30868915420060167\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.2453994795635972 TEST LOSS: 0.20532072497397885\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.21946730396933348 TEST LOSS: 0.1791635634015031\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.2021547332826041 TEST LOSS: 0.1589798285265866\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.18815364005203547 TEST LOSS: 0.14106918188281817\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.17990362112949776 TEST LOSS: 0.1267890996713903\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.1733563575063621 TEST LOSS: 0.11836265610948693\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.1636963664448195 TEST LOSS: 0.11107339134705364\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.1728271291093406 TEST LOSS: 0.12279741982435302\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.17696904924074475 TEST LOSS: 0.12134955407623768\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.18658311190249413 TEST LOSS: 0.12958289214333354\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.17517748552386433 TEST LOSS: 0.11215614068920016\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.16898312304827728 TEST LOSS: 0.11830919090466575\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.17542501372119793 TEST LOSS: 0.11745405412298401\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.16508906878404492 TEST LOSS: 0.11250960884249017\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.16340056478773932 TEST LOSS: 0.10830378081498494\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.16833068746383337 TEST LOSS: 0.11132433412796645\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.1680598973339317 TEST LOSS: 0.10855392135687696\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.167543068850087 TEST LOSS: 0.11401751189078993\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.1614836352418177 TEST LOSS: 0.1085765395408205\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.15695031103670468 TEST LOSS: 0.11070900400769446\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.1725294811464403 TEST LOSS: 0.11908957359522747\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.16058710915530286 TEST LOSS: 0.11180602331900989\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.15702799953873783 TEST LOSS: 0.09721464379844165\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.16379296328029178 TEST LOSS: 0.1112805858713829\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.16977798490726834 TEST LOSS: 0.1138610036697823\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.16578848962762022 TEST LOSS: 0.11096074385120067\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.1612472526589436 TEST LOSS: 0.11267417456563576\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.16487512874277346 TEST LOSS: 0.10677573713735884\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.16695319139407241 TEST LOSS: 0.10129482869265712\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.16115476939183532 TEST LOSS: 0.10333118557779505\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.16124238766937446 TEST LOSS: 0.10202622664514609\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.1582323359609738 TEST LOSS: 0.09752097341607559\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.15812020803321708 TEST LOSS: 0.09966651019985152\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.15832181225509934 TEST LOSS: 0.09941024810001814\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.1665488437347975 TEST LOSS: 0.09764757881687346\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.1639283055837801 TEST LOSS: 0.10488803031407923\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.16537060129412762 TEST LOSS: 0.11412116351000585\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.15921425362442912 TEST LOSS: 0.10844966462554995\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.15810606486861034 TEST LOSS: 0.09680423513258343\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.16496129667681578 TEST LOSS: 0.10841670374340559\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.15608196453900966 TEST LOSS: 0.10205734162369214\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.15727693395014067 TEST LOSS: 0.10090223132311234\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.1683176793796246 TEST LOSS: 0.10657884313913138\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.1577643662331854 TEST LOSS: 0.10520078888196674\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.1642658656829275 TEST LOSS: 0.10790460913274225\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.16256266271925304 TEST LOSS: 0.10656981750922871\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.1729243719429421 TEST LOSS: 0.11725605374181867\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.16072080220028262 TEST LOSS: 0.10702265978511309\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.15914745914976508 TEST LOSS: 0.10403827465523953\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.1532566854884693 TEST LOSS: 0.0937115941380671\n",
      "0.15252250124052685 0.07838170849939909\n",
      "COMPUTING FOR ITERATION NUMBER 4\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000017810FF0208>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.25553684774395385 TEST LOSS: 0.26883850210810895\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.19275545431849214 TEST LOSS: 0.19681696614045793\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.15258504904382414 TEST LOSS: 0.14646734562348057\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.1340478776837856 TEST LOSS: 0.1362263533463974\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.10392123564082292 TEST LOSS: 0.11589508758515409\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.09724600333915663 TEST LOSS: 0.11371079014136565\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.09537769131244603 TEST LOSS: 0.10302480769901295\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.09494048268660606 TEST LOSS: 0.10118217790372347\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.10671768500782852 TEST LOSS: 0.10680937935315837\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.09127777055753222 TEST LOSS: 0.09747151621317508\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.10473087706146324 TEST LOSS: 0.10343359963457384\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.0825777163860627 TEST LOSS: 0.08369137975427803\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.09389583496761052 TEST LOSS: 0.10042201144280637\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.08998308983304622 TEST LOSS: 0.09330251519178467\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.08636345519263104 TEST LOSS: 0.08614227597519149\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.09323895328936792 TEST LOSS: 0.08989807666767374\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.10039867204223456 TEST LOSS: 0.10697270711844206\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.10444167575455857 TEST LOSS: 0.1076162331716868\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.0981290842394935 TEST LOSS: 0.1017582080629351\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.0905349846543957 TEST LOSS: 0.09380837104061958\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.09017200518821725 TEST LOSS: 0.09833448191312602\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.08431185096062833 TEST LOSS: 0.09495695941439097\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.08635117679425691 TEST LOSS: 0.0970156315328312\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.08267369140686757 TEST LOSS: 0.09140317754694093\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.0902193043680703 TEST LOSS: 0.09482500603040592\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.08769163023230392 TEST LOSS: 0.09680506353591432\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.08571293042172641 TEST LOSS: 0.08996207154435568\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.08580243117662249 TEST LOSS: 0.0879800649252992\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.08743308613946658 TEST LOSS: 0.09079213756699284\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.08371746076425089 TEST LOSS: 0.0935545134603683\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.08352560941000504 TEST LOSS: 0.09331550684340165\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.09183860246583798 TEST LOSS: 0.09276140956057709\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.08829712190630966 TEST LOSS: 0.09571695429465983\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.08833904858398083 TEST LOSS: 0.09245957159782384\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.08756907212825008 TEST LOSS: 0.08612813085297236\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.08127177216474038 TEST LOSS: 0.08566232386773508\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.08407060543802397 TEST LOSS: 0.08670503666351347\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.08312539975834855 TEST LOSS: 0.08995887798952222\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.0823768623091079 TEST LOSS: 0.08595970263392311\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.08441989345030373 TEST LOSS: 0.08728183353925549\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.08377036238846734 TEST LOSS: 0.08707698130685734\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.07746573907806067 TEST LOSS: 0.08851531794853751\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.08180615808631386 TEST LOSS: 0.09065888113240876\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.08262751421987144 TEST LOSS: 0.08098383753168237\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.08791842103217663 TEST LOSS: 0.09363192488078358\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.08783130998473919 TEST LOSS: 0.08709625131193205\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.08271657208544625 TEST LOSS: 0.08509964047727538\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.07901845192627768 TEST LOSS: 0.07784814614349904\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.08017932291302794 TEST LOSS: 0.08059270735503314\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.08323396432592559 TEST LOSS: 0.08763829705550528\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.07909688368920155 TEST LOSS: 0.08143423476162309\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000017812131358>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.19887766641732804 TEST LOSS: 0.23025754167010257\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.10894693619753047 TEST LOSS: 0.13784811607962047\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.09230654891354272 TEST LOSS: 0.11742396942537407\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.08769401011371232 TEST LOSS: 0.10606407834126545\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.08389765344731066 TEST LOSS: 0.1044647797480133\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.080954679476859 TEST LOSS: 0.0996811361844544\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.08524199549894043 TEST LOSS: 0.09866794047218078\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.08505775290817866 TEST LOSS: 0.08886261270577661\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.08598210907622063 TEST LOSS: 0.09512237876422111\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.08427358405003439 TEST LOSS: 0.0846364184102432\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.0871800111285143 TEST LOSS: 0.08989634777421635\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.08419383136627501 TEST LOSS: 0.08281257311314787\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.08484476572916143 TEST LOSS: 0.08402879470469975\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.0862588378964304 TEST LOSS: 0.08637221385145384\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.08222905882360795 TEST LOSS: 0.08744569030766951\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.08691527457498291 TEST LOSS: 0.08477053641135932\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.07995107961685302 TEST LOSS: 0.079097623812556\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.08328754618471439 TEST LOSS: 0.08019826401401854\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.08236906491364232 TEST LOSS: 0.08050648110598581\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.07968327519247129 TEST LOSS: 0.07875008006489283\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.08215935782971254 TEST LOSS: 0.08055870794253253\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.08346590377394417 TEST LOSS: 0.08358967539077872\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.07897040236433868 TEST LOSS: 0.08099339398257985\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.08273860576449565 TEST LOSS: 0.07472537778724848\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.09029223194637095 TEST LOSS: 0.07229845200287874\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.08030040764310822 TEST LOSS: 0.0845057780462693\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.0854930410920468 TEST LOSS: 0.07682676685781062\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.08461844461418647 TEST LOSS: 0.07360154584011665\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.08068725305471895 TEST LOSS: 0.07525922450384515\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.0837266061954777 TEST LOSS: 0.07602730894995345\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.0828736110106435 TEST LOSS: 0.07446371987599529\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.08658962937655264 TEST LOSS: 0.0717181309116329\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.07855058060335372 TEST LOSS: 0.07292267746942865\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.07939241041508019 TEST LOSS: 0.06980097236187521\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.08090462735505505 TEST LOSS: 0.07811856865556172\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.08222235273335735 TEST LOSS: 0.07410499149667683\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.08128511450759986 TEST LOSS: 0.07623537469901374\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.0821122871014808 TEST LOSS: 0.07475764477921476\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.08282676285216992 TEST LOSS: 0.06906854650390434\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.0843021624459756 TEST LOSS: 0.06639699608415806\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.07644073327032376 TEST LOSS: 0.06924627499961866\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.075595048547309 TEST LOSS: 0.06910605851737162\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.07941413379294573 TEST LOSS: 0.07239717068135301\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.0807806022288272 TEST LOSS: 0.07590753381725072\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.08026465200620743 TEST LOSS: 0.07618078660383294\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.07754157171302985 TEST LOSS: 0.068225791249506\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.08091991315197385 TEST LOSS: 0.07013337013241903\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.08466384901039309 TEST LOSS: 0.06478572544836232\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.08427018341873907 TEST LOSS: 0.07036816249271054\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.07678960907425925 TEST LOSS: 0.0711159542392597\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.08095405727275365 TEST LOSS: 0.07608900698747412\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x00000178136F8F98>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.18087665387885568 TEST LOSS: 0.28250644580269113\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.13370337961674847 TEST LOSS: 0.1828039884278549\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.11288463036156918 TEST LOSS: 0.15925592303865677\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.1022592190989206 TEST LOSS: 0.13259198633849814\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.09724733105698932 TEST LOSS: 0.1426174576286807\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.09741259833391934 TEST LOSS: 0.12498641550059812\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.09233274810344272 TEST LOSS: 0.11666332399549617\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.09602030120111407 TEST LOSS: 0.12341099884290771\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.08852742965744663 TEST LOSS: 0.11927026144711247\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.0889104257475875 TEST LOSS: 0.10597341538419552\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.0896951987973743 TEST LOSS: 0.0988873655576032\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.08446628812348014 TEST LOSS: 0.10011413222945664\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.08867718083694581 TEST LOSS: 0.11588778597409649\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.08748264349731927 TEST LOSS: 0.09819536138513087\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.08632487120634381 TEST LOSS: 0.08987524481910103\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.0825375003929618 TEST LOSS: 0.09603007193060595\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.08992384985821489 TEST LOSS: 0.0850477516900648\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.08347637128795048 TEST LOSS: 0.11551580675402146\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.0830759175420229 TEST LOSS: 0.09207026454387104\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.08062639524488274 TEST LOSS: 0.08893701856156183\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.08638586928036562 TEST LOSS: 0.08872636041280717\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.08230279210799137 TEST LOSS: 0.08376305427466481\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.08350179841285868 TEST LOSS: 0.08219674153769375\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.08220762312832101 TEST LOSS: 0.08958220249949563\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.08354731854281242 TEST LOSS: 0.08393885806551853\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.08554806081461061 TEST LOSS: 0.08204294252299581\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.08309450307834171 TEST LOSS: 0.09468631238676892\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.08099830534330525 TEST LOSS: 0.09407836033571901\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.08418212834359048 TEST LOSS: 0.09363944663401345\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.08178840403415151 TEST LOSS: 0.08437616012223326\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.08295726753979442 TEST LOSS: 0.08397118979721223\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.08122784790218242 TEST LOSS: 0.09538453967195472\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.08206151922746757 TEST LOSS: 0.08971000043048927\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.08317066773316198 TEST LOSS: 0.08694251482616538\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.08084261507239245 TEST LOSS: 0.09498970545827813\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.0819713641381283 TEST LOSS: 0.08370158589129878\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.08082426138030842 TEST LOSS: 0.08011955899819892\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.08068906740862634 TEST LOSS: 0.08729224043462153\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.08196031640273263 TEST LOSS: 0.08811974761665803\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.08247549974120943 TEST LOSS: 0.08043107305426701\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.0831709887319883 TEST LOSS: 0.08346561064138755\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.08182868773389046 TEST LOSS: 0.08324189500914145\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.08410706150953733 TEST LOSS: 0.07930395211016456\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.08216169454563062 TEST LOSS: 0.0842477565902284\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.0809730691226542 TEST LOSS: 0.08368498798827592\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.08332537080392775 TEST LOSS: 0.08193889311041877\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.07971861894437358 TEST LOSS: 0.08293890120378997\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.08303674803868821 TEST LOSS: 0.08180442215149206\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.08083711115350929 TEST LOSS: 0.08032430761520888\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.0813054908247439 TEST LOSS: 0.08569525548650163\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.08217941263937535 TEST LOSS: 0.08714362438060685\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001781A61DBA8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.23965020216005348 TEST LOSS: 0.16394382199333163\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.18913774799663466 TEST LOSS: 0.1326141353013114\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.14600486656066836 TEST LOSS: 0.09696382708650697\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.15229606919122504 TEST LOSS: 0.09703641956631835\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.13167487763700128 TEST LOSS: 0.08596642635153427\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.1355048498883632 TEST LOSS: 0.08825429241928197\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.1262506036909356 TEST LOSS: 0.08216489168572036\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.1271696101399335 TEST LOSS: 0.07702002043100034\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.12732413246520047 TEST LOSS: 0.0779120404103286\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.12432423933510196 TEST LOSS: 0.08049200840754009\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.12273692027877915 TEST LOSS: 0.07692754664328212\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.12158377475700256 TEST LOSS: 0.07563671477968255\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.12492553873581316 TEST LOSS: 0.07825426377280034\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.1266228324924579 TEST LOSS: 0.08255964590577458\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.12018599829176285 TEST LOSS: 0.07595015386014996\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.11029359803688353 TEST LOSS: 0.07628632065544533\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.11722217584393026 TEST LOSS: 0.07936887919542836\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.11317529495770907 TEST LOSS: 0.0744273551731783\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.12067125741445842 TEST LOSS: 0.07570814627546862\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.11269018476655993 TEST LOSS: 0.0733386817114489\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.11320895479092137 TEST LOSS: 0.07580950110205764\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.11220361429432651 TEST LOSS: 0.0736416659524385\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.11562316563444765 TEST LOSS: 0.07307227439451856\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.10614384469185172 TEST LOSS: 0.0709568394014009\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.11049627045980662 TEST LOSS: 0.07375067141773779\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.10622561986856441 TEST LOSS: 0.07159827960775535\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.10559923441249745 TEST LOSS: 0.07262277369730956\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.10502152443513982 TEST LOSS: 0.07340319116314116\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.11199373091355931 TEST LOSS: 0.07480485607401334\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.10827650524888378 TEST LOSS: 0.07055865211526847\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.11042601743541494 TEST LOSS: 0.07114955985986819\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.10944237895406342 TEST LOSS: 0.07196303316249628\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.11116330088817768 TEST LOSS: 0.0695010486295967\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.11514935579319853 TEST LOSS: 0.07202036746783425\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.1067228147591281 TEST LOSS: 0.06958075889387191\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.10579587436512405 TEST LOSS: 0.07055390922628625\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.11146438646478786 TEST LOSS: 0.06922181040105625\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.11339554461229343 TEST LOSS: 0.06888397775155365\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.10324196391739826 TEST LOSS: 0.06933783339964796\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.09620986138995402 TEST LOSS: 0.07075736386616711\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.09864182840877667 TEST LOSS: 0.07121948265610265\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.10523507897541129 TEST LOSS: 0.07258332552496252\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.1073078192347385 TEST LOSS: 0.0714238686923726\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.10189861932395158 TEST LOSS: 0.07092443945781339\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.10640946309416863 TEST LOSS: 0.06867967002945045\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.10816634770770207 TEST LOSS: 0.07053801194527165\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.10014542639513227 TEST LOSS: 0.07060637853511678\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.1013169379269409 TEST LOSS: 0.06892360652268684\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.10436068491045566 TEST LOSS: 0.06660872640879734\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.10599766152983515 TEST LOSS: 0.06749730772838111\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.096453113310729 TEST LOSS: 0.0694015408808206\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x00000178136FD470>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.27845661372217534 TEST LOSS: 0.2974779022759633\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.19299594404814951 TEST LOSS: 0.21033714108904578\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.14486513449963195 TEST LOSS: 0.16749812447226473\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.1318492261368115 TEST LOSS: 0.13689341081493292\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.12030243250157259 TEST LOSS: 0.13781514179049179\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.11716783992073287 TEST LOSS: 0.1382482967040332\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.11335839874087325 TEST LOSS: 0.12960554487553097\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.11038460999232151 TEST LOSS: 0.12582690173065547\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.11078657326382142 TEST LOSS: 0.11483295998069226\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.11146815313612955 TEST LOSS: 0.14007929566102412\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.11130641627763033 TEST LOSS: 0.1174457374182792\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.10815420381210819 TEST LOSS: 0.12331721700451048\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.10968772670861389 TEST LOSS: 0.12309792935385618\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.10945908844227056 TEST LOSS: 0.12365164168485053\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.10807342849914577 TEST LOSS: 0.1205967094746353\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.10636159863199743 TEST LOSS: 0.1253733395329031\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.10500835285705047 TEST LOSS: 0.12366047029755449\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.10535037706947642 TEST LOSS: 0.1215014537916688\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.10402319366026003 TEST LOSS: 0.13164157971010026\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.1039512105924095 TEST LOSS: 0.1235744957468743\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.10501479187245061 TEST LOSS: 0.12064822864654225\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.11148971106052491 TEST LOSS: 0.11355135816329325\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.10374933673322617 TEST LOSS: 0.11755528355581088\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.10542573808707616 TEST LOSS: 0.12577996982831385\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.10581425958830104 TEST LOSS: 0.128995442957011\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.10721596555330393 TEST LOSS: 0.13459880068510605\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.11024797040433139 TEST LOSS: 0.11763786538226763\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.10516920288736721 TEST LOSS: 0.12371421207643278\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.11241065515771245 TEST LOSS: 0.11012511572448394\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.10925595503651371 TEST LOSS: 0.11120812272785027\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.10528362411535033 TEST LOSS: 0.12048340857620107\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.10863290681560611 TEST LOSS: 0.11170379834846579\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.10459774701375484 TEST LOSS: 0.11679487862681368\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.10233118240527966 TEST LOSS: 0.12241338621608\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.10191620508898866 TEST LOSS: 0.12742492391250773\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.10526674815729564 TEST LOSS: 0.11650505145008831\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.10824399945494152 TEST LOSS: 0.11601157720470502\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.10550985911775054 TEST LOSS: 0.11725481687515389\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.1057373161706676 TEST LOSS: 0.11750173358052632\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.10547429439775063 TEST LOSS: 0.11622699930340236\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.10755223854406443 TEST LOSS: 0.11203149763322573\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.10474490492154218 TEST LOSS: 0.11765873779647755\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.10920430217738705 TEST LOSS: 0.11937067830263076\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.10590715148681878 TEST LOSS: 0.11656886076800456\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.10417344538156265 TEST LOSS: 0.12253235261631375\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.10523468110270454 TEST LOSS: 0.12693689381965778\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.10082011161773179 TEST LOSS: 0.12299178251617152\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.10626768142051518 TEST LOSS: 0.13081128739256842\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.10402087847458989 TEST LOSS: 0.12304568401103742\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.10255584831523615 TEST LOSS: 0.11757571428490941\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.10484998409068275 TEST LOSS: 0.11659593036265478\n",
      "0.10082011161773179 0.08634794553783098\n",
      "COMPUTING FOR ITERATION NUMBER 5\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x00000178121BCD30>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.23291844058381989 TEST LOSS: 0.2794844798087873\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.18481272277229116 TEST LOSS: 0.22859106856991554\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.14522016468127208 TEST LOSS: 0.19037141385420325\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.1288454339039263 TEST LOSS: 0.1774705720745298\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.11346492356612782 TEST LOSS: 0.15671062024871688\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.12938172211599813 TEST LOSS: 0.1679045466595258\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.11135991048302457 TEST LOSS: 0.16064546988309028\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.117940798407521 TEST LOSS: 0.16197098592407635\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.09395860225802118 TEST LOSS: 0.15144284936277957\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.10262751382982065 TEST LOSS: 0.14959332213235133\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.11618071119426396 TEST LOSS: 0.16119337590050828\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.09467129239659638 TEST LOSS: 0.14418187942038152\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.1077188105192487 TEST LOSS: 0.15370733479823548\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.09236868196215192 TEST LOSS: 0.13880530458575252\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.09841330885192008 TEST LOSS: 0.14566146481655784\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.10335236234700865 TEST LOSS: 0.14906079621061472\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.10242961340793277 TEST LOSS: 0.1479110404090084\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.10332466083784694 TEST LOSS: 0.15161303303480783\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.09713295295705468 TEST LOSS: 0.14750438954456255\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.09597689853180413 TEST LOSS: 0.14628398543932317\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.10106301266150136 TEST LOSS: 0.14922327379994507\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.09617935947047918 TEST LOSS: 0.14407047687020413\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.10772498051755384 TEST LOSS: 0.14710398341378544\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.09646281437632531 TEST LOSS: 0.14077083133326015\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.09475912329130066 TEST LOSS: 0.1400581872096431\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.1038909561076291 TEST LOSS: 0.14657098332865612\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.09582870636211953 TEST LOSS: 0.14733230296056588\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.0913926733938118 TEST LOSS: 0.14520426546487772\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.09584468549454662 TEST LOSS: 0.1432552346070809\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.09246300643743796 TEST LOSS: 0.13822989834727392\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.08710354227653967 TEST LOSS: 0.13814383849922812\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.09406488543439838 TEST LOSS: 0.143470455334765\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.093503658145832 TEST LOSS: 0.14042846049411464\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.08724517670617543 TEST LOSS: 0.13703710910625008\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.08568738849458545 TEST LOSS: 0.13622376496311195\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.09105597853986647 TEST LOSS: 0.1391469784445605\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.09354997566033724 TEST LOSS: 0.14364337535418611\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.0956994425706779 TEST LOSS: 0.13856388456536167\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.09731680317046965 TEST LOSS: 0.14339871794763462\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.09134979078245299 TEST LOSS: 0.13408825073095212\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.09148210342826356 TEST LOSS: 0.13905455207507644\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.09051167506265653 TEST LOSS: 0.13964058014430109\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.08905063439805633 TEST LOSS: 0.13598724728656425\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.08588000935973973 TEST LOSS: 0.13461452152527453\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.08674187954667453 TEST LOSS: 0.13309289516490702\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.08579872045297458 TEST LOSS: 0.12796900587596913\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.0946502277165534 TEST LOSS: 0.14140838823022597\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.09912532050112384 TEST LOSS: 0.14287381065291807\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.09580707946166377 TEST LOSS: 0.1456504238746879\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.08676283607812316 TEST LOSS: 0.13339421496973952\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.09069379648395316 TEST LOSS: 0.13854162477924742\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x00000178133A1940>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.28178654632796685 TEST LOSS: 0.20416982911384624\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.1778233155918604 TEST LOSS: 0.12649836371650314\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.15275918775564518 TEST LOSS: 0.10538206587441576\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.11093631999433168 TEST LOSS: 0.08447160181193678\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.10666142693238728 TEST LOSS: 0.07877705845873278\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.0982628644245911 TEST LOSS: 0.07854669278549567\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.09048371162535199 TEST LOSS: 0.07196752104952076\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.09534971619288052 TEST LOSS: 0.07301114883148135\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.08610726139167642 TEST LOSS: 0.06756411281626656\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.0994360493731962 TEST LOSS: 0.07055345373285239\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.08998882263865547 TEST LOSS: 0.07091829200886844\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.08899683042100791 TEST LOSS: 0.06637205283720889\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.09237193555314296 TEST LOSS: 0.06876587827238355\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.08641736120446106 TEST LOSS: 0.07007369035496808\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.08537834791910723 TEST LOSS: 0.07001201758284957\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.0911375046922738 TEST LOSS: 0.06982149838066055\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.0857530424439086 TEST LOSS: 0.06791873328500016\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.09744180243067474 TEST LOSS: 0.06770759528828384\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.0878435403394112 TEST LOSS: 0.06508933340182511\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.08250200875774012 TEST LOSS: 0.06509571599283359\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.08655617120873031 TEST LOSS: 0.06694521548148095\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.08761983322261543 TEST LOSS: 0.06678202715714293\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.08513694100494375 TEST LOSS: 0.06402686351194634\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.08229530608452874 TEST LOSS: 0.06693451676702969\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.08079192085649772 TEST LOSS: 0.0665797853394657\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.09425519857080315 TEST LOSS: 0.07008926484418537\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.0818322894905367 TEST LOSS: 0.06736617437813555\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.08022209952154426 TEST LOSS: 0.06116119916256693\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.08654029040547077 TEST LOSS: 0.06697150422787618\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.08016460684249582 TEST LOSS: 0.06539904836339847\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.08321832293289698 TEST LOSS: 0.06283319058715284\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.0843684938563545 TEST LOSS: 0.06350321576029266\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.0835814572341496 TEST LOSS: 0.06362655978470291\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.08173502951035709 TEST LOSS: 0.06536846253982007\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.08265279620010474 TEST LOSS: 0.06379592627449496\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.08290578400634145 TEST LOSS: 0.06634255238560957\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.08252753145105458 TEST LOSS: 0.06336766741969434\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.08233527430055952 TEST LOSS: 0.06370005543605436\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.08499980763542887 TEST LOSS: 0.0661521467210855\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.0831196228298038 TEST LOSS: 0.06363427914313653\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.08363769017104389 TEST LOSS: 0.06403913801710628\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.08185517261405094 TEST LOSS: 0.063761357631044\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.07941418116453432 TEST LOSS: 0.06670300630226231\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.07998814212828176 TEST LOSS: 0.06190142386900103\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.08126244150600456 TEST LOSS: 0.06752760989018479\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.08156363398152232 TEST LOSS: 0.06641089888965973\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.07830449480973747 TEST LOSS: 0.06376863626031934\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.0814886954512073 TEST LOSS: 0.06546907136081268\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.08295409225045647 TEST LOSS: 0.06310725254559278\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.08095613550302828 TEST LOSS: 0.06498347890787383\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.08159671930347716 TEST LOSS: 0.0617085805022876\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x00000178117CEA90>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.3384319218283842 TEST LOSS: 0.2847266635806283\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.21392570569008096 TEST LOSS: 0.18079270598787198\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.189684269074308 TEST LOSS: 0.1563819132103469\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.17403336178439086 TEST LOSS: 0.1458917172054201\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.14919883743080833 TEST LOSS: 0.12998214857939208\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.12529602855478775 TEST LOSS: 0.12174045196183754\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.12697419327252957 TEST LOSS: 0.11879756051925018\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.11869232870561536 TEST LOSS: 0.10986626089439597\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.098317767762417 TEST LOSS: 0.10940609239732278\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.10509241414999441 TEST LOSS: 0.1051436976754341\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.11445283405760052 TEST LOSS: 0.11410333164022103\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.11151828659245745 TEST LOSS: 0.10902828675038408\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.10913901876514769 TEST LOSS: 0.11066494101152036\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.09680343830083578 TEST LOSS: 0.10676144407900365\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.1088254921226004 TEST LOSS: 0.11044717343029746\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.10837843221104658 TEST LOSS: 0.11061604437205141\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.11542193772212932 TEST LOSS: 0.11227595692172429\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.11172270599529426 TEST LOSS: 0.11117160960276327\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.10381052050816995 TEST LOSS: 0.1083604723479658\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.10550009409756506 TEST LOSS: 0.10858646659742677\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.09665566166634267 TEST LOSS: 0.10594875723412507\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.10633741622492336 TEST LOSS: 0.1105741868822841\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.09415074015088777 TEST LOSS: 0.11418357289673033\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.11279771707725655 TEST LOSS: 0.10843314074064614\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.09760039415762288 TEST LOSS: 0.1062544637171652\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.09298680953650082 TEST LOSS: 0.1090013402810475\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.08772581873240275 TEST LOSS: 0.10768136865460608\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.10018162422930857 TEST LOSS: 0.10997586218673738\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.09573336423707844 TEST LOSS: 0.10434651303362019\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.09747526675230166 TEST LOSS: 0.1083839201689503\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.09684910211541817 TEST LOSS: 0.10624415585930497\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.10080728701248881 TEST LOSS: 0.10867579830079911\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.08308155513782307 TEST LOSS: 0.10876562899358651\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.08795081859056365 TEST LOSS: 0.1077047233007199\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.08902173494760147 TEST LOSS: 0.11087073593912732\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.09502246057957028 TEST LOSS: 0.10620881017356598\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.0914862930962748 TEST LOSS: 0.10672390264968967\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.10069707032180703 TEST LOSS: 0.10918440844623917\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.08938847891666404 TEST LOSS: 0.10707641001380434\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.09918411014725759 TEST LOSS: 0.11066500195137959\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.10098770408552211 TEST LOSS: 0.10842825453447634\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.10514639293710869 TEST LOSS: 0.10761175693705827\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.1036328977018814 TEST LOSS: 0.10718258946864524\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.10180521844650146 TEST LOSS: 0.10959499886351459\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.08797417410043595 TEST LOSS: 0.10805595451794649\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.09358172001777428 TEST LOSS: 0.10790978860803029\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.09467348778301889 TEST LOSS: 0.11400759820156861\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.09487903388119086 TEST LOSS: 0.10622014718068086\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.1016697513087877 TEST LOSS: 0.10796428269063141\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.09030073170968157 TEST LOSS: 0.1115297227667137\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.09527123638467093 TEST LOSS: 0.10989862561840258\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000017811092240>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.2123617477027063 TEST LOSS: 0.23554439035244049\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.14067970728355558 TEST LOSS: 0.19347463822104438\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.11299444628194036 TEST LOSS: 0.1508643367011889\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.10356649406158405 TEST LOSS: 0.13656153463239198\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.09935285461698201 TEST LOSS: 0.1258066638195714\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.09077024803600076 TEST LOSS: 0.12290238526418415\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.10684804818995206 TEST LOSS: 0.11532347190214366\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.08645603635382387 TEST LOSS: 0.12113938593847826\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.08806826817683337 TEST LOSS: 0.11941020018921956\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.08814672141003158 TEST LOSS: 0.11205871936768455\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.09211418466616336 TEST LOSS: 0.11360843711626076\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.08186419407826723 TEST LOSS: 0.11573895083146174\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.0834249037140642 TEST LOSS: 0.11345184801236317\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.08052669863425294 TEST LOSS: 0.11051211396362975\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.08106925668826057 TEST LOSS: 0.1096691226297105\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.08482420195156867 TEST LOSS: 0.10306317044055993\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.08135689377628703 TEST LOSS: 0.11211665915978238\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.07818442217854457 TEST LOSS: 0.11122428783004372\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.08056651750306415 TEST LOSS: 0.1017492665501686\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.0795670268869925 TEST LOSS: 0.10230517049731815\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.07803759540473805 TEST LOSS: 0.10221562583761437\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.08000459908989553 TEST LOSS: 0.10305217909326247\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.08257305824322785 TEST LOSS: 0.10209925944818361\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.07900806555933511 TEST LOSS: 0.10005720154823268\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.07835647110885373 TEST LOSS: 0.10881227281699538\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.07493034503854058 TEST LOSS: 0.10179965187936943\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.07554710080867333 TEST LOSS: 0.10269538932333014\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.07468483823333774 TEST LOSS: 0.109453453172117\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.07508478637175282 TEST LOSS: 0.09785692847894832\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.07556497652057394 TEST LOSS: 0.11163652912305778\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.07765114228949774 TEST LOSS: 0.0998464705527805\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.07736460853064915 TEST LOSS: 0.10666832689662106\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.07664705199470921 TEST LOSS: 0.09977184838788783\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.0736273522090027 TEST LOSS: 0.10279012710237548\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.07514400732204876 TEST LOSS: 0.10121283126420069\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.07363510021188423 TEST LOSS: 0.0998804323075659\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.07464283820826347 TEST LOSS: 0.10955830168267049\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.07569626389420166 TEST LOSS: 0.09209295459383299\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.07642830516870874 TEST LOSS: 0.10465057012310312\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.07291703905235859 TEST LOSS: 0.10384182910290189\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.07439807499814127 TEST LOSS: 0.10694765525488274\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.07907231946190164 TEST LOSS: 0.0941262779790767\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.07267401212258555 TEST LOSS: 0.10276992520656449\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.07256499018810132 TEST LOSS: 0.10511371542001434\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.0727086521325932 TEST LOSS: 0.10399069503642354\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.07170055151974379 TEST LOSS: 0.09461755390377558\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.07407898831971944 TEST LOSS: 0.10671545770591868\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.07279982685515574 TEST LOSS: 0.094302188773231\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.07285790698665619 TEST LOSS: 0.1075609077185676\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.07303480392044502 TEST LOSS: 0.10648083736034876\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.07649246448247626 TEST LOSS: 0.10149946608662098\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x00000178121D1CF8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.2516498775540871 TEST LOSS: 0.20329345600197626\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.15621879456573157 TEST LOSS: 0.13702721035568924\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.1387936359562218 TEST LOSS: 0.11640754889216544\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.12234109238399571 TEST LOSS: 0.10121906098025145\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.10698243676239794 TEST LOSS: 0.09552569795211738\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.10859756834035549 TEST LOSS: 0.09083869568060957\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.10286884433175862 TEST LOSS: 0.08967125907192651\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.10247253194967333 TEST LOSS: 0.0878377685936697\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.09602882239688071 TEST LOSS: 0.08439334425108698\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.09407250188868986 TEST LOSS: 0.08438366942276428\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.09340593160835603 TEST LOSS: 0.08480550562510943\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.08955008619747741 TEST LOSS: 0.08239179577247696\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.09450096198256033 TEST LOSS: 0.08318303699481462\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.09011700066966488 TEST LOSS: 0.0823486064662636\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.09681106391719971 TEST LOSS: 0.08265630753679129\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.09461322699385287 TEST LOSS: 0.08307091314290647\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.0916039854574499 TEST LOSS: 0.08370565806461733\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.09127525416224734 TEST LOSS: 0.08307765455455207\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.09574248572161621 TEST LOSS: 0.0820077148322318\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.09082567965353218 TEST LOSS: 0.08173204238892455\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.0907746776282223 TEST LOSS: 0.08260908657629941\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.08865322557949866 TEST LOSS: 0.082666590861202\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.08949732855734532 TEST LOSS: 0.0807034466276483\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.08975938778735244 TEST LOSS: 0.08247506967749522\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.09875987675058696 TEST LOSS: 0.08288148420291917\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.09006866292390861 TEST LOSS: 0.08100583495780592\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.09168037213871401 TEST LOSS: 0.08178443493363606\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.08858849604246664 TEST LOSS: 0.08052628152241079\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.09443720049038254 TEST LOSS: 0.0811132860340478\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.08984803094256512 TEST LOSS: 0.08251699816279946\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.08962185158520994 TEST LOSS: 0.08484125218988144\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.09239348894839065 TEST LOSS: 0.07940966289321327\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.09152583243484899 TEST LOSS: 0.08189611992248641\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.0917428986260184 TEST LOSS: 0.08266766782018595\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.09005079369963219 TEST LOSS: 0.08266377656382669\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.0903536176486224 TEST LOSS: 0.08164309818259938\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.092390644742607 TEST LOSS: 0.08318918510818586\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.09265228966770048 TEST LOSS: 0.0818542760917923\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.09180022844639531 TEST LOSS: 0.08160513195344397\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.0888031689978413 TEST LOSS: 0.08180522316154237\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.09261654947385017 TEST LOSS: 0.08051445154059153\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.09297708321428935 TEST LOSS: 0.082815136502648\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.0897105646461704 TEST LOSS: 0.07969342615986606\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.08785966846259748 TEST LOSS: 0.08087765986475685\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.08956190789777846 TEST LOSS: 0.08147176344743562\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.08958876353485287 TEST LOSS: 0.08105608718841974\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.09051289040910103 TEST LOSS: 0.08155985158759477\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.09101013448369796 TEST LOSS: 0.08045307266627935\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.09041828114965923 TEST LOSS: 0.08007521653958354\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.08955107339538496 TEST LOSS: 0.08183812824549516\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.09389280436605257 TEST LOSS: 0.07741447160011561\n",
      "0.08563093240777338 0.09702702890482422\n",
      "COMPUTING FOR ITERATION NUMBER 6\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000017810C50748>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.2776204898212301 TEST LOSS: 0.2532891224506571\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.16823202586217903 TEST LOSS: 0.14485431326877166\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.17049073152502736 TEST LOSS: 0.14593848178251054\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.13726586367456126 TEST LOSS: 0.12568394095195698\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.12983315598159353 TEST LOSS: 0.10523454786037685\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.13597435325324786 TEST LOSS: 0.11975464848673982\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.12339802935154619 TEST LOSS: 0.10464248958620881\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.12744544122266643 TEST LOSS: 0.10619840561468616\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.13214209162914375 TEST LOSS: 0.10457264529673317\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.13542090105083004 TEST LOSS: 0.10746038508507805\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.13614361195874353 TEST LOSS: 0.1053756817477484\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.13180469692458446 TEST LOSS: 0.10264768777982719\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.11225448714617002 TEST LOSS: 0.08739965466033563\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.12112154763619112 TEST LOSS: 0.09161126992846821\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.11866937981156066 TEST LOSS: 0.08812606419425441\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.12184162037481691 TEST LOSS: 0.09449367676349527\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.11482128010185116 TEST LOSS: 0.09142773306362821\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.12033853253458501 TEST LOSS: 0.08662518562688425\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.11938272642875684 TEST LOSS: 0.09382744297594671\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.11856291877673687 TEST LOSS: 0.08519265638227355\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.12502105671292654 TEST LOSS: 0.09295674729852227\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.12185244213829433 TEST LOSS: 0.09081977560461356\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.12271356571807741 TEST LOSS: 0.09228218562964724\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.13158995312643704 TEST LOSS: 0.09086955133169021\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.12460490324300048 TEST LOSS: 0.09369415225953619\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.11612853239059398 TEST LOSS: 0.08435053758334182\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.11799827451160706 TEST LOSS: 0.08353392117707265\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.11221170744453818 TEST LOSS: 0.08149194631959089\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.11623154986256794 TEST LOSS: 0.08288592220911378\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.11687770549461646 TEST LOSS: 0.08995067409300389\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.12927046826913732 TEST LOSS: 0.09645254306853492\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.11747248509708658 TEST LOSS: 0.09034151765172378\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.11475215600117507 TEST LOSS: 0.08344494736684674\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.11529962654211351 TEST LOSS: 0.08497863688759609\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.1147190817300079 TEST LOSS: 0.07898118853261615\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.11435042609543197 TEST LOSS: 0.07830565836630109\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.11762018105530825 TEST LOSS: 0.0810712512197139\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.11763866043264691 TEST LOSS: 0.08686728332077832\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.11743210230674686 TEST LOSS: 0.08398489737332189\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.11597619504875059 TEST LOSS: 0.07778462995429136\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.12059967165895881 TEST LOSS: 0.08934714159569188\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.11065484034617563 TEST LOSS: 0.07615102617219499\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.11196582512491306 TEST LOSS: 0.07820160345605402\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.11646842469964537 TEST LOSS: 0.08009185981807006\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.12275997632257274 TEST LOSS: 0.08378143754195298\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.11648140171024574 TEST LOSS: 0.07889654323875424\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.12061265377319748 TEST LOSS: 0.0899530047442914\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.116567861666434 TEST LOSS: 0.08314201176462106\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.11634269930806516 TEST LOSS: 0.08358861658555242\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.11290598001029391 TEST LOSS: 0.08036365753625703\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.1127428924090212 TEST LOSS: 0.07800687884689891\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x00000178121D1A90>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.25491001863471724 TEST LOSS: 0.18914438587753785\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.15702487218133448 TEST LOSS: 0.11550317469523422\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.13883954573332444 TEST LOSS: 0.10277772060716216\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.12257918963565696 TEST LOSS: 0.09025478823608064\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.11092993983221153 TEST LOSS: 0.07812511984727959\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.1113761980330733 TEST LOSS: 0.08408106395564366\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.10151551636904928 TEST LOSS: 0.07075703811241583\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.09987972720352357 TEST LOSS: 0.07356724182693362\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.10067750962613053 TEST LOSS: 0.07212975965261673\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.09808978298476378 TEST LOSS: 0.06831837156874578\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.09843893301032329 TEST LOSS: 0.07142164691232215\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.09460779317860685 TEST LOSS: 0.07452305127865153\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.10025159874979853 TEST LOSS: 0.06845614639305252\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.09562849007162125 TEST LOSS: 0.06849965667965027\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.09987660784688253 TEST LOSS: 0.06975881490554985\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.09708222301816477 TEST LOSS: 0.06963423566073319\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.09270652241949297 TEST LOSS: 0.06866191251576892\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.09762971484804076 TEST LOSS: 0.06550060577418142\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.09537838499764975 TEST LOSS: 0.06773314251322242\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.09613473916879033 TEST LOSS: 0.0683651441096464\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.09331285575579533 TEST LOSS: 0.06637217115664769\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.0947930923200962 TEST LOSS: 0.06930944378757004\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.09421725398096709 TEST LOSS: 0.06785838011238318\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.10004876286303942 TEST LOSS: 0.0659057739054756\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.09557151401966284 TEST LOSS: 0.06672397001123802\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.09122160764476733 TEST LOSS: 0.06614643404153397\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.09424565402391251 TEST LOSS: 0.0660079245885396\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.09461873400210392 TEST LOSS: 0.06632644974286314\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.09363754858864491 TEST LOSS: 0.06414377032315409\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.09174070336360735 TEST LOSS: 0.06751667408026586\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.09277677892254522 TEST LOSS: 0.0668965471600349\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.08986487014020664 TEST LOSS: 0.0664124860024376\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.09386124667885198 TEST LOSS: 0.06650667947235721\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.09252533932821168 TEST LOSS: 0.06723930351361052\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.09241429265914464 TEST LOSS: 0.06673251391887203\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.09369994355455906 TEST LOSS: 0.06672683257612792\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.09207026703542591 TEST LOSS: 0.06516434259168775\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.09428618986546454 TEST LOSS: 0.06348579771296861\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.09508986029990488 TEST LOSS: 0.06501495153524661\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.09200957672541063 TEST LOSS: 0.06664428296075582\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.09398805830565984 TEST LOSS: 0.06671268479505692\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.09700311101843842 TEST LOSS: 0.06658173229795256\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.0955010651224564 TEST LOSS: 0.06850234537269753\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.0946099545752225 TEST LOSS: 0.06282317599041372\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.0941491473850836 TEST LOSS: 0.06552085005870449\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.09736038926622674 TEST LOSS: 0.06571501297730331\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.09468686630207317 TEST LOSS: 0.06645010496501239\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.09593963759086815 TEST LOSS: 0.06522281327131413\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.09236746691933435 TEST LOSS: 0.06401713916242054\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.09370895308007567 TEST LOSS: 0.06235949189443719\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.09062734898320243 TEST LOSS: 0.06380441479035771\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000017817CF0630>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.19835239407900696 TEST LOSS: 0.2522771670951334\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.14408072065437388 TEST LOSS: 0.17720959346183743\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.10705588126205344 TEST LOSS: 0.1482961833832393\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.09621299866612101 TEST LOSS: 0.14064492238126358\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.09705400323950762 TEST LOSS: 0.13575238979213394\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.09362970671489165 TEST LOSS: 0.12669597454340173\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.09303890191594395 TEST LOSS: 0.12307357279769199\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.0899232914045621 TEST LOSS: 0.11878917851027608\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.08822421082930279 TEST LOSS: 0.11732335476679677\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.08849471218076671 TEST LOSS: 0.1179891798017933\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.08905506793570561 TEST LOSS: 0.11910462035535586\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.08560569109607684 TEST LOSS: 0.1168748152138046\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.08653832987973369 TEST LOSS: 0.11624239921041672\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.09094860934303407 TEST LOSS: 0.11684438366646621\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.08551705212347921 TEST LOSS: 0.12037808800964779\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.08516815663834088 TEST LOSS: 0.11344316017821618\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.08736590311611735 TEST LOSS: 0.11305400132002998\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.08578569485873057 TEST LOSS: 0.11600224226386259\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.08782190474091017 TEST LOSS: 0.11890352552511115\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.08869605723374091 TEST LOSS: 0.12298597660946574\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.08245000238967186 TEST LOSS: 0.11227159036094216\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.08357126378785996 TEST LOSS: 0.11581777019542593\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.0857500024229304 TEST LOSS: 0.115580025447736\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.08495138545616134 TEST LOSS: 0.11239001298790524\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.08732861981161552 TEST LOSS: 0.11209001192843533\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.08635996304838077 TEST LOSS: 0.11604163717081416\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.08362985892985436 TEST LOSS: 0.11271388830194193\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.08676643205462614 TEST LOSS: 0.11411060329392243\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.08381630492208555 TEST LOSS: 0.1114175258870848\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.08491874460501998 TEST LOSS: 0.11228874502515532\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.0866594867563573 TEST LOSS: 0.11528132967079079\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.08032682776544234 TEST LOSS: 0.1111700368216502\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.08368744950870223 TEST LOSS: 0.11395163522703063\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.0842528089789292 TEST LOSS: 0.11308912615365775\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.08520453856040591 TEST LOSS: 0.1171912004423309\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.08294558655598579 TEST LOSS: 0.11303530927241821\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.08230132475677304 TEST LOSS: 0.11103335156969596\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.08262652643556571 TEST LOSS: 0.11348023498946568\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.08240840274841557 TEST LOSS: 0.11392222173552176\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.08179123508614919 TEST LOSS: 0.11346712187309697\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.08339406243508073 TEST LOSS: 0.11263076057360143\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.08160222760750939 TEST LOSS: 0.11414533984550863\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.08095639475208467 TEST LOSS: 0.11577417831624609\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.08400672461350758 TEST LOSS: 0.11443864785976868\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.08046781816809204 TEST LOSS: 0.11723753960395422\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.08258870174927421 TEST LOSS: 0.11019587741567942\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.08341612359547212 TEST LOSS: 0.11146621607197833\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.08169864695751004 TEST LOSS: 0.11284521636378958\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.08091780677198444 TEST LOSS: 0.10974854703481908\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.08563188523463319 TEST LOSS: 0.11213491621361807\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.08353852864716341 TEST LOSS: 0.11546850927574684\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000017810E30B00>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.23976687948918524 TEST LOSS: 0.3054287174822431\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.17594909238812267 TEST LOSS: 0.20821207611096074\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.14227368674400373 TEST LOSS: 0.171001289808503\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.13045161427721438 TEST LOSS: 0.15663596904519742\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.11018203770290376 TEST LOSS: 0.14026379546724416\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.10219489228302216 TEST LOSS: 0.13652945249954923\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.09614449768507036 TEST LOSS: 0.12644288549621358\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.08936659719021992 TEST LOSS: 0.11976737091035103\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.09004871848767185 TEST LOSS: 0.12198321861512111\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.09100176522141051 TEST LOSS: 0.12142435303287916\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.0989166178217586 TEST LOSS: 0.12516826510498277\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.09530603980639435 TEST LOSS: 0.1213067185282256\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.09066386330118335 TEST LOSS: 0.1096957891590889\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.08709585145720682 TEST LOSS: 0.11075954059224788\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.09693110240470529 TEST LOSS: 0.12105425151793323\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.09183780697873203 TEST LOSS: 0.10682641797369356\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.08459250475520232 TEST LOSS: 0.10543324030068583\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.09133850679325786 TEST LOSS: 0.1163364443788491\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.0860520869361604 TEST LOSS: 0.11152125536178978\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.08257077146802859 TEST LOSS: 0.10605271102447905\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.09029629903188613 TEST LOSS: 0.11373586456615796\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.09640537668214884 TEST LOSS: 0.12123799171241864\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.08535247070124152 TEST LOSS: 0.10418887840126116\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.08836900636841451 TEST LOSS: 0.11086336728273122\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.09006190330863545 TEST LOSS: 0.11047307872030504\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.08613703498546306 TEST LOSS: 0.1015357977896969\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.08330491723516278 TEST LOSS: 0.10006067761255388\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.08493455356390993 TEST LOSS: 0.10534105244955655\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.08747837015408415 TEST LOSS: 0.11025579600904505\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.09014992875747659 TEST LOSS: 0.11029256316124304\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.08754155868387901 TEST LOSS: 0.10067971165125769\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.08510947418669829 TEST LOSS: 0.10463219339320663\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.08373153305381671 TEST LOSS: 0.10584996985394356\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.0811229523227471 TEST LOSS: 0.1036999241581344\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.08940567772294818 TEST LOSS: 0.11479797285377302\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.08475811825222822 TEST LOSS: 0.10209541939012622\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.07796438499809692 TEST LOSS: 0.09612432096261453\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.09154135856732447 TEST LOSS: 0.10817355059455659\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.08717492952666767 TEST LOSS: 0.1054433503346093\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.08356686119513218 TEST LOSS: 0.10253876229486235\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.08451612951596 TEST LOSS: 0.10720908379642173\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.0837403603582536 TEST LOSS: 0.10887086749792775\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.08417791349323127 TEST LOSS: 0.10414473629533127\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.08990505158701796 TEST LOSS: 0.10668853786062757\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.08440854899641376 TEST LOSS: 0.10233858021128182\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.0809988446706742 TEST LOSS: 0.10332647470970867\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.08219577317334262 TEST LOSS: 0.1044567245131298\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.08697066583250773 TEST LOSS: 0.10141190769809004\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.08044134072437842 TEST LOSS: 0.10000203606929131\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.0831905002205323 TEST LOSS: 0.10031093453242587\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.08650101092528523 TEST LOSS: 0.10970040584163558\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000017813651940>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.2266584345196913 TEST LOSS: 0.2774133524907333\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.16403756295537855 TEST LOSS: 0.19550220761348214\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.13305562744766722 TEST LOSS: 0.15788185168254495\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.11886563761112609 TEST LOSS: 0.14308056730328333\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.10736886097770296 TEST LOSS: 0.1370240740264428\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.09866894317862884 TEST LOSS: 0.12588262531667704\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.09145568277631731 TEST LOSS: 0.11727289296650135\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.08806022093672282 TEST LOSS: 0.11025396047377328\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.08268605053597301 TEST LOSS: 0.10296165333617271\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.09054537977224258 TEST LOSS: 0.12270868732413812\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.0784311422268199 TEST LOSS: 0.10005581546737413\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.08434385221933795 TEST LOSS: 0.11176761646145825\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.08430827126212066 TEST LOSS: 0.11596003548692639\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.08007071761366953 TEST LOSS: 0.1019546549439831\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.07635380805424391 TEST LOSS: 0.09538517827834624\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.07894781558596803 TEST LOSS: 0.10229052130618162\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.08011789236127255 TEST LOSS: 0.10312277837488718\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.07545767954360927 TEST LOSS: 0.09896785043587887\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.07570376324405027 TEST LOSS: 0.0985813918748118\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.07471667751380102 TEST LOSS: 0.10127870421253535\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.07136782601564126 TEST LOSS: 0.09736155053234323\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.07339391131596523 TEST LOSS: 0.10109318392068184\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.0755492636690507 TEST LOSS: 0.09132617483532779\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.07217075628350994 TEST LOSS: 0.0894786783465091\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.07385598120196453 TEST LOSS: 0.09904168803339669\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.07150904262883363 TEST LOSS: 0.09638552603967865\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.07288210586832053 TEST LOSS: 0.09900284150180394\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.07407758560475994 TEST LOSS: 0.08944122699393374\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.07298005631060968 TEST LOSS: 0.09593613244916793\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.07211569080987906 TEST LOSS: 0.09220200164411278\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.0700123095852724 TEST LOSS: 0.09049151504377136\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.07723845669919603 TEST LOSS: 0.10183907213431097\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.0720330763565923 TEST LOSS: 0.090143562207085\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.07172929519480825 TEST LOSS: 0.10117349436030203\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.07221213743984857 TEST LOSS: 0.0943298795741596\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.06948382784997505 TEST LOSS: 0.08882786208563016\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.07250574460075675 TEST LOSS: 0.09609113099851384\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.07122306399172812 TEST LOSS: 0.09300871103581132\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.07045484477429843 TEST LOSS: 0.09235998980952045\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.07050957985771532 TEST LOSS: 0.09378157377371249\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.07024333295567096 TEST LOSS: 0.09351256592784442\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.07079723358932219 TEST LOSS: 0.09470363276825755\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.07263555674351276 TEST LOSS: 0.09713245094458177\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.07071945299764912 TEST LOSS: 0.08493373159265528\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.07025896749249727 TEST LOSS: 0.09323492618227905\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.06888358374637481 TEST LOSS: 0.08684767196929678\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.07259125248049118 TEST LOSS: 0.09228222392094991\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.06886136183881764 TEST LOSS: 0.09090591963595977\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.07140591728256605 TEST LOSS: 0.09052633843970681\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.06967923162037952 TEST LOSS: 0.09448900156854219\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.06777572685143618 TEST LOSS: 0.08866941646881665\n",
      "0.06732709615978932 0.08833065201059069\n",
      "COMPUTING FOR ITERATION NUMBER 7\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x00000178121D1438>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.24684456950164838 TEST LOSS: 0.2522251324586575\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.15838751820071806 TEST LOSS: 0.15129789478813813\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.1376250753298472 TEST LOSS: 0.12634122033866113\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.12560057611035946 TEST LOSS: 0.11103444501878028\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.11043881986565166 TEST LOSS: 0.10156662635667296\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.10270617799138669 TEST LOSS: 0.08981015139354194\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.09509854696434314 TEST LOSS: 0.08523713490442666\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.09279493253817679 TEST LOSS: 0.08906774652397642\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.0891022974536159 TEST LOSS: 0.08470768823854195\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.09148831907389447 TEST LOSS: 0.08561148608912125\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.08817649891392877 TEST LOSS: 0.08004026630725572\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.08852049695106506 TEST LOSS: 0.08548218467076923\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.09089443450832088 TEST LOSS: 0.08257745005964973\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.08766678835825725 TEST LOSS: 0.08279249524286592\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.08077799910054895 TEST LOSS: 0.07917841756988689\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.0905210023875788 TEST LOSS: 0.08133480254573787\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.08562601572479962 TEST LOSS: 0.08091802131465496\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.08102587991972922 TEST LOSS: 0.07562733733756226\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.08653949821904773 TEST LOSS: 0.07924482803990704\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.08066752826955446 TEST LOSS: 0.07981700880549936\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.0857306678913188 TEST LOSS: 0.07723092196849109\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.08334020284141995 TEST LOSS: 0.07701080855086498\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.08502277926043043 TEST LOSS: 0.08032693326700911\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.08100140406744255 TEST LOSS: 0.07510464286718482\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.07785473254844993 TEST LOSS: 0.07530276256374492\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.08178471847005392 TEST LOSS: 0.07675331533393907\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.08027658049451128 TEST LOSS: 0.0733523795267479\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.08149360430444853 TEST LOSS: 0.07584642936781241\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.07726774206055717 TEST LOSS: 0.07456733771893503\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.08791418103265712 TEST LOSS: 0.07624355837083177\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.07902456217963492 TEST LOSS: 0.07729271908070538\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.08442206925020344 TEST LOSS: 0.07765017873955912\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.08391682701374616 TEST LOSS: 0.07680201002042113\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.08044194034353119 TEST LOSS: 0.0744207732434643\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.0783151618296935 TEST LOSS: 0.0756877130107287\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.08250854662777016 TEST LOSS: 0.07510827135711301\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.0843733681403661 TEST LOSS: 0.07576914710088557\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.08113174723939444 TEST LOSS: 0.07422272518466014\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.08393494016562288 TEST LOSS: 0.0746741791085357\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.08541152304519102 TEST LOSS: 0.07691723100953815\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.08621275110443495 TEST LOSS: 0.07456109486680447\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.08449779113495685 TEST LOSS: 0.07355573928558663\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.07986450234336165 TEST LOSS: 0.07789572393618696\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.0791992891086592 TEST LOSS: 0.07185234392449828\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.080754703441028 TEST LOSS: 0.07117920051588461\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.07903436352872216 TEST LOSS: 0.06913470283675499\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.08346609073995219 TEST LOSS: 0.07470555949438965\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.07883611095956211 TEST LOSS: 0.0743007906058097\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.07827114060063219 TEST LOSS: 0.07306925519329321\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.08177720556380308 TEST LOSS: 0.07360394277471634\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.07807397958084471 TEST LOSS: 0.07015194756723342\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x00000178117598D0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.2255765167419987 TEST LOSS: 0.21159291093451346\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.16881609744181955 TEST LOSS: 0.15496941669905812\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.14951383687238312 TEST LOSS: 0.13438522472854375\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.1340551066735833 TEST LOSS: 0.11382425839070316\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.12338471929839452 TEST LOSS: 0.1052444137268117\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.12286721955402082 TEST LOSS: 0.10528093966898855\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.11774417928903255 TEST LOSS: 0.0953098464696805\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.11628534069743482 TEST LOSS: 0.09092804510378057\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.1124657758077499 TEST LOSS: 0.09546363440012333\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.11558977081954673 TEST LOSS: 0.08851796562782932\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.11351295026547846 TEST LOSS: 0.07958545651579055\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.10650707730880907 TEST LOSS: 0.08657387086236448\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.11498097447845257 TEST LOSS: 0.08136426094799513\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.10475940150149192 TEST LOSS: 0.08029774106009038\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.10437088444760395 TEST LOSS: 0.08449856205640881\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.10648368199673947 TEST LOSS: 0.07983665679901839\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.10321870770112757 TEST LOSS: 0.0864197349521978\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.10795944710021185 TEST LOSS: 0.08118057307160019\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.10602336940764376 TEST LOSS: 0.08152326572775526\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.10983897676509005 TEST LOSS: 0.0854975450310867\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.1017525862413746 TEST LOSS: 0.07777183212619743\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.10805386911840237 TEST LOSS: 0.08672320233420586\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.10467959620463249 TEST LOSS: 0.08012137270288733\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.09489859476582525 TEST LOSS: 0.08887230087500642\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.10114576875918621 TEST LOSS: 0.07994605193715422\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.10194941146482091 TEST LOSS: 0.09217185299765124\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.09540133678414779 TEST LOSS: 0.07814123825239992\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.08646130727861065 TEST LOSS: 0.07533277739185591\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.0938952132214804 TEST LOSS: 0.07805065050151666\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.10206866741719645 TEST LOSS: 0.07886181216129952\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.08807899863457207 TEST LOSS: 0.077521160300008\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.09575911954508527 TEST LOSS: 0.0786605799987731\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.09716082952378285 TEST LOSS: 0.08249500054992201\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.08324415420886962 TEST LOSS: 0.07990789981497402\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.09444788583658169 TEST LOSS: 0.07932274044550383\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.08976222209086152 TEST LOSS: 0.08649800364356082\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.08789733051047957 TEST LOSS: 0.07901133179254112\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.09410052924179052 TEST LOSS: 0.08588655282158918\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.09145586664860152 TEST LOSS: 0.08377417270689431\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.08994177864922072 TEST LOSS: 0.07891421873735292\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.09632904516091075 TEST LOSS: 0.07947751556097793\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.08934204250160675 TEST LOSS: 0.07733335884183674\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.08326934133760008 TEST LOSS: 0.08214876015042379\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.0899911156972228 TEST LOSS: 0.07551427395552783\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.09361797153820857 TEST LOSS: 0.0752937633311143\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.08958725926461923 TEST LOSS: 0.07333354228629721\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.08597527075253382 TEST LOSS: 0.07961570359154506\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.08114060997914714 TEST LOSS: 0.07633142196166946\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.08999937895863498 TEST LOSS: 0.07649438804183417\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.08676790876025732 TEST LOSS: 0.07751912026168684\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.08479557662583703 TEST LOSS: 0.07817246465334804\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x00000178121D1FD0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.2807074955684864 TEST LOSS: 0.2553254722440786\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.17951282037184613 TEST LOSS: 0.16109729008901155\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.14663177658558543 TEST LOSS: 0.135545424604576\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.13288539897999108 TEST LOSS: 0.12270477414684186\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.11911777535000816 TEST LOSS: 0.10816000449154638\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.11487572781856235 TEST LOSS: 0.1114529130009191\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.11251576438001953 TEST LOSS: 0.10531235930896096\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.10981627294279946 TEST LOSS: 0.10188870756236658\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.10270224694451793 TEST LOSS: 0.09894538781058222\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.1034731066631867 TEST LOSS: 0.09452601283322867\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.10135506078355883 TEST LOSS: 0.09913033712168148\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.10320377530729907 TEST LOSS: 0.0990059407333742\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.09800167553169459 TEST LOSS: 0.0954854866443866\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.10566589236075606 TEST LOSS: 0.1019905900543517\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.09985672428545725 TEST LOSS: 0.09629646689531465\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.10849809092372843 TEST LOSS: 0.09696824145978365\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.09561929056632582 TEST LOSS: 0.09164150825018794\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.09297103617463795 TEST LOSS: 0.09821436123187349\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.09473384390184673 TEST LOSS: 0.09022141094674511\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.09476270522612573 TEST LOSS: 0.09747313750018854\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.09334074929115664 TEST LOSS: 0.08871382078493784\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.09141338558998031 TEST LOSS: 0.09194933003381835\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.09696778033943455 TEST LOSS: 0.09300959934355779\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.0941755245201929 TEST LOSS: 0.09779491238395763\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.09210952011931225 TEST LOSS: 0.0938356998310099\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.09203665060407938 TEST LOSS: 0.09435689401552365\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.09485780318925635 TEST LOSS: 0.0936357071131842\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.09954944710569583 TEST LOSS: 0.094797792098872\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.09576558993331694 TEST LOSS: 0.09385990787818804\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.09703753113373184 TEST LOSS: 0.09349220994984132\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.09896640578885654 TEST LOSS: 0.0928713310504988\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.09739963511007232 TEST LOSS: 0.09490577597634405\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.09631809314382178 TEST LOSS: 0.0941701720297531\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.1003406657417601 TEST LOSS: 0.09270885527363407\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.10141220415954974 TEST LOSS: 0.09444844675942589\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.09405684225142706 TEST LOSS: 0.09083337821897822\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.10467686640328572 TEST LOSS: 0.09007595216383371\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.09859141838551617 TEST LOSS: 0.09116950976318244\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.10124104106566445 TEST LOSS: 0.09058417945131286\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.09828618251554352 TEST LOSS: 0.09305526404238666\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.1073303443937299 TEST LOSS: 0.09626655992329099\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.10031733667251908 TEST LOSS: 0.0941428305395391\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.09924427959683277 TEST LOSS: 0.09134388482777055\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.09591274622266358 TEST LOSS: 0.0941015356649536\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.0913898383612541 TEST LOSS: 0.08990799706425474\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.09897306354175385 TEST LOSS: 0.09094930355264211\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.09049659641376817 TEST LOSS: 0.09087569274284815\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.0918497000052669 TEST LOSS: 0.08598032232834966\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.09628972801351116 TEST LOSS: 0.09030361977555304\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.09297279427922138 TEST LOSS: 0.08705184401831004\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.09900165220889162 TEST LOSS: 0.09131312619353822\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000017817B742E8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.26016734831825655 TEST LOSS: 0.27584510287853253\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.17377589488052836 TEST LOSS: 0.1619267728411309\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.155191114594156 TEST LOSS: 0.14108800124462959\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.13280958565636947 TEST LOSS: 0.13115343738339524\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.1275801676739393 TEST LOSS: 0.12629056702851818\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.12284527466669437 TEST LOSS: 0.1275326145733847\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.11766806747316474 TEST LOSS: 0.1198654340743036\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.11530917078592869 TEST LOSS: 0.11991352150726026\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.1161716177801878 TEST LOSS: 0.12524467793318295\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.11548770061994953 TEST LOSS: 0.12120357377361235\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.10932351081368473 TEST LOSS: 0.11767499099145057\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.1167615586922206 TEST LOSS: 0.11855376640217229\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.10530368157320455 TEST LOSS: 0.12190867230549492\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.11809691746215686 TEST LOSS: 0.12218494241586678\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.12048741785517347 TEST LOSS: 0.12151949002374123\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.10911447360611327 TEST LOSS: 0.12517728782283497\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.10603729093690294 TEST LOSS: 0.12177784588895964\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.10912760111773495 TEST LOSS: 0.11999083041745184\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.10825427105909145 TEST LOSS: 0.11833278647102459\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.11242414884886938 TEST LOSS: 0.11468869464810671\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.10869577282770032 TEST LOSS: 0.11435117039330722\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.10788118223975537 TEST LOSS: 0.11408250425272297\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.11219007144420133 TEST LOSS: 0.1153588497322108\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.11448080117642084 TEST LOSS: 0.11311017479155529\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.11181375240742762 TEST LOSS: 0.11604223727205591\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.1044509278139166 TEST LOSS: 0.12214991430365742\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.10994427123740425 TEST LOSS: 0.11849082500576417\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.10431493345956921 TEST LOSS: 0.1164902457467497\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.10957714526413886 TEST LOSS: 0.11441141084941372\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.10283502213537488 TEST LOSS: 0.111374095020601\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.10367924786737459 TEST LOSS: 0.11878476560037189\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.10985984351135392 TEST LOSS: 0.11565650298404546\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.11274787757637954 TEST LOSS: 0.11352978273846799\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.10569475818514337 TEST LOSS: 0.11484922254294566\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.10562973132974825 TEST LOSS: 0.11164104741960436\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.10286910446676531 TEST LOSS: 0.11323051387483081\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.10415498094085425 TEST LOSS: 0.11556636864003278\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.1069392979675813 TEST LOSS: 0.10976987448263889\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.10725182757095057 TEST LOSS: 0.11054746432979155\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.10830181163311355 TEST LOSS: 0.11326842103589273\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.10575415953772904 TEST LOSS: 0.11238707487497994\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.10745657407661892 TEST LOSS: 0.11475172726754886\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.10715322527121605 TEST LOSS: 0.11162791165925177\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.10489759084050691 TEST LOSS: 0.11035555215924867\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.10675091326311056 TEST LOSS: 0.11496833042488643\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.10881253738056701 TEST LOSS: 0.11390210874670642\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.10402730199806066 TEST LOSS: 0.11296811311124125\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.10227396590720288 TEST LOSS: 0.11527301271704829\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.10602695252501249 TEST LOSS: 0.11262678153171714\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.1057302558089888 TEST LOSS: 0.1141808512167508\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.10970988267930204 TEST LOSS: 0.11386275977435267\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000017813760198>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.20476119355704253 TEST LOSS: 0.27947154852717465\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.14707841620902895 TEST LOSS: 0.1873469958838151\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.12096524236995312 TEST LOSS: 0.16931804089271318\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.10925140868340372 TEST LOSS: 0.14973171946163963\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.09808003498688232 TEST LOSS: 0.10609203939263159\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.09736158023589515 TEST LOSS: 0.11685558081709004\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.09522855903106406 TEST LOSS: 0.0864399203645144\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.09351058306299127 TEST LOSS: 0.1062432506639818\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.09475115720490584 TEST LOSS: 0.09487233141186756\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.09365762081057012 TEST LOSS: 0.09286446074918034\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.09214683388421213 TEST LOSS: 0.09586808237671417\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.09248027472892778 TEST LOSS: 0.10936818193283593\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.09148563457946833 TEST LOSS: 0.10444671284786068\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.08935795717496857 TEST LOSS: 0.08791348946423194\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.08914206032421704 TEST LOSS: 0.09408945872327061\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.08760192099833788 TEST LOSS: 0.08677203569532792\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.09059862111362216 TEST LOSS: 0.10770913036779302\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.08594557226241484 TEST LOSS: 0.09511623427531092\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.08619013480393219 TEST LOSS: 0.10086030346549497\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.08732530306817675 TEST LOSS: 0.0932269096663918\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.08572050402427928 TEST LOSS: 0.10223293797169988\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.08362543658739885 TEST LOSS: 0.08618254488715461\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.08559975976566404 TEST LOSS: 0.08543945748037443\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.08356330133306318 TEST LOSS: 0.09929807285882286\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.0812990346886325 TEST LOSS: 0.09418667169880848\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.08434439727919298 TEST LOSS: 0.09829116846026265\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.0814451203815105 TEST LOSS: 0.08930496345086143\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.08408678014814948 TEST LOSS: 0.09604221158646505\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.08402587184068873 TEST LOSS: 0.09366718478337784\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.0838966647534975 TEST LOSS: 0.08987274951173731\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.08366253303689125 TEST LOSS: 0.09758529817937238\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.08156274739540839 TEST LOSS: 0.0829075578805688\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.08676441466053623 TEST LOSS: 0.08183271334971957\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.08486650500387857 TEST LOSS: 0.0892707790341312\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.08337967797264961 TEST LOSS: 0.0852491792343827\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.08335258443802543 TEST LOSS: 0.09932504853500425\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.07913242334612669 TEST LOSS: 0.08711956326388469\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.0824201081355063 TEST LOSS: 0.08906630473463838\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.08216157912722298 TEST LOSS: 0.08814851129801302\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.0833627189135504 TEST LOSS: 0.07892737158468313\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.08536917194087994 TEST LOSS: 0.09258420706466511\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.07947662092061246 TEST LOSS: 0.08309202407533041\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.08160981394096693 TEST LOSS: 0.09363866858629549\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.0839963056585171 TEST LOSS: 0.0855604388431401\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.07891811191259986 TEST LOSS: 0.08956643133858365\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.08118402116329523 TEST LOSS: 0.0860423446298733\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.07822798861876969 TEST LOSS: 0.0855290252389539\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.07714806360609143 TEST LOSS: 0.09460201543736882\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.0803579264782409 TEST LOSS: 0.09265985352933953\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.07920428046842866 TEST LOSS: 0.08784024016978756\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.07705968691095981 TEST LOSS: 0.08944641035868109\n",
      "0.07714806360609143 0.08907944481554486\n",
      "COMPUTING FOR ITERATION NUMBER 8\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000017810C53278>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.2544562393475379 TEST LOSS: 0.22001843367472837\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.1633613727186163 TEST LOSS: 0.15150890035307724\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.13953947728487015 TEST LOSS: 0.128030614740909\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.11644969538166404 TEST LOSS: 0.11086009456191168\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.11124756662465625 TEST LOSS: 0.0985274199942938\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.09976596555747039 TEST LOSS: 0.09306992869777457\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.09762398708865104 TEST LOSS: 0.08863649875922806\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.10153546389575747 TEST LOSS: 0.0895346316034798\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.09767604862365778 TEST LOSS: 0.08389566632587814\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.09325097293229796 TEST LOSS: 0.08235934364255951\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.09451041858164473 TEST LOSS: 0.0823259138015516\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.09595002560527453 TEST LOSS: 0.07998321562378106\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.09437768089339389 TEST LOSS: 0.07891937428842417\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.09327511233166917 TEST LOSS: 0.07828713577094282\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.1015830965932639 TEST LOSS: 0.08091664364483535\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.09328302552198324 TEST LOSS: 0.07817099300578861\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.0940280172071119 TEST LOSS: 0.07647671895808235\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.09177479205344313 TEST LOSS: 0.07779599803993603\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.09187905187526275 TEST LOSS: 0.07431056923304978\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.09335881822454967 TEST LOSS: 0.0749963638068074\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.0904651585199391 TEST LOSS: 0.07872341314015281\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.09249825506792386 TEST LOSS: 0.07893799891293418\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.09085388628148972 TEST LOSS: 0.07775021674770813\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.09173431669005062 TEST LOSS: 0.07647422948385531\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.09039078838258911 TEST LOSS: 0.07573911562429296\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.09004444860494139 TEST LOSS: 0.07813067763899653\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.08927379438530904 TEST LOSS: 0.07601404167051402\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.09138020918909735 TEST LOSS: 0.07510799740745182\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.09108796291051698 TEST LOSS: 0.07679693088254265\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.09330774707641565 TEST LOSS: 0.07657010690577247\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.08860257321493058 TEST LOSS: 0.0745717977531809\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.09107836117346485 TEST LOSS: 0.07616801432300495\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.08812798289707839 TEST LOSS: 0.07587543754982133\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.09196917947668679 TEST LOSS: 0.07533469271388889\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.09101552350460528 TEST LOSS: 0.07472176135521423\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.08661542383981966 TEST LOSS: 0.07626996971898692\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.08785498472483214 TEST LOSS: 0.07581464324444392\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.09083708258564031 TEST LOSS: 0.07408715151604299\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.09001158759671592 TEST LOSS: 0.07615088892545602\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.09170262207262841 TEST LOSS: 0.07709027255592496\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.09098007149534883 TEST LOSS: 0.07529035024703212\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.09035929309151226 TEST LOSS: 0.07254932681926567\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.09152903787764514 TEST LOSS: 0.07574322821813878\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.09153485659370507 TEST LOSS: 0.07279711516446101\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.08865842415216023 TEST LOSS: 0.07446482830467042\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.08734745155417036 TEST LOSS: 0.07551860276212684\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.08973544840420793 TEST LOSS: 0.07463405459427731\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.09078211095149594 TEST LOSS: 0.07584860957587232\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.08872994898033847 TEST LOSS: 0.07394181328504032\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.09026692886620978 TEST LOSS: 0.07484365995849039\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.08837921088640312 TEST LOSS: 0.07069398470013422\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000017817FD9668>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.28214565034684475 TEST LOSS: 0.23987846378739477\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.1749377652897278 TEST LOSS: 0.16323985327113846\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.12820463171925162 TEST LOSS: 0.1271172778526615\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.11290813942078956 TEST LOSS: 0.11984464251559292\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.1143956355252457 TEST LOSS: 0.12344173269288054\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.1050106374264026 TEST LOSS: 0.11641971608309629\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.09636922374708547 TEST LOSS: 0.1093894743401697\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.08228748069332481 TEST LOSS: 0.09341658670744553\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.10158233349850232 TEST LOSS: 0.10360000836934402\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.08606751849655786 TEST LOSS: 0.09518542612261462\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.0843294074333501 TEST LOSS: 0.08828028186382429\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.08528019139618719 TEST LOSS: 0.0767358311492386\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.09668747696870636 TEST LOSS: 0.08920528743214849\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.0910098586206178 TEST LOSS: 0.09188720709497607\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.09308952605149337 TEST LOSS: 0.0947391981203902\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.09941934370978577 TEST LOSS: 0.09069548880429316\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.08143629769886183 TEST LOSS: 0.07151310308108842\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.0931953960182589 TEST LOSS: 0.08839989172055564\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.09534606946345973 TEST LOSS: 0.08410036221104442\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.08128208202509585 TEST LOSS: 0.08579106108279265\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.0774511691299325 TEST LOSS: 0.07834840674251022\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.08225740698296317 TEST LOSS: 0.08090367169967308\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.07888113511784423 TEST LOSS: 0.08072150707452619\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.08505730713476606 TEST LOSS: 0.07895746760715636\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.08152674690549871 TEST LOSS: 0.080755525582152\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.07757893583339888 TEST LOSS: 0.07601492092689806\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.07739497813937968 TEST LOSS: 0.07233867884710549\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.08756190892171273 TEST LOSS: 0.08721708563488292\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.08250431059052393 TEST LOSS: 0.0817751400641611\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.07790548530458379 TEST LOSS: 0.07847745043347563\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.08212348773733294 TEST LOSS: 0.07764937399559628\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.07513877505547287 TEST LOSS: 0.0818325027447291\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.08455608828829261 TEST LOSS: 0.08173689459206131\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.07401508987891606 TEST LOSS: 0.07382457656911615\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.08093024256192898 TEST LOSS: 0.08589188387508144\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.08872163506715437 TEST LOSS: 0.08167781726759785\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.08273789710040588 TEST LOSS: 0.08261949262687623\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.0797963819354254 TEST LOSS: 0.07885944153254701\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.08349610398137718 TEST LOSS: 0.08651249993647162\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.07769563971546309 TEST LOSS: 0.07845833222095341\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.07365036237195569 TEST LOSS: 0.08102822023025641\n",
      "EPOCH 410\n",
      "VAL LOSS: 0.07797898120782815 TEST LOSS: 0.07568500558177582\n",
      "EPOCH 420\n",
      "VAL LOSS: 0.08327381026258032 TEST LOSS: 0.08483827264683\n",
      "EPOCH 430\n",
      "VAL LOSS: 0.07367345356263148 TEST LOSS: 0.07867276813820709\n",
      "EPOCH 440\n",
      "VAL LOSS: 0.08058240055438728 TEST LOSS: 0.0811712573869471\n",
      "EPOCH 450\n",
      "VAL LOSS: 0.074762218169311 TEST LOSS: 0.08437691854050797\n",
      "EPOCH 460\n",
      "VAL LOSS: 0.07543229854257531 TEST LOSS: 0.07790253307061328\n",
      "EPOCH 470\n",
      "VAL LOSS: 0.07432800296675492 TEST LOSS: 0.07650745392301583\n",
      "EPOCH 480\n",
      "VAL LOSS: 0.07305969445828846 TEST LOSS: 0.07419121191351033\n",
      "EPOCH 490\n",
      "VAL LOSS: 0.08006008185258792 TEST LOSS: 0.0906180446258086\n",
      "EPOCH 500\n",
      "VAL LOSS: 0.07290402519536265 TEST LOSS: 0.07984112213982482\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x0000017810EA8C18>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "EPOCH 1\n",
      "VAL LOSS: 0.2467513796698023 TEST LOSS: 0.24216503673116802\n",
      "EPOCH 10\n",
      "VAL LOSS: 0.1550102441056109 TEST LOSS: 0.17639866516351346\n",
      "EPOCH 20\n",
      "VAL LOSS: 0.11552972634626679 TEST LOSS: 0.13529106458629314\n",
      "EPOCH 30\n",
      "VAL LOSS: 0.09516236954226207 TEST LOSS: 0.1130830144059785\n",
      "EPOCH 40\n",
      "VAL LOSS: 0.0921826997294586 TEST LOSS: 0.10127802797240097\n",
      "EPOCH 50\n",
      "VAL LOSS: 0.09108335369056567 TEST LOSS: 0.10259683488884164\n",
      "EPOCH 60\n",
      "VAL LOSS: 0.07985278792720918 TEST LOSS: 0.09465625150295963\n",
      "EPOCH 70\n",
      "VAL LOSS: 0.07704094097709796 TEST LOSS: 0.09360147564483294\n",
      "EPOCH 80\n",
      "VAL LOSS: 0.07810153790374215 TEST LOSS: 0.09350677231495777\n",
      "EPOCH 90\n",
      "VAL LOSS: 0.07977014931500684 TEST LOSS: 0.09358043779808743\n",
      "EPOCH 100\n",
      "VAL LOSS: 0.07657683349287836 TEST LOSS: 0.08740649777549404\n",
      "EPOCH 110\n",
      "VAL LOSS: 0.07979497775605779 TEST LOSS: 0.09064348171459385\n",
      "EPOCH 120\n",
      "VAL LOSS: 0.0765035562115697 TEST LOSS: 0.08643428331599404\n",
      "EPOCH 130\n",
      "VAL LOSS: 0.07269887855100887 TEST LOSS: 0.08924334105393908\n",
      "EPOCH 140\n",
      "VAL LOSS: 0.07050796520102676 TEST LOSS: 0.08716018270349854\n",
      "EPOCH 150\n",
      "VAL LOSS: 0.07183004448095413 TEST LOSS: 0.08689076297926744\n",
      "EPOCH 160\n",
      "VAL LOSS: 0.07271440185958805 TEST LOSS: 0.09442355209957444\n",
      "EPOCH 170\n",
      "VAL LOSS: 0.07305676289893494 TEST LOSS: 0.0913353734765809\n",
      "EPOCH 180\n",
      "VAL LOSS: 0.0692074768160771 TEST LOSS: 0.08595721929305512\n",
      "EPOCH 190\n",
      "VAL LOSS: 0.07021952308483659 TEST LOSS: 0.08702057307924685\n",
      "EPOCH 200\n",
      "VAL LOSS: 0.07075724991435951 TEST LOSS: 0.08971368140846027\n",
      "EPOCH 210\n",
      "VAL LOSS: 0.06691482973051058 TEST LOSS: 0.08349571265238204\n",
      "EPOCH 220\n",
      "VAL LOSS: 0.07021897216068619 TEST LOSS: 0.08601395083138647\n",
      "EPOCH 230\n",
      "VAL LOSS: 0.06826479231977749 TEST LOSS: 0.08603150870209161\n",
      "EPOCH 240\n",
      "VAL LOSS: 0.0678149558337183 TEST LOSS: 0.08791131319633222\n",
      "EPOCH 250\n",
      "VAL LOSS: 0.0738705966085014 TEST LOSS: 0.09011245445554147\n",
      "EPOCH 260\n",
      "VAL LOSS: 0.06799700166689517 TEST LOSS: 0.08553274165955337\n",
      "EPOCH 270\n",
      "VAL LOSS: 0.06897109987978871 TEST LOSS: 0.08261406809910968\n",
      "EPOCH 280\n",
      "VAL LOSS: 0.06733615717873095 TEST LOSS: 0.08363048395691097\n",
      "EPOCH 290\n",
      "VAL LOSS: 0.06731528758129952 TEST LOSS: 0.08215310555893646\n",
      "EPOCH 300\n",
      "VAL LOSS: 0.06926274853472321 TEST LOSS: 0.08969885679573886\n",
      "EPOCH 310\n",
      "VAL LOSS: 0.07215784194178353 TEST LOSS: 0.08282080182185828\n",
      "EPOCH 320\n",
      "VAL LOSS: 0.06776931889847662 TEST LOSS: 0.0825461971399898\n",
      "EPOCH 330\n",
      "VAL LOSS: 0.06907924020645888 TEST LOSS: 0.0884010189194656\n",
      "EPOCH 340\n",
      "VAL LOSS: 0.06797790263875006 TEST LOSS: 0.08716947818945463\n",
      "EPOCH 350\n",
      "VAL LOSS: 0.06810350631976281 TEST LOSS: 0.08602571159993314\n",
      "EPOCH 360\n",
      "VAL LOSS: 0.06946310115833941 TEST LOSS: 0.08081594596597023\n",
      "EPOCH 370\n",
      "VAL LOSS: 0.06837500519861592 TEST LOSS: 0.08161915887965729\n",
      "EPOCH 380\n",
      "VAL LOSS: 0.06943803423071847 TEST LOSS: 0.08407393187603844\n",
      "EPOCH 390\n",
      "VAL LOSS: 0.07030012570100043 TEST LOSS: 0.08403539379698646\n",
      "EPOCH 400\n",
      "VAL LOSS: 0.06968698460420468 TEST LOSS: 0.08810736791506016\n"
     ]
    }
   ],
   "source": [
    "# FOR NO MOMENTS WITH DIFFERENT PROCESSORS\n",
    "\n",
    "iteration_number = 10\n",
    "random_seed_list = list(range(iteration_number))\n",
    "processor_steps_list = [4]\n",
    "final_val_loss, final_test_loss = [], []\n",
    "\n",
    "for num_processor_steps in processor_steps_list:\n",
    "    print(\"COMPUTING FOR \" + str(num_processor_steps) + \" PROCESSING STEPS\")\n",
    "    validation_loss_list, test_loss_list = [], []\n",
    "    for index in range(iteration_number):\n",
    "        print('COMPUTING FOR ITERATION NUMBER ' + str(index+1))\n",
    "        lowest_val_loss, loss_test_list = inference_attention(random_seed_list[index], num_processor_steps, 5, False, 1, False)\n",
    "        validation_loss_list.append(np.mean(lowest_val_loss))\n",
    "        test_loss_list.append(np.mean(loss_test_list))\n",
    "        print(np.mean(lowest_val_loss), np.mean(loss_test_list))\n",
    "        \n",
    "    final_val_loss.append(np.mean(validation_loss_list))\n",
    "    final_test_loss.append(np.mean(test_loss_list)) \n",
    "    print(np.mean(validation_loss_list), np.mean(test_loss_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(tf.trainable_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 64)\n",
      "2\n",
      "12\n",
      "64\n",
      "768\n",
      "(65, 256)\n",
      "2\n",
      "65\n",
      "256\n",
      "16640\n",
      "(256,)\n",
      "1\n",
      "256\n",
      "256\n",
      "(128, 64)\n",
      "2\n",
      "128\n",
      "64\n",
      "8192\n",
      "(128, 1)\n",
      "2\n",
      "128\n",
      "1\n",
      "128\n",
      "25984\n"
     ]
    }
   ],
   "source": [
    "# total_parameters = 0\n",
    "# for variable in tf.trainable_variables():\n",
    "#     # shape is an array of tf.Dimension\n",
    "#     shape = variable.get_shape()\n",
    "#     print(shape)\n",
    "#     print(len(shape))\n",
    "#     variable_parameters = 1\n",
    "#     for dim in shape:\n",
    "#         print(dim)\n",
    "#         variable_parameters *= dim.value\n",
    "#     print(variable_parameters)\n",
    "#     total_parameters += variable_parameters\n",
    "# print(total_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Aggregated-MIR (with moments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aggregated_method_moments(n_moments=1):\n",
    "    \n",
    "    random_seed_list = list(range(10))\n",
    "    final_data, labels = moments_df(n_moments)\n",
    "    \n",
    "    final_loss_train, final_loss_test = [], []\n",
    "    count = 1\n",
    "\n",
    "    for index in range(10):    \n",
    "\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=random_seed_list[index])\n",
    "        list_loss_train, list_loss_test = [], []\n",
    "        for train_index, test_index in kf.split(range(labels.shape[0])):\n",
    "            train_x, test_x = final_data.iloc[train_index,:], final_data.iloc[test_index,:]\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(train_x)\n",
    "            train_x, test_x = scaler.transform(train_x), scaler.transform(test_x)\n",
    "\n",
    "            train_y, test_y = labels.iloc[train_index,:], labels.iloc[test_index,:]\n",
    "\n",
    "            rbf_svr = MLPRegressor(hidden_layer_sizes=(256, ), learning_rate_init=0.001, \n",
    "                                   max_iter=300, alpha=0.5)\n",
    "            \n",
    "            rbf_svr.fit(train_x, train_y)\n",
    "            train_pred = rbf_svr.predict(train_x)\n",
    "            test_pred = rbf_svr.predict(test_x)\n",
    "\n",
    "            training_loss = np.sqrt(mean_squared_error(np.reshape(np.array(train_pred),(len(train_pred),1)), np.reshape(np.array(train_y), (len(train_pred),1))))\n",
    "            testing_loss = np.sqrt(mean_squared_error(np.reshape(np.array(test_pred),(len(test_pred),1)), np.reshape(np.array(test_y), (len(test_pred),1))))\n",
    "\n",
    "            list_loss_train.append(training_loss)\n",
    "            list_loss_test.append(testing_loss)\n",
    "\n",
    "        final_loss_train.append(np.mean(list_loss_train))\n",
    "        final_loss_test.append(np.mean(list_loss_test))\n",
    "        print('Iteration number ' + str(count) + ' is done')\n",
    "        count += 1\n",
    "\n",
    "    print('The training loss is ' + str(np.mean(final_loss_train)))\n",
    "    print('The test loss is ' + str(np.mean(final_loss_test)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 1 is done\n",
      "Iteration number 2 is done\n",
      "Iteration number 3 is done\n",
      "Iteration number 4 is done\n",
      "Iteration number 5 is done\n",
      "Iteration number 6 is done\n",
      "Iteration number 7 is done\n",
      "Iteration number 8 is done\n",
      "Iteration number 9 is done\n",
      "Iteration number 10 is done\n",
      "The training loss is 0.11241429922087909\n",
      "The test loss is 0.12241815508728324\n"
     ]
    }
   ],
   "source": [
    "aggregated_method_moments(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Instance-MIR (with moments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def instance_method(use_moments=False, n_moments=1):\n",
    "\n",
    "    full_data = load_data()\n",
    "    random_seed_list = list(range(10))\n",
    "    \n",
    "    if use_moments:\n",
    "        df, _ = moments_df(n_moments)\n",
    "        col_solar = ['solar_0', 'solar_1', 'solar_2', 'solar_3']\n",
    "        df = df.iloc[np.repeat(np.arange(len(df)), 100)]\n",
    "        df = df[[col for col in df.columns if col not in col_solar]]\n",
    "        df = df.reset_index(drop=True)\n",
    "        full_data = full_data.reset_index(drop=True)\n",
    "        full_data = pd.concat([df, full_data], axis=1)\n",
    "\n",
    "    final_loss_train, final_loss_test = [], []\n",
    "    count = 1\n",
    "    for index in range(10):\n",
    "\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=random_seed_list[index])\n",
    "        cols_exclude = [\"id\", \"label\"]\n",
    "        features = [col for col in list(full_data.columns) if col not in cols_exclude]\n",
    "        list_loss_train, list_loss_test = [], []\n",
    "\n",
    "        for train_index, test_index in kf.split(list(full_data['id'].unique())):\n",
    "            train_index, test_index = np.array(full_data['id'].unique())[list(train_index)], np.array(full_data['id'].unique())[list(test_index)]\n",
    "            train = full_data[full_data['id'].apply(lambda value: value in train_index)]\n",
    "            test = full_data[full_data['id'].apply(lambda value: value in test_index)]\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(train[features])\n",
    "            train[features], test[features] = scaler.transform(train[features]), scaler.transform(test[features])\n",
    "\n",
    "            train_x, train_y = train[features], train['label']\n",
    "            test_x, test_y = test[features], test['label']\n",
    "\n",
    "            rbf_svr = MLPRegressor(hidden_layer_sizes=(256,), learning_rate_init=0.001, max_iter=200, alpha=0.5)\n",
    "            rbf_svr.fit(train_x, train_y)\n",
    "            train_pred = rbf_svr.predict(train_x)\n",
    "            test_pred = rbf_svr.predict(test_x)\n",
    "\n",
    "            df_train_pred = pd.DataFrame(np.concatenate([np.reshape(train_pred, (train_pred.shape[0],1)), \n",
    "                        np.reshape(train['id'].values, (train_pred.shape[0],1))], axis=1))\n",
    "\n",
    "            df_test_pred = pd.DataFrame(np.concatenate([np.reshape(test_pred, (test_pred.shape[0],1)), \n",
    "                        np.reshape(test['id'].values, (test_pred.shape[0],1))], axis=1))\n",
    "\n",
    "            true_train_y, true_test_y = train.groupby(['id']).mean()['label'].values, test.groupby(['id']).mean()['label'].values\n",
    "            train_mean_pred = df_train_pred.groupby(1).mean().values\n",
    "            test_mean_pred = df_test_pred.groupby(1).mean().values\n",
    "\n",
    "            training_loss = np.sqrt(mean_squared_error(np.reshape(train_mean_pred,(train_mean_pred.shape[0],1)), \n",
    "                                                       np.reshape(true_train_y, (train_mean_pred.shape[0],1))))\n",
    "\n",
    "            testing_loss = np.sqrt(mean_squared_error(np.reshape(test_mean_pred,(test_mean_pred.shape[0],1)), \n",
    "                                                      np.reshape(true_test_y, (test_mean_pred.shape[0],1))))\n",
    "\n",
    "            list_loss_train.append(training_loss)\n",
    "            list_loss_test.append(testing_loss)\n",
    "            \n",
    "        final_loss_train.append(np.mean(list_loss_train))\n",
    "        final_loss_test.append(np.mean(list_loss_test))\n",
    "        print('Iteration number ' + str(count) + ' is done')\n",
    "        count += 1\n",
    "\n",
    "    print('The training loss is ' + str(np.mean(final_loss_train)))\n",
    "    print('The test loss is ' + str(np.mean(final_loss_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 1 is done\n",
      "Iteration number 2 is done\n",
      "Iteration number 3 is done\n",
      "Iteration number 4 is done\n",
      "Iteration number 5 is done\n",
      "Iteration number 6 is done\n",
      "Iteration number 7 is done\n",
      "Iteration number 8 is done\n",
      "Iteration number 9 is done\n",
      "Iteration number 10 is done\n",
      "The training loss is 0.10745618025577611\n",
      "The test loss is 0.11639862968962338\n",
      "Iteration number 1 is done\n",
      "Iteration number 2 is done\n",
      "Iteration number 3 is done\n",
      "Iteration number 4 is done\n",
      "Iteration number 5 is done\n",
      "Iteration number 6 is done\n",
      "Iteration number 7 is done\n",
      "Iteration number 8 is done\n",
      "Iteration number 9 is done\n",
      "Iteration number 10 is done\n",
      "The training loss is 0.08688767765096075\n",
      "The test loss is 0.09981807489559483\n",
      "Iteration number 1 is done\n",
      "Iteration number 2 is done\n",
      "Iteration number 3 is done\n",
      "Iteration number 4 is done\n",
      "Iteration number 5 is done\n",
      "Iteration number 6 is done\n",
      "Iteration number 7 is done\n",
      "Iteration number 8 is done\n",
      "Iteration number 9 is done\n",
      "Iteration number 10 is done\n",
      "The training loss is 0.08072287275910187\n",
      "The test loss is 0.0981182145844817\n",
      "Iteration number 1 is done\n",
      "Iteration number 2 is done\n",
      "Iteration number 3 is done\n",
      "Iteration number 4 is done\n",
      "Iteration number 5 is done\n",
      "Iteration number 6 is done\n",
      "Iteration number 7 is done\n",
      "Iteration number 8 is done\n",
      "Iteration number 9 is done\n",
      "Iteration number 10 is done\n",
      "The training loss is 0.07877169414926731\n",
      "The test loss is 0.09860174386719459\n",
      "Iteration number 1 is done\n",
      "Iteration number 2 is done\n",
      "Iteration number 3 is done\n",
      "Iteration number 4 is done\n",
      "Iteration number 5 is done\n",
      "Iteration number 6 is done\n",
      "Iteration number 7 is done\n",
      "Iteration number 8 is done\n",
      "Iteration number 9 is done\n",
      "Iteration number 10 is done\n",
      "The training loss is 0.07865021658294132\n",
      "The test loss is 0.10315644400134238\n"
     ]
    }
   ],
   "source": [
    "for index in range(1,6):\n",
    "    instance_method(True, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 1 is done\n",
      "Iteration number 2 is done\n",
      "Iteration number 3 is done\n",
      "Iteration number 4 is done\n",
      "Iteration number 5 is done\n",
      "Iteration number 6 is done\n",
      "Iteration number 7 is done\n",
      "Iteration number 8 is done\n",
      "Iteration number 9 is done\n",
      "Iteration number 10 is done\n",
      "The training loss is 0.11552289902203985\n",
      "The test loss is 0.12013622473019914\n"
     ]
    }
   ],
   "source": [
    "instance_method(False, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
